\newpage
\section{Meta-aprendizado} \label{meta}
sugiro
quebrar o primeiro paragrafo em paragrafos menores e discutir , alem
de falar como voce fala que alguns trabalhos tratam de recomendacao de
algoritmos nao supervisionados, falar que as medidas diretas
frequentemente usam informacao sobre o atributo alvo
e que para algumas estrategias de recomendacao, como aprendi nao
supervisionado e aprendizado (assim fazer um gancho para sua tese), eh
necessario procurar medidas adicionais alem das propostas no statlog

seria interessante mencionar os trabalhos feitos no grupo ainda para
pre-processamento de dados (Bruno e Luis Paulo) para otimizacao
(Jorge) e para series de dados (Andre Rossi)


Um sistema de classificação baseado em aprendizado de máquina depende
de um modelo que é induzido por algoritmos de aprendizado (Seção \ref{contexto}).
Diante da infinidade de vieses possíveis de aprendizado,
muitos algoritmos têm sido propostos e alguns são frequentemente
empregados de forma generalizada na solução dos mais diversos problemas,
como é o caso das redes neurais artificiais \citep{haykin2004comprehensive}.
Entretanto, nenhum algoritmo pode ser adequado a todos os domínios,
pois um desempenho positivo em algumas situações de aprendizado
precisa ser compensado por um igual grau de desempenho negativo
em outras \citep{conf/icml/Schaffer94}.
Dessa forma, um sistema de aprendizado de máquina requer
uma escolha criteriosa de qual algoritmo deva ser empregado.
% \cite{wolpert1996lack},
Normalmente, o problema da escolha do algoritmo é resolvido
por um especialista em aprendizado de máquina que se baseia em conhecimentos
sobre os dados e sobre os algoritmos disponíveis
para escolher manualmente o melhor.
Essa escolha é feita segundo alguma métrica de desempenho
\cite{books/daglib/0022052}.
Uma maneira de se evitar a escolha manual é a adoção de algum tipo
de \textit{meta-aprendizado}, que é o estudo do aperfeiçoamento dos
algoritmos de aprendizado por meio da experiência.
Esse aperfeiçoamento se dá no nível \textit{meta},
que é um nível acima do aprendizado convencional, chamado de nível \textit{base}
\citep{journals/air/VilaltaD02}.
No nível base, o viés de aprendizado é fixo, enquanto que
no nível meta o viés normalmente é escolhido dinamicamente.
Existem diferentes formas de meta-aprendizado.
As mais relevantes são apresentadas nas seções seguintes.
A Seção \ref{direta}, em especial, descreve a abordagem mais aplicável ao problema de
recomendação de estratégias de aprendizado ativo.
Dependendo do conjunto de meta-atributos escolhidos,
ela permite caracterizar as bases de dados com poucos rótulos ou na ausência deles.

\subsection{Generalização em pilha}
Na \ing{generalização em pilha}{stacked generalization}
\citep{journals/nn/Wolpert92} o meta-aprendiz lida com uma metabase
que consiste de um conjunto de treinamento transformado por
aprendizes no nível base.
O resultado dessa transformação são metaexemplos cujos valores dos atributos
são as predições de cada modelo base.
Uma particularidade dessa abordagem é o viés estático,
pois ocorre uma combinação de algoritmos ao invés de uma seleção.

\subsection{Caracterização por modelos}
A própria estrutura dos modelos do nível base pode ser explorada na construção dos
metaexemplos.
Uma representante da \textit{caracterização por modelos} é a
\ing{indução de modelos tipados de ordem maior}{typed higher-order induction}.
Ela gera - de acordo com exemplo dado no trabalho de
\cite{conf/ilp/BensusanGK00} - uma árvore de decisão para cada
base de dados.
As árvores são completamente representadas por estruturas complexas
que servem de metaexemplos que são aprendidos por algoritmos especialmente
desenvolvidos para esse tipo de tarefa.

\subsection{Marcadores de referência}
Os \ing{marcadores de referência}{landmarkers} \citep{pfahringer2000tell}
são um conjunto diverso de algoritmos simples usados como referência para
algoritmos mais complexos.
A acurácia de cada um dos modelos associados fornece o valor de um meta-atributo.
Embora não diretamente aplicável, o conceito da geração de meta-atributos por meio
de processamentos que representem uma simplificação da tarefa base pode
ser adaptável ao cenário de aprendizado ativo conforme definido na Seção \ref{recom}.

\subsection{Caracterização direta}\label{direta}
A caracterização direta consiste na obtenção de medidas diretamente dos exemplos
que compõem uma base de dados, ou seja, sem o intermédio de um algoritmo
de aprendizado.
% tese kalousis: The first attempt to characterize datasets in order to predict the
% performance of classication algorithms was done by Rendell et al. (1987).
A primeira caracterização de bases de dados foi feita por \cite{conf/ijcai/RendellST87}
com o intuito de predizer acurácia e tempo de processamento e era baseada no número
de exemplos e de atributos.
O próximo conjunto, proposto no projeto STATLOG
\citep{brazdil1994analysis}, era composto de quinze medidas:
% mitchie 1994 pode ser a referência certa do STATLOG?
\begin{itemize}
 \item número de exemplos, atributos binários e não binários e classes;
 \item entropia das classes, informação mútua entre classe e atributos e razão sinal-ruído;
 \item entropia, curtose, assimetria, correlação e razão entre os desvios padrão entre atributos;
 \item primeira correlação canônica e variância pelo primeiro discriminante canônico.
\end{itemize}
Variações desse conjunto são propostas em trabalhos posteriores
\citep{books/daglib/0022052},
como a adoção de histogramas para evitar a perda de informações que ocorre quando
se adota a média das medidas nos diferentes atributos base \citep{kalousis2002algorithm};
ou a binarização de medidas, como o grau de dispersão do atributo alvo em
tarefas de regressão \citep{journals/ijon/GomesPSRC12}.
Outros conjuntos visam a recomendação automática de algoritmos não supervisionados.
Essa tarefa é mais próxima da recomendação de estratégias de aprendizado ativo.
Alguns trabalhos, por exemplo, adotam medidas como o grau de normalidade da distribuição e
o percentual de pontos aberrantes e de atributos mais relevantes
\citep{conf/ijcnn/SoutoPSACLS08,Ferrari2015181}.
As medidas adotadas na presente pesquisa são apresentadas em maior detalhe na
Seção \ref{recom}.



% kalousis2002algorithm -
%Algorithm selection via meta-learning - pg9 formaliza ap. sup. pra eu colocar no cap contexto
%ele fala de normalizar entropia pela maior possivel log(-) e fala de usa-la como medida de
%balanceamento




