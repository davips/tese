\newpage
\section{Meta-aprendizado} \label{meta}
Um sistema de classificação baseado em aprendizado de máquina depende
de um modelo que é induzido por algoritmos de aprendizado (Seção \ref{contexto}).
Diante da infinidade de vieses possíveis de aprendizado,
muitos algoritmos têm sido propostos e alguns são frequentemente
empregados de forma generalizada na solução dos mais diversos problemas,
como é o caso das redes neurais artificiais \citep{haykin2004comprehensive}.
Entretanto, nenhum algoritmo pode ser adequado a todos os domínios,
pois um desempenho positivo em algumas situações de aprendizado
precisa ser compensado por um igual grau de desempenho negativo
em outras \citep{conf/icml/Schaffer94}.
Isso decorre da existência de um viés necessário na forma de representação
(árvores de decisão e neurônios artificiais entre outras)
e busca de hipóteses sobre um dado problema (busca gulosa e otimização de funções entre outros).
A existência do viés de aprendizado é essencial para a capacidade de generalização
do algoritmo \citep{Mitchell:1980}.

Dessa forma, um sistema de aprendizado de máquina requer
uma escolha criteriosa de qual algoritmo deve ser empregado.
% deva <- errado(?)
% \cite{wolpert1996lack},
Normalmente, o problema da escolha do algoritmo é resolvido
por um especialista em aprendizado de máquina que se baseia em conhecimentos
sobre os dados e sobre os algoritmos disponíveis
para escolher manualmente o melhor.
Essa escolha é feita segundo alguma métrica de desempenho
\cite{books/daglib/0022052}.
Uma maneira de se evitar a escolha manual é a adoção de algum tipo
de \textit{meta-aprendizado}, que é o estudo do aperfeiçoamento dos
algoritmos de aprendizado por meio da experiência.
Esse aperfeiçoamento se dá no nível \textit{meta},
que é um nível acima do aprendizado convencional, chamado de nível \textit{base}
\citep{journals/air/VilaltaD02}.
No nível base, o viés de aprendizado é fixo, enquanto que
no nível meta o viés normalmente é escolhido dinamicamente.
Existem diferentes formas de meta-aprendizado.
As mais relevantes são apresentadas nas seções seguintes.
A Seção \ref{direta}, em especial, descreve a abordagem mais aplicável ao problema de
recomendação de estratégias de aprendizado ativo.
Dependendo do conjunto de meta-atributos escolhidos,
ela permite caracterizar as bases de dados com poucos rótulos ou na ausência deles.

\subsection{Generalização em pilha}
Na \ing{generalização em pilha}{stacked generalization}
\citep{journals/nn/Wolpert92} o meta-aprendiz lida com uma metabase
que consiste de um conjunto de treinamento transformado por
aprendizes no nível base.
O resultado dessa transformação são metaexemplos cujos valores dos atributos
são as predições de cada modelo base.
Uma particularidade dessa abordagem é o viés estático,
pois ocorre uma combinação de algoritmos ao invés de uma seleção.

\subsection{Caracterização por modelos}
A própria estrutura dos modelos do nível base pode ser explorada na construção dos
metaexemplos.
Uma representante da \textit{caracterização por modelos} é a
\ing{indução de modelos tipados de ordem maior}{typed higher-order induction}.
Ela gera - de acordo com exemplo dado no trabalho de
\cite{conf/ilp/BensusanGK00} - uma árvore de decisão para cada
base de dados.
As árvores são completamente representadas por estruturas complexas
que servem de metaexemplos que são aprendidos por algoritmos especialmente
desenvolvidos para esse tipo de tarefa.

\subsection{Marcadores de referência}
Os \ing{marcadores de referência}{landmarkers} \citep{pfahringer2000tell}
são um conjunto diverso de algoritmos simples usados como referência para
algoritmos mais complexos.
A acurácia de cada um dos modelos associados fornece o valor de um meta-atributo.
Embora não diretamente aplicável, o conceito da geração de meta-atributos por meio
de processamentos que representem uma simplificação da tarefa base pode
ser adaptável ao cenário de aprendizado ativo conforme definido na Seção \ref{recom}.

\subsection{Caracterização direta}\label{direta}
A caracterização direta consiste na obtenção de medidas diretamente dos exemplos
que compõem uma base de dados, ou seja, sem o intermédio de um algoritmo
de aprendizado.
A primeira caracterização de bases de dados foi feita por \cite{conf/ijcai/RendellST87}
com o intuito de predizer acurácia e tempo de processamento.
Ela era baseada no número de exemplos e de atributos.
O próximo conjunto de meta-atributos, proposto no projeto STATLOG
\citep{brazdil1994analysis}, era composto de quinze medidas:
% mitchie 1994 pode ser a referência certa do STATLOG?
\begin{itemize}
 \item número de exemplos, atributos binários e não binários e classes;
 \item entropia das classes, informação mútua entre classe e atributos e razão sinal-ruído;
 \item entropia, curtose, assimetria, correlação e razão entre os desvios padrão entre atributos;
 \item primeira correlação canônica e variância pelo primeiro discriminante canônico.
\end{itemize}
Variações desse conjunto são propostas em trabalhos posteriores
\citep{books/daglib/0022052},
como a adoção de histogramas para evitar a perda de informações que ocorre quando
se adota a média das medidas nos diferentes atributos base \citep{kalousis2002algorithm};
ou a binarização de medidas, como o grau de dispersão do atributo alvo em
tarefas de regressão \citep{journals/ijon/GomesPSRC12}.
Também há trabalhos direcionados a: otimização \citep{journals/ijhis/KandaCHS11},
fluxos de dados \citep{journals/ijon/RossiCSS14}, predição de ranqueamentos
\citep{conf/iberamia/SouzaCS10} e detecção de ruído \citep{Garcia2015}.
Finalmente, há trabalhos que visam a recomendação automática de algoritmos
não supervisionados.
Essa tarefa é mais próxima da recomendação de estratégias de aprendizado ativo
pela ausência de rótulos, diferentemente de muitas medidas dos conjuntos
citados anteriormente que dependem do atributo alvo, ou seja,
da existência de rótulos.
Assim, dentro do contexto desta tese, a caracterização não supervisionada
de bases de dados, apesar de não voltada originalmente ao problema
de seleção de estratégias, se mostra compatível.
Esse tipo de caracterização inclui medidas como o grau de normalidade da distribuição e
o percentual de pontos aberrantes e de atributos mais relevantes
\citep{conf/ijcnn/SoutoPSACLS08,Ferrari2015181}.


As medidas adotadas na presente pesquisa são apresentadas em maior detalhe na
Seção \ref{recom}.

% kalousis2002algorithm -
%Algorithm selection via meta-learning - pg9 formaliza ap. sup. pra eu colocar no cap contexto
%ele fala de normalizar entropia pela maior possivel log(-) e fala de usa-la como medida de
%balanceamento