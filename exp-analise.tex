\section{Análise comparativa}\label{comparativa}
\esb{em todos exp, a necessidade de aplicação de filtro é separada, ex.: o learner precisa,
mas não obriga o classif a usar ou viceversa;
a mesma ideia foi estendida para a relação estrat-learner,
a estratégia precisa (maha), mas não obriga o learner a usar  ou viceversa}

Há aplicações cujas particularidades ou preferências do especialista determinam
previamente o algoritmo de aprendizado. \ano{exemplos?}
Nessas aplicações, o algoritmo do classificador coincide com o algoritmo do aprendiz.
Por outro lado, há aplicações em que a escolha do algoritmo é livre e, definido o
aprendiz (ou sua ausência), a escolha do classificador se dá idealmente a partir do
momento em que o conjunto de treinamento se torne suficientemente grande para
a realização de uma validação cruzada \ano{ref?}.
Para simular esses dois cenários de forma concisa,
a comparação de estratégias está dividida da seguinte maneira:
\begin{enumerate}
  \item \textbf{algoritmo pré-definido} -
  cada combinação base-algoritmo é um teste e cada estratégia é uma abordagem sob comparação;
  o desempenho é medido durante a evolução do aprendiz.
  \item \textbf{algoritmo definido após rotulação} -
  cada base é um teste e cada par estratégia-aprendiz é uma abordagem sob comparação;
  o desempenho é medido com o melhor classificador obtido após a rotulação.
\end{enumerate}

\subsection{Cenário com algoritmo pré-definido}\label{predefinido}
\ano{detalhes do exp aqui ou na metodologia ou nos dois?:
ALC kappa}

No cenário em que o algoritmo a ser adotado pelo aprendiz e pelo classificador é
pré-definido, supõe-se que a aplicação impõe
o algoritmo a ser usado devido à natureza do problema ou devido a restrições do sistema; ou,
o especialista recorre à experiência pessoal ou faz uma escolha arbitrária.
Assim, todas as combinações base-algoritmo foram consideradas possíveis numa aplicação real
e puderam ser adotadas como testes no experimento.

% http://research.cs.wisc.edu/techreports/2009/TR1648.pdf
Estratégias são normalmente avaliadas por meio de curvas de aprendizado,
que são os gráficos da medida de interesse em função da quantidade de consultas
\citep{settles2010active}.
% Figure 3 presents learning curves for the first 100 instances labeled using
% uncertainty sampling and random sampling.
% The reported results are for a logistic regression model averaged over ten folds
% using cross-validation.
O comportamento típico da curva de aprendizado ativo seguido pelas diferentes estratégias
é ilustrado na Figura \ref{curvas}
Apesar da pouca discernibilidade das curvas, a exibição delas permite notar
que elas têm a mesma forma logarítmica, com o valor kappa divergindo na medida em que novos
exemplos são consultados.
\input plot
Se todas as bases tivessem a mesma quantidade de exemplos
e o aprendizado prosseguisse, as curvas se encontrariam novamente,
pois tendem ao desempenho passivo.

É possível observar que a curva de SVMbal se destaca negativamente,
mas comparações de curvas neste gráfico são imprecisas devido aos diferentes
pesos que as bases podem ter:
bases mais difíceis, por exemplo, tendem a ter um valor mais baixo para kappa e acabam
sub-representadas.
Uma forma de neutralização desse tipo de desigualdade entre as bases é a adoção
de ranqueamento das médias\footnote{Além das médias,
um gráfico das medianas também foi elaborado e teve um comportamento praticamente igual.
% com leves perturbações irrelevantes
Por motivos de espaço ele foi omitido.}, conforme mostrado na Figura \ref{curvasrank},
que confirma o mau desempenho de SVMbal e QBCRFw - as duas estratégias de aprendiz fixo.
\input rankplot
Os aprendizes fixos (SVM e RFw) podem gerar consultas desfavoráveis aos outros algoritmos
empregados como classificador (5NN, C4.5w, CIELM e NB).
De forma mais ampla, pode-se esperar que estratégias gnósticas não tenham um desempenho
constante ao longo de todos os seis aprendizes em cada base.
Essa hipótese seria mais provável se as estratégias agnósticas (Rnd, Clu e ATUmah) tivessem obtido
resultados acima da média, porém Rnd e Clu que permaneceram
abaixo da colocação média ($5.5$) por praticamente todo o intervalo de consultas.
ATUmah se manteve próxima da média, porém com mais vantagem na primeira metade do orçamento.
Assim, é mais provável que a própria natureza das estratégias seja inferior para o dado conjunto de bases.
\ano{muito especulativo}

% DWeuc é a estratégia Mar ponderada pela densidade, logo, dada a superioridade de Mar,
% a ponderação por densidade pode ser considerada bastante prejudicial quando não leva em
% conta os exemplos rotulados.
% Por outro lado, as extensões de DW (TU, ATU e GATU) superam as demais, pois ponderam inversamente pela
% densidade de exemplos rotulados evitando, assim, as regiões densamente rotuladas.
SGmulti, por sua vez, se manteve estável, pouco acima da colocação média.
Um evento importante entre as melhores curvas é a inversão entre a estratégia agnóstica
ATUmah e Mar após aproximadamente $50$ exemplos.
Essa inversão coincide com a intuição de que consultas exploratórias sejam vantajosas no início do
aprendizado, enquanto que consultas prospectivas passem a ser proveitosas mais tardiamente.
Assim, estratégias como HTUmah e TUmah, capazes de combinar agnosticidade e gnosticidade,
podem ter um bom desempenho tanto no início quanto no restante da curva de aprendizado
conforme evidenciado por suas curvas.
A curva ascendente de Mar, quando vista isoladamente, também é um indicativo de que a prospecção pura
é prejudicial no início e vantajosa com o avanço do aprendizado.
Por fim, EERent mostrou-se como uma das melhores opções pela estabilidade e colocação de sua curva.

Para confirmar as conclusões com segurança estatística, os níveis de confiança
($p \in \{0,01; 0,05; 0,10\}$) na Tabela \ref{stratsALCKappaFriedAllReduxall} indicam
quando uma estratégia na linha é melhor que a outra na coluna.
O critério de vitória é baseado na comparação dos valores da kappa médio para todas as bases.
A medida foi calculada com $200$ exemplos nas bases de tamanho suficiente
e $|\mathcal{U}|$ nas demais.
% \input stratsmahALCKappaFriedAllReduxall
\begin{table}[h]
\caption{Um contra um para as estratégias (564 testes).
Medida: kappa médio. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}

\begin{center}
\scalebox{0.82}{
\begin{tabular}{lcc|cc|cc|cc|cc}
                   & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
1 - Rnd         & - &   &   &   &   &   &   &   &   &   \\
2 - Clu         & + & - &   &   &   & * &   &   &   & * \\ \hline
3 - \textbf{ATUmah}     & * &   & - &   &   & * &   &   &   & * \\
4 - \textbf{HTUmah}     & * & * & * & - & * & * &   &   &   & * \\ \hline
5 - \textbf{SGmulti}    & * &   &   &   & - & * &   &   &   & * \\
6 - QBCRFw      &   &   &   &   &   & - &   &   &   &   \\ \hline
7 - Mar         & * & * &   &   &   & * & - &   &   & * \\
8 - TUmah       & * & * & + &   & + & * &   & - &   & * \\ \hline
9 - EERent      & * & * & * &   & * & * &   &   & - & * \\
10 - SVMbal     &   &   &   &   &   &   &   &   &   & - \\ \hline
\end{tabular}
}
\quad
\scalebox{0.82}{
\begin{tabular}{lccc}
algoritmo & \makecell{primeiros\\lugares} & \makecell{derrotas\\para Rnd}  & \makecell{últimos\\lugares} \\
\hline
EERent     & \bom{280} & \bom{168} & 121 \\
\textbf{HTUmah}     & \bomd{251} & \bomd{179} & \bom{88} \\
Mar        & 235 & 187 & 161 \\
TUmah      & 233 & 200 & \bomd{119} \\
\textbf{ATUmah}     & 176 & 207 & 139 \\
\textbf{SGmulti}    & 152 & 216 & 134 \\
SVMbal     & 123 & \ruim{334} & \ruim{304} \\
QBCRFw     & 106 & 311 & 266 \\
Clu        & 103 & 227 & 164 \\
Rnd        & \ruim{71} & - & 225 \\
\end{tabular}
}
\label{stratsALCKappaFriedAllReduxall}
\end{center}
\end{table}

Como um indicativo da viabilidade do aprendizado ativo em geral, Rnd perde de todas exceto QBCRFw
e SVMbal.
Clu superou a amostragem aleatória, respeitando a garantia teórica de que não é inferior a ela.
Dentre as melhores estratégias,
a proposta HTUmah obteve vitórias maior significância estatística que sua principal contendente TUmah
e se equiparou a EERent.
Dentre as agnósticas selecionadas ATUmah é a preferível, também por superar suas contendentes
significativamente.
SGmulti obteve um desempenho próximo ao de ATUmah.

% Se forem consideradas apenas as primeiras 100 consultas -
% %150 conf/emnlp/SettlesC08
% valor arbitrário frequentemente adotado em outros trabalhos
% \citep{journals/pieee/CrawfordTY13,chermanaprendizado,conf/nips/SettlesCR07,conf/icml/RoyM01} -
% A comparação passa a ser como na Tabela \ref{stratsALCKappaFriedAllReduxHalf}.
% \input stratsmanALCKappaFriedAllReduxall
% \input stratseucALCKappaFriedAllReduxall
% conforme Tabela \ref{stratsALCKappaFriedAllReduxHalf}.
% $50$ exemplos: quantidade máxima antes que o tamanho das bases permita ALCs de tamanhos diferentes
% - conforme Tabela \ref{stratsALCKappaFriedAllRedux50}.
Em aplicações reais, entretanto, a estabilidade do algoritmo pode ser mais importante
do que o desempenho preditivo médio, pois uma grande variabilidade pode colocar o
orçamento sob o risco de ser gasto sem que seja atingido um desempenho adequado e pode levar a custos
excedentes de rotulação imprevisíveis.
Assim, a estabilidade da estratégia tem fundamental importância para a análise do risco financeiro
da aplicação. É importante enfatizar que o processo de rotulação é irreversível,
impossibilitando a experimentação de mais de uma estratégia.

De forma análoga às curvas apresentadas para o valor médio de kappa e o ranqueamento
correspondente, dois conjuntos de curvas baseadas no desvio padrão do valor de kappa foram
construídos visando ilustrar o comportamento da variância preditiva a cada instante ao longo
de sucessivos valores de orçamento.
É possível observar, na Figura \ref{curvasrankdesvio}, que as estratégias ATUmah, HTUmah,
TUmah e EERent detêm as melhores colocações no ranqueamento médio dos menores valores de desvio
padrão durante a maior parte do processo de rotulação.
\input rankplotRisco
\input plotRisco
O mesmo ocorre com os ranqueamentos apresentados na Figura \ref{curvasdesvio}.
Nesse gráfico, a distância entre a melhor e a pior curva se mantém em torno de $0,01$,
indicando que, embora algumas sejam mais estáveis, a faixa ocupada pelas curvas é estreita.
porém com EERent alternando com TUmah.
A curva de SGmulti ficou em torno do ranqueamento médio ($5,5$).

Uma propriedade das curvas é a tendência de estabilização durante o treinamento,
indicando que em baixos orçamentos a escolha de estratégias mais estáveis é prioritária.
A significância estatística das diferenças pode ser verificada na Tabela
\ref{stratsALCKappaFriedAllRiscoReduxall}.
\begin{table}[h]
\caption{Um contra um para as estratégias. Medida: desvio padrão do kappa médio. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}
\begin{center}
\begin{tabular}{lcc|cc|cc|cc|cc}
                                  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
1 - Rnd                        & - &   &    &   &    &   &    &    &   &   \\
2 - Clu                         &   & - &    &   &    &   &    &    &   &   \\ \hline
3 - \textbf{ATUmah}     & *& * & -  &   & * &   & * &    & * & * \\
4 - \textbf{HTUmah}     & * & * &   & - & * &   & * &  +& * & * \\ \hline
5 - \textbf{SGmulti}       &   &   &    &   & - &   &    &   &   &   \\
6 - QBCRFw                 & * & * &    &   & * & - & * &   & * & * \\ \hline
7 - Mar                        &   &   &    &   &    &   &  - &    &   &   \\
8 - TUmah                   & * & * &    &   & * &   & * &  - & *& * \\ \hline
9 - EERent                   &   & * &    &   &    &   &    &    & - &   \\
10 - SVMbal                 &   &   &    &   &    &   &    &    &   & - \\ \hline\end{tabular}
% calculado pelo R
\label{stratsALCKappaFriedAllRiscoReduxall}
\end{center}
\end{table}

Finalmente, pode-se concluir que a versão híbrida proposta (HTUmah) é superior a TUmah
para o conjunto de bases e algoritmos utilizados.
ATUmah é viável enquanto alternativa agnóstica.
SGmulti obteve um desempenho mediano,
logo ela pode ser uma candidata a viés de amostragem alternativo num sistema de recomendação.
Com relação à minimização de risco financeiro, 
novamente as estratégias propostas também se mostraram viáveis,
com HTUmah sendo a mais estável - vencendo TUmah com significância estatística.

A principal dificuldade do cenário explorado nesta seção é, possivelmente, a existência de algumas
combinações menos favoráveis entre as bases e os algoritmos selecionados.
Algumas delas são perceptíveis na Figura \ref{treebadleas}.
A árvore indica a contagem de derrotas de cada algoritmo de acordo com a medida kappa.
Pequenas reservas de exemplos ($\#exemplos \leq 142,4$),
por exemplo, desfavorecem CIELM mais fortemente.
% \afterpage{\clearpage\begin{landscape}
\begin{figure}
\tikzset{
every node/.style={font=\scriptsize,black, thin},
decision/.style={shape=rectangle, minimum height=1cm, text width=1.7cm,
text centered, rounded corners=1ex, draw},
outcome/.style={ shape=rectangle, fill=red!15, draw, text width=2cm, text justified},
decision tree/.style={sibling distance=3cm, level distance=2cm},
cond/.style={blue, yshift=-2mm, shape=rectangle, text centered},
}
\begin{center}
\caption{Possíveis nichos de inadequação base-algoritmo.
\textit{Mínimo de dez exemplos por folha.}}
\begin{tikzpicture} [edge from parent/.style={->,above,draw,sloped,midway,gray!30,ultra thick},
text width=2.7cm, align=flush center, grow cyclic,
level 1/.style={level distance=3.2cm,sibling angle=45},
level 2/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 3/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 4/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 5/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
]
\input{treeLearnerKappaperd}
\label{treebadleas}
\end{tikzpicture}
\end{center}
\end{figure}
% \end{landscape}\clearpage}

As curvas de ranqueamento dos dez melhores\footnote{Melhor conforme o maior valor de cada curva.}
pares estratégia-aprendiz são exibidas
na Figura \ref{plotPares}. Adicionalmente, a melhor curva de cada algoritmo não contemplado
entre os melhores pares é apresentada juntamente com suas demais curvas em pontilhado.
As curvas em pontilhado de um mesmo algoritmo se mantêm próximas.
Isso é mais claramente ilustrado pelas curvas dos pares com CIELM.
É notável que, quando usado com um algoritmo mais adequado, por exemplo,
o RFw no casos das bases adotadas, SGmulti e Clu se tornam mais competitivos.

\ano{colocar tabela fried e contagens}
\begin{figure}[!h]
   \setlength{\unitlength}{1.0cm}
   \centering
     \includegraphics[scale=1]{plotPares.pdf}
   \caption{curvas de ranqueamento dos pares}
   \label{plotPares}
\end{figure}


% \subsection{Síntese das comparações}\label{sintese}
% \ano{rever}
% \tar{fazer uma sintese pra cada uma das duas comparações ou fazer uma sintese só no fim de tudo?}
% Estratégias agnósticas têm a vantagem de dispensar o aprendiz.
% Assim, elas evitam o risco de uma escolha inadequada de algoritmo de aprendizado
% para um dado problema.
% Consequentemente, ATUmah seria a preferível no caso de algoritmos variados.
% Entretanto, os resultados dos quatro experimentos apontam para diferentes melhores
% estratégias.
% Apesar de ATUmah não ter sido pior que a amostragem aleatória em nenhum deles,
% ela perde de Mar, TUmah e EERent em alguns casos.
% Logo, se for desejado o melhor desempenho para um dado algoritmo,
% então é preciso recorrer a algum procedimento que minimize a chance de
% uma escolha inadequada de estratégia.
% Além do algoritmo, o orçamento disponível e as características de cada base também
% podem favorecer ou prejudicar certas estratégias.
% 
% Nesta seção, as estratégias são comparadas com o objetivo de identificar nichos
% em que umas possam se sobressair em relação às outras.
% Cada nicho corresponde a um algoritmo e um conjunto de bases de dados similares entre si.
% 
% Nas árvores exibidas nas figuras \ref{treeBest} e \ref{tree},
% é possível observar o papel central do algoritmo de aprendizado sobre
% a estratégia de aprendizado ativo, pois é a primeira regra em ambas as árvores.
% Elas simulam dois cenários com relação à escolha do algoritmo: quando o mais adequado é conhecido
% (\ref{treeBest}) e quando ele é arbitrário (\ref{tree}).
% O primeiro caso resulta em $95$ metaexemplos devido a um empate,
% e o segundo caso também resulta em torno de $95$ metaexemplos, porém para cada algoritmo,
% totalizando $595$.
% % Apesar de ilustrativa, a árvore pode não ser segura do ponto de vista de tomada de
% % decisão devido ao baixo grau de pureza das folhas.
% % \input arvorebest
% % \input arvore
% % \input arvorebestperd
% % \input arvoreperd
% 
% % \ref{tree}
% A amostragem aleatória aparece apenas na folha que representa o uso do 5NN nas quatro bases que têm
% uma proporção de atributos nominais não muito alta (igual ou abaixo de $77$),
% poucos atributos em geral (igual ou abaixo de $6$) e não muitos exemplos (igual ou abaixo de $1078$).
% Assim, pode-se concluir que não optar pelo aprendizado ativo raramente é a melhor estratégia.
% Num nicho similar, porém com muitos exemplos (acima de $1078$), HTUmah é a mais indicada.
% ATUmah
% 
% % \ref{treeBest}
% O algoritmo NB produz estimativas de distribuição de probabilidade excessivamente confiantes
% que podem ser amenizadas por um \ing{comitê por amostragem}{bagging} \citep{conf/icml/RoyM01}.
% Estratégias que dependem dessas estimativas podem ser prejudicadas.
% ATUmah por ser agnóstica é independente dessas estimativas e aparece como nó
% folha para esse algoritmo de aprendizado.
% EERent também aparece e é gnóstico,
% mas seu uso da soma das entropias das estimativas de
% probabilidade de todos os exemplos da reserva ameniza o efeito do excesso de confiança.
% 
% % Algumas ramificações aceitam explicações plausíveis:
% % \begin{itemize}
% %  \item
% % 
% % % \esb{When Does Active Learning Work?
% % % confirma que atributos não-discretizados favorecem AL,
% % % isso justifica z-score para qq classificador ?
% % % (ao menos RF, SVM, log reg. e QDA usados no artigo).
% % % usa apenas QBC, entropia e random.
% % % }
% % \end{itemize}

\section{algoritmo definido após rotulação}\label{ind}
Numa aplicação real, a disponibilidade de rótulos permite uma escolha mais adequada
do algoritmo de aprendizado.
\ano{relembrar que U=100, o valor comum na literatura e para não ficar com menos de 75 bases}
Na Figura \ref{treegoodstrats}, embora a árvore de nichos de inadequação contenha uma
previsível presença expressiva das piores estratégias em todos os nós, como as variantes DW*,
algumas estratégias bem sucedidas no primeiro experimento aparecem com a maior frequência
de derrotas em alguns nós, como é o caso de EERent no caminho
(fronteira=flexível) $\rightarrow$ (algoritmo=CIELM) $\rightarrow$ ($\#atributos \leq 18$)
com 24 derrotas.
Assim, mesmo estratégias com um bom desempenho geral podem ser contraindicadas em
bases ou aprendizes com determinadas características - dificultando a definição prévia
do par estratégia-algoritmo mais adequado.
% \afterpage{\clearpage\begin{landscape}
\begin{figure}
\tikzset{
every node/.style={font=\scriptsize,black, thin},
decision/.style={shape=rectangle, minimum height=1cm, text width=1.7cm,
text centered, rounded corners=1ex, draw},
outcome/.style={ shape=rectangle, fill=red!15, draw, text width=2cm, text justified},
decision tree/.style={sibling distance=3cm, level distance=2cm},
cond/.style={blue, yshift=-2mm, shape=rectangle, text centered},
}
\begin{center}
\caption{Possíveis nichos de inadequação base-estratégia-algoritmo.
\textit{Mínimo de dez exemplos por folha.}}
\begin{tikzpicture} [edge from parent/.style={->,above,draw,sloped,midway,gray!30,ultra thick},
text width=2.7cm, align=flush center, grow cyclic,
level 1/.style={level distance=3.2cm,sibling angle=180},
level 2/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 3/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 4/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 5/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
]
\input{treeALCKappaperd}
\label{treegoodstrats}
\end{tikzpicture}
\end{center}
\end{figure}
% % \end{landscape}\clearpage}
Mesmo que o usuário disponha de informações auxiliares sobre o domínio da aplicação,
elas podem não se aplicar ao seu conjunto específico de exemplos cujo tamanho foi restringido
pelo orçamento, pois algoritmos com boa performance em treinamento com poucos
dados podem ter baixa performance com muitos dados
\citep{journals/sigkdd/AttenbergP10,journals/jmlr/PerlichPS03}.
Assim, estratégias agnósticas e aquelas cujo aprendiz possa ser desvinculado da escolha do
algoritmo de aprendizado definitivo da aplicação se mostram desejáveis.

As estratégias agnósticas adiam naturalmente a escolha do algoritmo para depois da
etapa de rotulação.
Entretanto, elas são desprovidas da capacidade de prospecção advinda do víes de
aprendizado inerente a todo aprendiz.
As estratégias gnósticas, por sua vez, dependem desse viés desde o início da amostragem ativa.
Apesar disso, é possível adotar um aprendiz compatível com a estratégia e do qual
se espera um bom desempenho geral.
Assim, depois de obtidos os rótulos, o algoritmo definitivo seria escolhido via validação cruzada.

O experimento desta seção foi formulado para avaliar a viabilidade de se contornar o
problema da escolha do aprendiz e identificar pares estratégia-aprendiz com melhor
desempenho geral ou por nicho.
Para isso, foram comparadas todas as combinações possíveis.
A avaliação de cada par foi feita após o término do processo de rotulação,
com base no modelo gerado por um algoritmo de aprendizado desvinculado do mesmo,
escolhido por validação cruzada e simulando o papel de classificador final do sistema.
A comparação dos pares estratégia-aprendiz se dá por dois pontos de vista:
tabelas um contra um e contagem de colocações; e, árvore de nichos de adequação.

\input arvorePares

% \section{Tempo de espera tolerável (fazer se der tempo depois de ter terminado meta)}
% \ano{para o tempo não é necessário separar por classificador; basta um fried}
% 
% \ano{EER venceu demais. no tempo ele vai perder de todas?}
% 
% \esb{Não foi possível auferir tempo durante experimentos de desempenho porque eles são
% paralelizados e compartilham cache de processador.}
% 
% \tar{limite de espera pra usuário web é 15s, é o máximo aceitável}
% \citep{conf/amcis/Nah03}
% 
% % Miller (1968) argued for the 2-second rule based on the theory of limitations in human short-
% % term memory. According to Miller, short-term memory plays a critical role in human information
% % processing; interference with short-term memory can occur when an individual senses an awareness of
% % waiting after approximately 2 seconds. Thus, to stay uninterrupted in information processing, the 2-
% % second guideline is recommended. For tasks where uninterrupted focus is critical, Nielsen (1995)
% % suggests that computer response should be kept within one second.
% % 
% % 
% % From this study, we found that Web users expect a response in about 2 seconds for simple
% % information retrieval tasks on the Web.
% % A 2-second response is needed to ensure 'smooth' interactions
% % between the WWW and the users.  The findings from this
% % study also suggest that the upper bound for Web users' TWT is 15 seconds when
% % the system does not provide any indication or feedback concerning
% % the download
% 
% \esb{
% é melhor comparar tempos minimos do que tempos medios;
% pode haver outlier para cima,
% mas para baixo há o limite onde todas as otimizações de hardware já
% foram atingidas e a ausência de outros processos é total.
% Assim, trata-se de uma grandeza mais comparável entre algoritmos. (ref?)
% }
% 
% \tar{rodar um classif. rápido de treino e um
% rápido de teste em todas as bases, registrar tempo médio de consulta de cada
% estratégia e gerar friedman (espera-se realçar vantagem dos agnósticos)}
% 
% % 
% % e uma faixa de orçamentos:
% % \begin{itemize}
% %  \item orçamento baixo: $|Y|<\cent\leq min(\frac{|\mathcal{U}|}{2},100)$
% %  \item orçamento alto: $min(\frac{|\mathcal{U}|}{2},100)<\cent\leq min(|\mathcal{U}|,200)$
% % \end{itemize}
% 
% \esb{pra provar que o algoritmo é determinante, basta demonstrar qtas vezes o melhor par contem
% o mesmo algoritmo que venceu na passiva}
