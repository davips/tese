\section{Análise Comparativa}\label{analise}
\esb{criar boas siglas pras estrats e learners pras tabelas}

\ano{explicar pela arvore quais os nichos de cada estrategia}

\ano{usar clustering para mostrar que estrategias se adequam a nichos parecidos
(a arvore do agrupamento hierarquico pode ilustrar bem isso,
só falta descobrir como fazer o weka imprimir os nomes das strats,
provavelm é colocando um atributo string.)}

\esb{provavelmente o classificador atrapalha quando ele
não tem uma estimativa de distribuição de probabilidade suave;
isso afeta a medida de incerteza;
ao menos NB e 5NN devem ter esse problema;}

\esb{
É fato que o algoritmo NB produz estimativas de distribuição de probabilidade
excessivamente confiantes \citep{conf/icml/RoyM01}, eles usaram bagging para amenizar
e talvez SGmulti esteja funcionando como bagging, por isso NB vai melhor com ele.
Os dois extremos seriam: SGmultiConsensus e Uncertainty.
Os outros algoritmos são ortogonais a essa hierarquia.
Os baseados em densidade, por exemplo, podem consultar
exemplos adjacentes àqueles já conhecidos, explorando, assim,
uma região fora daquela delimitada pelos extremos da hierarquia
(citar figura do capítulo anterior) - ou pelo menos fora da SG.
É possível percorrer controlar essa abrangência em ambos os
algoritmos de um extremo ao outro. Com SG,
basta que os pesos dos exemplos rotulados artificialmente sejam
ajustados para valores muito menores.
O mesmo vale para Uncertainty, se for definido um limiar de decisão binário.
O limiar determinaria a abrangência espacial.}

\ano{para avaliar a suavidade de cada learner,
posso calcular a entropia média da saída de cada classif para cada
base em todos os exemplos
e fazer uma tabela com a ultima linha sendo a media de todas as bases}

\esb{When Does Active Learning Work?
confirma que atributos não-discretizados favorecem AL, isso justifica z-score para qq classificador ? (ao menos RF, SVM, log reg. e QDA usados no artigo).
usa apenas QBC, entropia e random.
}

\ano{dizer em algum lugar que demonstra a Viabilidade do Aprendizado Ativo}

\ano{neste e nos outros 2 caps de resultados vão aparecer apenas dados
das strats mais importantes;
as tabelas completam ficarão no apêndice inclusive resultados de kff e balanced-ee;
outra opção para kff e balanced-ee é ficarem apenas na tabela referente a learner=svm do
cap de experimentos}

\esb{ilustra diferenças entre estratégias (incluindo as novas)}

\esb{árvore, plot de vitórias vs budget, variabilidade/estabilidade, tempo, comparação com passivo* -
demonstra que AL é viável em geral e demonstra a efetividade das novas
estratégias propostas
(ponderação pela classe tenta atacar o desbalanceamento, preciso ver se
é mesmo nessas bases que ela se sobressai)}

ref para plot:
Active learning literature survey 2009
http://research.cs.wisc.edu/techreports/2009/TR1648.pdf
...
Active learning algorithms are generally evaluated by constructing learning curves,
which plot the evaluation measure of interest (e.g., accuracy) as a function of the
number of new instance queries that are labeled and added to L.
Figure 3 presents learning curves for the first 100 instances labeled using
uncertainty sampling and random sampling.
The reported results are for a logistic regression model averaged over ten folds
using cross-validation.

\ano{comparar o melhor par estrat/ELM com o melhor par estrat/SVM
seria um bom indicativo de viabiidade da ELM com AL}

\esb{
agrupar por distância entre acurácias (vetor de ~700 dimensões) -
inclui tabela 18x18, grupos de estratégias similares e árvore com hierarquia dos grupos
}

\ano{o experimento poderia continuar rodando para as strats e learns(?) mais importantes
até que a passiva fosse atingida, assim seria possivel avaliar as mais economicas quando
perdas na acurácia é inaceitável. (a forma menos codificante de fazer isso
é fixar um learner no código,
manter apenas os datasets em que a passiva ainda nao foi atingida visualmente
na tabela, rodar
mais 10 queries e repetir o processo até acabarem os datasets)}

\tar{falta um teste para esse cap. ficar ideal: rodar um classif. rápido de treino e um
rápido de teste em todas as bases, registrar tempo médio de consulta de cada
estratégia e gerar friedman (espera-se realçar vantagem dos agnósticos)}

\ano{* -> foram adotadas duas medidas importantes:
ALCKappa e BalancedAcc (poderia haver tb ALCBalancedAcc e Kappa,
mas vai duplicar a qtd de dados pra análise);
por definição, a ALC passiva não é comparável com ALCs ativas.
A BalancedAcc passiva deve ser calculada num ponto anterior ao término
dos exemplos em todas as bases, i.e.  200
(um número grande deixa mais justa a comparação com passivo) ou
metade do numero de exemplos, o que for menor.
}
\ano{Efetividade geral}

\blue{friedman um a um não está dando nada?}

\blue{friedman talvez funcione melhor por nicho (metaclusters)}

\esb{citar: contra random; comparação 1-a-1; variabilidade (risco);
tolerable waiting time}

\tar{ fazer tabelão friedman (40? pares strat/classif: 40x40)}

\section{Determinação da semelhança entre classificadores}
tabela de passivas: learners nas colunas, datasets nas linhas
fried de passivas
tabela de distâncias no espaço R7 para descobrir quais são similares entre si

\section{Afinidades estratégia-domínio-classificador-orçamento}

\section{Risco}
variabilidade

\section{Tempo de espera tolerável}

\tar{
fazer árvore de decisão que mostre que metacaracteristicas influenciam e como no tempo de treinamento?
}

Não é possível auferir tempo durante experimentos de desempenho porque eles são
paralelizados e compartilham cache de processador.

limite de espera pra usuário web é 15s, é o máximo aceitável
\citep{conf/amcis/Nah03}

Miller (1968) argued for the 2-second rule based on the theory of limitations in human short-
term memory. According to Miller, short-term memory plays a critical role in human information
processing; interference with short-term memory can occur when an individual senses an awareness of
waiting after approximately 2 seconds. Thus, to stay uninterrupted in information processing, the 2-
second guideline is recommended. For tasks where uninterrupted focus is critical, Nielsen (1995)
suggests that computer response should be kept within one second.


From this study, we found that Web users expect a response in about 2 seconds for simple
information retrieval tasks on the Web.
A 2-second response is needed to ensure 'smooth' interactions
between the WWW and the users.  The findings from this
study also suggest that the upper bound for Web users' TWT is 15 seconds when
the system does not provide any indication or feedback concerning
the download

\esb{
é melhor comparar tempos minimos do que tempos medios;
pode haver outlier para cima,
mas para baixo há o limite onde todas as otimizações de hardware já
foram atingidas e a ausência de outros processos é total.
Assim, trata-se de uma grandeza mais comparável entre algoritmos. (ref?)
}