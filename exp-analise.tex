\section{Análise comparativa}\label{comparativa}
Há aplicações cujas particularidades ou preferências do especialista determinam
previamente o algoritmo de aprendizado. \ano{exemplos?}
Nessas aplicações, o algoritmo do classificador coincide com o algoritmo do aprendiz.
Por outro lado, há aplicações em que a escolha do algoritmo é livre e, definido o
aprendiz (ou sua ausência), a escolha do classificador se dá idealmente a partir do
momento em que o conjunto de treinamento se torne suficientemente grande para
a realização de uma validação cruzada \ano{ref?}.
Para simular esses dois cenários de forma concisa,
a comparação de estratégias está dividida da seguinte maneira:
\begin{enumerate}
  \item \textbf{algoritmo pré-definido} -
  cada combinação base-algoritmo é um teste e cada estratégia é uma abordagem sob comparação;
  o desempenho é medido durante a evolução do aprendiz.
  \item \textbf{algoritmo definido após rotulação} -
  cada base é um teste e cada par estratégia-aprendiz é uma abordagem sob comparação;
  o desempenho é medido com o melhor classificador obtido após a rotulação.
\end{enumerate}

\subsection{Cenário com algoritmo pré-definido}\label{predefinido}
\ano{detalhes do exp aqui ou na metodologia ou nos dois?:
ALC kappa}

No cenário em que o algoritmo a ser adotado pelo aprendiz e pelo classificador é
pré-definido, supõe-se que a aplicação impõe
o algoritmo a ser usado devido à natureza do problema ou devido a restrições do sistema; ou,
o especialista recorre à experiência pessoal ou faz uma escolha arbitrária.
Assim, todas as combinações base-algoritmo foram consideradas possíveis numa aplicação real
e puderam ser adotadas como testes no experimento.

% http://research.cs.wisc.edu/techreports/2009/TR1648.pdf
Estratégias são normalmente avaliadas por meio de curvas de aprendizado,
que são os gráficos da medida de interesse em função da quantidade de consultas
\citep{settles2010active}.
% Figure 3 presents learning curves for the first 100 instances labeled using
% uncertainty sampling and random sampling.
% The reported results are for a logistic regression model averaged over ten folds
% using cross-validation.
O comportamento típico da curva de aprendizado ativo seguido pelas diferentes estratégias
é ilustrado na Figura \ref{curvas}
Apesar da pouca discernibilidade das curvas, a exibição delas permite notar
que elas têm a mesma forma logarítmica, com o valor kappa divergindo na medida em que novos
exemplos são consultados.
%\input plot
Se todas as bases tivessem a mesma quantidade de exemplos
e o aprendizado prosseguisse, as curvas se encontrariam novamente,
pois tendem ao desempenho passivo.

É possível observar que a curva de SVMbal se destaca negativamente,
mas comparações de curvas neste gráfico são imprecisas devido aos diferentes
pesos que as bases podem ter:
bases mais difíceis, por exemplo, tendem a ter um valor mais baixo para kappa e acabam
sub-representadas.
Uma forma de neutralização desse tipo de desigualdade entre as bases é a adoção
de ranqueamento das médias\footnote{Além das médias,
um gráfico das medianas também foi elaborado e teve um comportamento praticamente igual.
% com leves perturbações irrelevantes
Por motivos de espaço ele foi omitido.}, conforme mostrado na Figura \ref{curvasrank},
que confirma o mau desempenho de SVMbal e QBCRFw - as duas estratégias de aprendiz fixo.
%\input rankplot
Os aprendizes fixos (SVM e RFw) podem gerar consultas desfavoráveis aos outros algoritmos
empregados como classificador (5NN, C4.5w, CIELM e NB).
De forma mais ampla, pode-se esperar que estratégias gnósticas não tenham um desempenho
constante ao longo de todos os seis aprendizes em cada base.
Essa hipótese seria mais provável se as estratégias agnósticas (Rnd, Clu e ATUmah) tivessem obtido
resultados acima da média, porém Rnd e Clu que permaneceram
abaixo da colocação média ($5.5$) por praticamente todo o intervalo de consultas.
ATUmah se manteve próxima da média, porém com mais vantagem na primeira metade do orçamento.
Assim, é mais provável que a própria natureza das estratégias seja inferior para o dado conjunto de bases.
\ano{muito especulativo}

% DWeuc é a estratégia Mar ponderada pela densidade, logo, dada a superioridade de Mar,
% a ponderação por densidade pode ser considerada bastante prejudicial quando não leva em
% conta os exemplos rotulados.
% Por outro lado, as extensões de DW (TU, ATU e GATU) superam as demais, pois ponderam inversamente pela
% densidade de exemplos rotulados evitando, assim, as regiões densamente rotuladas.
SGmulti, por sua vez, se manteve estável, pouco acima da colocação média.
Um evento importante entre as melhores curvas é a inversão entre a estratégia agnóstica
ATUmah e Mar após aproximadamente $50$ exemplos.
Essa inversão coincide com a intuição de que consultas exploratórias sejam vantajosas no início do
aprendizado, enquanto que consultas prospectivas passem a ser proveitosas mais tardiamente.
Assim, estratégias como HTUmah e TUmah, capazes de combinar agnosticidade e gnosticidade,
podem ter um bom desempenho tanto no início quanto no restante da curva de aprendizado
conforme evidenciado por suas curvas.
A curva ascendente de Mar, quando vista isoladamente, também é um indicativo de que a prospecção pura
é prejudicial no início e vantajosa com o avanço do aprendizado.
Por fim, EERent mostrou-se como uma das melhores opções pela estabilidade e colocação de sua curva.

Para confirmar as conclusões com segurança estatística, os níveis de confiança
($p \in \{0,01; 0,05; 0,10\}$) na Tabela \ref{stratsALCKappaFriedAllReduxall} indicam
quando uma estratégia na linha é melhor que a outra na coluna.
O critério de vitória é baseado na comparação dos valores da kappa médio para todas as bases.
A medida foi calculada com $200$ exemplos nas bases de tamanho suficiente
e $|\mathcal{U}|$ nas demais.
% \input stratsmahALCKappaFriedAllReduxall
\begin{table}[h]
\caption{Um contra um para as estratégias (564 testes).
Medida: kappa médio. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}

\begin{center}
\scalebox{0.82}{
\begin{tabular}{lcc|cc|cc|cc|cc}
                   & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
1 - Rnd         & - &   &   &   &   &   &   &   &   &   \\
2 - Clu         & + & - &   &   &   & * &   &   &   & * \\ \hline
3 - \textbf{ATUmah}     & * &   & - &   &   & * &   &   &   & * \\
4 - \textbf{HTUmah}     & * & * & * & - & * & * &   &   &   & * \\ \hline
5 - \textbf{SGmulti}    & * &   &   &   & - & * &   &   &   & * \\
6 - QBCRFw      &   &   &   &   &   & - &   &   &   &   \\ \hline
7 - Mar         & * & * &   &   &   & * & - &   &   & * \\
8 - TUmah       & * & * & + &   & + & * &   & - &   & * \\ \hline
9 - EERent      & * & * & * &   & * & * &   &   & - & * \\
10 - SVMbal     &   &   &   &   &   &   &   &   &   & - \\ \hline
\end{tabular}
}
\quad
\scalebox{0.82}{
\begin{tabular}{lccc}
algoritmo & \makecell{primeiros\\lugares} & \makecell{derrotas\\para Rnd}  & \makecell{últimos\\lugares} \\
\hline
EERent     & \bom{280} & \bom{168} & 121 \\
\textbf{HTUmah}     & \bomd{251} & \bomd{179} & \bom{88} \\
Mar        & 235 & 187 & 161 \\
TUmah      & 233 & 200 & \bomd{119} \\
\textbf{ATUmah}     & 176 & 207 & 139 \\
\textbf{SGmulti}    & 152 & 216 & 134 \\
SVMbal     & 123 & \ruim{334} & \ruim{304} \\
QBCRFw     & 106 & 311 & 266 \\
Clu        & 103 & 227 & 164 \\
Rnd        & \ruim{71} & - & 225 \\
\end{tabular}
}
\label{stratsALCKappaFriedAllReduxall}
\end{center}
\end{table}

Como um indicativo da viabilidade do aprendizado ativo em geral, Rnd perde de todas exceto QBCRFw
e SVMbal.
Clu superou a amostragem aleatória, respeitando a garantia teórica de que não é inferior a ela.
Dentre as melhores estratégias,
a proposta HTUmah obteve vitórias maior significância estatística que sua principal contendente TUmah
e se equiparou a EERent.
Dentre as agnósticas selecionadas ATUmah é a preferível, também por superar suas contendentes
significativamente.
SGmulti obteve um desempenho próximo ao de ATUmah.

% Se forem consideradas apenas as primeiras 100 consultas -
% %150 conf/emnlp/SettlesC08
% valor arbitrário frequentemente adotado em outros trabalhos
% \citep{journals/pieee/CrawfordTY13,chermanaprendizado,conf/nips/SettlesCR07,conf/icml/RoyM01} -
% A comparação passa a ser como na Tabela \ref{stratsALCKappaFriedAllReduxHalf}.
% \input stratsmanALCKappaFriedAllReduxall
% \input stratseucALCKappaFriedAllReduxall
% conforme Tabela \ref{stratsALCKappaFriedAllReduxHalf}.
% $50$ exemplos: quantidade máxima antes que o tamanho das bases permita ALCs de tamanhos diferentes
% - conforme Tabela \ref{stratsALCKappaFriedAllRedux50}.
Em aplicações reais, entretanto, a estabilidade do algoritmo pode ser mais importante
do que o desempenho preditivo médio, pois uma grande variabilidade pode colocar o
orçamento sob o risco de ser gasto sem que seja atingido um desempenho adequado e pode levar a custos
excedentes de rotulação imprevisíveis.
Assim, a estabilidade da estratégia tem fundamental importância para a análise do risco financeiro
da aplicação. É importante enfatizar que o processo de rotulação é irreversível,
impossibilitando a experimentação de mais de uma estratégia.

De forma análoga às curvas apresentadas para o valor médio de kappa e o ranqueamento
correspondente, dois conjuntos de curvas baseadas no desvio padrão do valor de kappa foram
construídos visando ilustrar o comportamento da variância preditiva a cada instante ao longo
de sucessivos valores de orçamento.
É possível observar, na Figura \ref{curvasrankdesvio}, que as estratégias ATUmah, HTUmah,
TUmah e EERent detêm as melhores colocações no ranqueamento médio dos menores valores de desvio
padrão durante a maior parte do processo de rotulação.

%\input rankplotRisco
%\input plotRisco
O mesmo ocorre com os ranqueamentos apresentados na Figura \ref{curvasdesvio}.
Nesse gráfico, a distância entre a melhor e a pior curva se mantém em torno de $0,01$,
indicando que, embora algumas sejam mais estáveis, a faixa ocupada pelas curvas é estreita.
porém com EERent alternando com TUmah.
A curva de SGmulti ficou em torno do ranqueamento médio ($5,5$).

Uma propriedade das curvas é a tendência de estabilização durante o treinamento,
indicando que em baixos orçamentos a escolha de estratégias mais estáveis é prioritária.
A significância estatística das diferenças pode ser verificada na Tabela
\ref{stratsALCKappaFriedAllRiscoReduxall}.
\begin{table}[h]
\caption{Um contra um para as estratégias. Medida: desvio padrão do kappa médio. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}
\begin{center}
\begin{tabular}{lcc|cc|cc|cc|cc}
                                  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
1 - Rnd                        & - &   &    &   &    &   &    &    &   &   \\
2 - Clu                         &   & - &    &   &    &   &    &    &   &   \\ \hline
3 - \textbf{ATUmah}     & *& * & -  &   & * &   & * &    & * & * \\
4 - \textbf{HTUmah}     & * & * &   & - & * &   & * &  +& * & * \\ \hline
5 - \textbf{SGmulti}       &   &   &    &   & - &   &    &   &   &   \\
6 - QBCRFw                 & * & * &    &   & * & - & * &   & * & * \\ \hline
7 - Mar                        &   &   &    &   &    &   &  - &    &   &   \\
8 - TUmah                   & * & * &    &   & * &   & * &  - & *& * \\ \hline
9 - EERent                   &   & * &    &   &    &   &    &    & - &   \\
10 - SVMbal                 &   &   &    &   &    &   &    &    &   & - \\ \hline\end{tabular}
% calculado pelo R
\label{stratsALCKappaFriedAllRiscoReduxall}
\end{center}
\end{table}

Finalmente, pode-se concluir que a versão híbrida proposta (HTUmah) é superior a TUmah
para o conjunto de bases e algoritmos utilizados.
ATUmah é viável enquanto alternativa agnóstica.
SGmulti obteve um desempenho mediano,
logo ela pode ser uma candidata a viés de amostragem alternativo num sistema de recomendação.
Com relação à minimização de risco financeiro, 
novamente as estratégias propostas também se mostraram viáveis,
com HTUmah sendo a mais estável - vencendo TUmah com significância estatística.




A principal dificuldade do cenário explorado nesta seção é, possivelmente, a existência de algumas
combinações menos favoráveis entre as bases e os algoritmos selecionados.
Algumas delas são perceptíveis na Figura \ref{treebadleas}.
A árvore indica a contagem de derrotas de cada algoritmo de acordo com a medida kappa.
Pequenas reservas de exemplos ($\#\leq142,4$),
por exemplo, desfavorecem CIELM mais fortemente.
% \afterpage{\clearpage\begin{landscape}
\begin{figure}
\tikzset{
every node/.style={font=\scriptsize,black, thin},
decision/.style={shape=rectangle, minimum height=1cm, text width=1.7cm,
text centered, rounded corners=1ex, draw},
outcome/.style={ shape=rectangle, fill=red!15, draw, text width=2cm, text justified},
decision tree/.style={sibling distance=3cm, level distance=2cm},
cond/.style={blue, yshift=-2mm, shape=rectangle, text centered},
}
\begin{center}
\caption{Possíveis nichos de inadequação base-algoritmo.
\textit{Mínimo de dez exemplos por folha.}}
\begin{tikzpicture} [edge from parent/.style={->,above,draw,sloped,midway,gray!30,ultra thick},
text width=2.7cm, align=flush center, grow cyclic,
level 1/.style={level distance=3.2cm,sibling angle=45},
level 2/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 3/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 4/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 5/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
]
\input{treeLearnerKappaperd}
\label{treebadleas}
\end{tikzpicture}
\end{center}
\end{figure}
% \end{landscape}\clearpage}

% % \afterpage{\clearpage\begin{landscape}
\begin{figure}
\tikzset{
every node/.style={font=\scriptsize,black, thin},
decision/.style={shape=rectangle, minimum height=1cm, text width=1.7cm,
text centered, rounded corners=1ex, draw},
outcome/.style={ shape=rectangle, fill=red!15, draw, text width=2cm, text justified},
decision tree/.style={sibling distance=3cm, level distance=2cm},
cond/.style={blue, yshift=-2mm, shape=rectangle, text centered},
}
\begin{center}
\caption{Possíveis nichos de inadequação base-estratégia-algoritmo.
\textit{Mínimo de dez exemplos por folha.}}
\begin{tikzpicture} [edge from parent/.style={->,above,draw,sloped,midway,gray!30,ultra thick},
text width=2.7cm, align=flush center, grow cyclic,
level 1/.style={level distance=3.2cm,sibling angle=180},
level 2/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 3/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 4/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
level 5/.style={text width=2cm, font=\footnotesize, level distance=3.2cm,sibling angle=60},
]
\input{treeALCKappaperd}
\label{treegoodleas}
\end{tikzpicture}
\end{center}
\end{figure}
% % \end{landscape}\clearpage}
essa arvore acima justifica o cenario abaixo 
\subsection{Cenário com definição de algoritmo após rotulação}\label{crf}
A estratégia específica QBC perdeu de todas, exceto GATUman e Rnd,
conforme Tabela \ref{stratsALCKappaFriedRFwRedux}.
GATUman também teve um desempenho significativamente negativo.
Com o algoritmo RFw, as estratégias mais exploratórias ficaram em desvantagem,
com TUman vencendo todas, exceto Mar, que é uma estratégia puramente
prospectiva.
SGmulti, Mar e EERent também tiveram algum destaque, em oposição ao ocorrido
na comparação de estratégias com algoritmos variados.

\begin{table}[h]
\caption{Um contra um (RFw). Medida: ALCKappa. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}
\begin{center}
\scalebox{0.9}{\begin{tabular}{lcc|cc|cc|cc|c}
                        & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\
1 - Rnd         & - &   &   &   &   &   &   &   &   \\
2 - Clu         &   & - &   &   &   &   &   &   & * \\ \hline
3 - \textbf{ATUmah}     & * &   & - & * &   &   &   &   & * \\
4 - \textbf{HTUmah}    &   &   &   & - &   &   &   &   &   \\ \hline
5 - \textbf{SGmulti}    & * & * &   & * & - &   &   &   & * \\
6 - Mar         & * & * & * & * &   & - &   &   & * \\ \hline
7 - TUmah       & * & * & * & * & * &   & - & * & * \\
8 - EERent      & * & * &   & * &   &   &   & - & * \\ \hline
9 - QBC         &   &   &   &   &   &   &   &   & - \\\end{tabular}
\quad
\begin{tabular}{lccc}
algoritmo & \makecell{primeiros\\lugares} & \makecell{derrotas\\para Rnd}  & \makecell{últimos\\lugares} \\
\hline
TUmah      & \bom{50} & \bomd{13} & 2 \\
Mar        & \bomd{19} & 14 & 2 \\
ATUmah     & 9 & 18 & 5 \\
SGmulti    & 8 & \bom{8} & \bom{0} \\
EERent     & 3 & 14 & 2 \\
Rnd        & 2 & - & 24 \\
QBC        & 1 & \ruim{64} & \ruim{45} \\
HTUmah     & 1 & 48 & 13 \\
Clu        & \ruim{1} & 25 & \bomd{1} \\
\end{tabular}
}
\label{stratsALCKappaFriedRFwRedux}
\end{center}
\end{table}

\input{stratsfriedKappa}


\subsection{Comparação SVM}\label{csvm}
Diferentemente do que ocorreu com RFw, a SVM favoreceu GATUman.
EERent apareceu como a melhor opção, vencendo praticamente todas.
As estratégias específicas não tiveram tantas derrotas quanto a QBC na Seção \ref{crf}
\begin{table}[h]
\caption{Um contra um (SVM). Medida: ALCKappa. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}
\begin{center}
\scalebox{0.85}{\begin{tabular}{lcc|cc|cc|cc|cc}
                        & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
1 - Rnd         & - &   &   &   &   &   &   &   &   &   \\
2 - Clu         &   & - &   &   &   &   &   &   &   &   \\ \hline
3 - \textbf{ATUmah}     &   &   & - &   &   &   &   &   &   &   \\
4 - \textbf{HTUmah}    & * &   & . & - & * & * &   &   & * & + \\ \hline
5 - \textbf{SGmulti}    &   &   &   &   & - &   &   &   &   &   \\
6 - Mar         &   &   &   &   &   & - &   &   &   &   \\ \hline
7 - TUmah       & . &   &   &   &   &   & - &   &   &   \\
8 - EERent      & * & * & * &   & * & * & * & - & * & * \\ \hline
9 - SVMRBFbal   &   &   &   &   &   &   &   &   & - &   \\
10 - SVMRBFsim  &   &   &   &   &   &   &   &   &   & - \\ \hline\end{tabular}
\quad
\begin{tabular}{lccc}
algoritmo & \makecell{primeiros\\lugares} & \makecell{derrotas\\para Rnd}  & \makecell{últimos\\lugares} \\
\hline
EERent     & \bom{32} & \bom{19} & \bom{2} \\
SVMsim     & \bomd{17} & 48 & \ruim{23} \\
HTUmah     & 13 & \bomd{26} & 5 \\
SVMbal     & 8 & \ruim{51} & 13 \\
TUmah      & 7 & 36 & 5 \\
Clu        & 7 & 34 & 7 \\
Mar        & 4 & 44 & 18 \\
ATUmah     & 4 & 35 & 6 \\
SGmulti    & 2 & 42 & \bomd{4} \\
Rnd        & \ruim{0} & - & 11 \\
\end{tabular}
}
\label{stratsALCKappaFriedSVMRedux}
\end{center}
\end{table}


% \subsection{Comparação ELM}\label{celm}
% Similarmente ao ocorrido com a QBC, a estratégia específica da ELM (EMC)
% perdeu de todas incluindo a amostragem aleatória.
% Isso sugere que a proposta não é viável.
% Porém, segundo a comparação de classificadores da Seção \ref{algs},
% a ELM teve apenas quatro primeiros lugares dentre as $94$ bases de dados.
% É possível que a seleção de modelos via PRESS tenha influenciado negativamente
% as predições e consequentemente prejudicado a estimativa de mudança no modelo.
% TUmah, EERent e Mar venceram as três estratégias agnósticas com diferentes
% graus de significância estatística.
% SGmulti superou apenas as estratégias Rnd e Clu.
% \begin{table}[h]
% \caption{Um contra um (ELM). Medida: ALCKappa. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}
% \begin{center}\begin{tabular}{lcc|cc|cc|cc|c}
%                         & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\
% 1 - Rnd         & - &   &   &   &   &   &   &   & + \\
% 2 - Clu         &   & - &   &   &   &   &   &   & + \\ \hline
% 3 - \textbf{ATUmah}     &   &   & - &   &   &   &   &   & * \\
% 4 - \textbf{GATUmah}    &   &   &   & - &   &   &   &   & * \\ \hline
% 5 - \textbf{SGmulti}    & + & + &   &   & - &   &   &   & * \\
% 6 - Mar         & * & * & . &   &   & - &   &   & * \\ \hline
% 7 - TUmah       & * & * & + &   &   &   & - &   & * \\
% 8 - EERent      & * & * & + &   &   &   &   & - & * \\ \hline
% 9 - EMC         &   &   &   &   &   &   &   &   & - \\\end{tabular}
% \quad
% \begin{tabular}{lccc}
% algoritmo & \makecell{primeiros\\lugares} & \makecell{derrotas\\para Rnd}  & \makecell{últimos\\lugares} \\
% \hline
% TUmah      & 28 & 36 & 3 \\
% EERent     & 18 & 25 & 3 \\
% Mar        & 15 & 29 & 6 \\
% EMC        & 8 & 69 & 58 \\
% SGmulti    & 7 & 24 & 2 \\
% HTUmah     & 7 & 38 & 7 \\
% ATUmah     & 5 & 37 & 7 \\
% Clu        & 5 & 45 & 4 \\
% Rnd        & 3 & 94 & 9 \\
% \end{tabular}
% \label{stratsALCKappaFriedELMRedux}
% \end{center}
% \end{table}

\subsection{Síntese das comparações}\label{sintese}
Estratégias agnósticas têm a vantagem de dispensar o aprendiz.
Assim, elas evitam o risco de uma escolha inadequada de algoritmo de aprendizado
para um dado problema.
Consequentemente, ATUmah seria a preferível no caso de algoritmos variados.
Entretanto, os resultados dos quatro experimentos apontam para diferentes melhores
estratégias.
Apesar de ATUmah não ter sido pior que a amostragem aleatória em nenhum deles,
ela perde de Mar, TUmah e EERent em alguns casos.
Logo, se for desejado o melhor desempenho para um dado algoritmo,
então é preciso recorrer a algum procedimento que minimize a chance de
uma escolha inadequada de estratégia.
Além do algoritmo, o orçamento disponível e as características de cada base também
podem favorecer ou prejudicar certas estratégias.

Nesta seção, as estratégias são comparadas com o objetivo de identificar nichos
em que umas possam se sobressair em relação às outras.
Cada nicho corresponde a um algoritmo e um conjunto de bases de dados similares entre si.

Nas árvores exibidas nas figuras \ref{treeBest} e \ref{tree},
é possível observar o papel central do algoritmo de aprendizado sobre
a estratégia de aprendizado ativo, pois é a primeira regra em ambas as árvores.
Elas simulam dois cenários com relação à escolha do algoritmo: quando o mais adequado é conhecido
(\ref{treeBest}) e quando ele é arbitrário (\ref{tree}).
O primeiro caso resulta em $95$ metaexemplos devido a um empate,
e o segundo caso também resulta em torno de $95$ metaexemplos, porém para cada algoritmo,
totalizando $595$.
% Apesar de ilustrativa, a árvore pode não ser segura do ponto de vista de tomada de
% decisão devido ao baixo grau de pureza das folhas.
% \input arvorebest
% \input arvore
% \input arvorebestperd
% \input arvoreperd

% \ref{tree}
A amostragem aleatória aparece apenas na folha que representa o uso do 5NN nas quatro bases que têm
uma proporção de atributos nominais não muito alta (igual ou abaixo de $77$),
poucos atributos em geral (igual ou abaixo de $6$) e não muitos exemplos (igual ou abaixo de $1078$).
Assim, pode-se concluir que não optar pelo aprendizado ativo raramente é a melhor estratégia.
Num nicho similar, porém com muitos exemplos (acima de $1078$), HTUmah é a mais indicada.
ATUmah

% \ref{treeBest}
O algoritmo NB produz estimativas de distribuição de probabilidade excessivamente confiantes
que podem ser amenizadas por um \ing{comitê por amostragem}{bagging} \citep{conf/icml/RoyM01}.
Estratégias que dependem dessas estimativas podem ser prejudicadas.
ATUmah por ser agnóstica é independente dessas estimativas e aparece como nó
folha para esse algoritmo de aprendizado.
EERent também aparece e é gnóstico,
mas seu uso da soma das entropias das estimativas de
probabilidade de todos os exemplos da reserva ameniza o efeito do excesso de confiança.

% Algumas ramificações aceitam explicações plausíveis:
% \begin{itemize}
%  \item
% 
% % \esb{When Does Active Learning Work?
% % confirma que atributos não-discretizados favorecem AL,
% % isso justifica z-score para qq classificador ?
% % (ao menos RF, SVM, log reg. e QDA usados no artigo).
% % usa apenas QBC, entropia e random.
% % }
% \end{itemize}

\section{algoritmo definido após rotulação}\label{ind}
algoritmos com boa performance com poucos dados podem ter baixa
performance com muitos dados
\citep{journals/sigkdd/AttenbergP10,journals/jmlr/PerlichPS03}.


Numa aplicação real, a disponibilidade de rótulos permite uma escolha mais adequada
do algoritmo de aprendizado.
Assim, estratégias agnósticas e aquelas cujo aprendiz possa ser desvinculado da escolha do
algoritmo de aprendizado definitivo da aplicação se mostram desejáveis.
As estratégias agnósticas adiam naturalmente a escolha do algoritmo para depois da
etapa de rotulação.
Entretanto, elas são desprovidas da capacidade de prospecção advinda do víes de
aprendizado inerente a todo aprendiz.
As gnósticas, por sua vez, dependem desse viés desde o início da amostragem ativa.
Apesar disso, é possível adotar um aprendiz compatível com a estratégia e que tenha um bom
desempenho geral; depois de obtidos os rótulos, o algoritmo definitivo seria escolhido via validação
cruzada.

O experimento desta seção foi formulado para avaliar a viabilidade da independência do aprendiz
enquanto alternativa às estratégias agnósticas, simulando uma aplicação real.

A medida de desempenho (ALC-kappa) 

Nas árvores das figuras \ref{treeBestdesf} e  \ref{treedesf},
TUmah, por exemplo, pode ser entendido como uma escolha arriscada
quando o algoritmo é o 5NN ou aceita apenas atributos nominais, ou seja, requer discretização.

\esb{neste exp, a necessidade de aplicação de filtro é separada, ex.: o learner precisa,
mas não obriga o classif a usar ou viceversa;
a mesma ideia foi estendida para a relação estrat-learner, embora pudesse ter sido
feito no experimento anterior (posso aproveitar os resultados daqui lá,
mas faltaria rodar os hits que não coincidem com o bestlearner):
a estratégia precisa (maha), mas não obriga o learner a usar  ou viceversa}

\section{Tempo de espera tolerável}
\ano{para o tempo não é necessário separar por classificador; basta um fried}

\ano{EER venceu demais. no tempo ele vai perder de todas?}

Não é possível auferir tempo durante experimentos de desempenho porque eles são
paralelizados e compartilham cache de processador.

limite de espera pra usuário web é 15s, é o máximo aceitável
\citep{conf/amcis/Nah03}

% Miller (1968) argued for the 2-second rule based on the theory of limitations in human short-
% term memory. According to Miller, short-term memory plays a critical role in human information
% processing; interference with short-term memory can occur when an individual senses an awareness of
% waiting after approximately 2 seconds. Thus, to stay uninterrupted in information processing, the 2-
% second guideline is recommended. For tasks where uninterrupted focus is critical, Nielsen (1995)
% suggests that computer response should be kept within one second.
% 
% 
% From this study, we found that Web users expect a response in about 2 seconds for simple
% information retrieval tasks on the Web.
% A 2-second response is needed to ensure 'smooth' interactions
% between the WWW and the users.  The findings from this
% study also suggest that the upper bound for Web users' TWT is 15 seconds when
% the system does not provide any indication or feedback concerning
% the download

\esb{
é melhor comparar tempos minimos do que tempos medios;
pode haver outlier para cima,
mas para baixo há o limite onde todas as otimizações de hardware já
foram atingidas e a ausência de outros processos é total.
Assim, trata-se de uma grandeza mais comparável entre algoritmos. (ref?)
}

\tar{rodar um classif. rápido de treino e um
rápido de teste em todas as bases, registrar tempo médio de consulta de cada
estratégia e gerar friedman (espera-se realçar vantagem dos agnósticos)}

% 
% e uma faixa de orçamentos:
% \begin{itemize}
%  \item orçamento baixo: $|Y|<\cent\leq min(\frac{|\mathcal{U}|}{2},100)$
%  \item orçamento alto: $min(\frac{|\mathcal{U}|}{2},100)<\cent\leq min(|\mathcal{U}|,200)$
% \end{itemize}

\esb{pra provar que o algoritmo é determinante, basta demonstrar qtas vezes o melhor par contem
o mesmo algoritmo que venceu na passiva}

\ano{faz sentido testar com o melhor classif porque o user vai ter os rotulos pra poder escolher o melhor,
mas isso soh vale pra agnosticas: Rnd, Clu, ATUman, ATUmah e ATUeuc}