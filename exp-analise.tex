\section{Análise comparativa}\label{comparativa}
Há aplicações em que suas particularidades ou preferências do especialista determinam
previamente o algoritmo de aprendizado. \ano{exemplos?}
Por outro lado, há aplicações, possivelmente a maioria, em que a escolha é livre
e concretizada idealmente a partir do momento em que o conjunto de treinamento é
suficientemente grande para a realização de uma validação cruzada \ano{ref?}.
Para simular esses dois cenários de forma concisa e
devido à presença de estratégias específicas de um único tipo de aprendiz
(QBC, SVMS e SVMB),
% (QBC, EMC, SVMS e SVMB),
a comparação de estratégias está dividida em três partes:
\begin{itemize}
 \item \textbf{comparação com algoritmos variados} - compreende algoritmos não vinculados a nenhuma estratégia
 (5NN, C4.5w, CIELM e NB); incidentalmente, esse critério remove os algoritmos que aparecem
 nos extremos da contagem de posições, deixando a contagem de primeiros
e últimos lugares mais equilibrada, entre $21$ e $27$ e entre $19$ e $28$, respectivamente;
 \item \textbf{comparação RFw} - por ser um comitê, o RF viabiliza o uso da estratégia QBC;
  nessa comparação é possível avaliar a existência de benefícios em aplicá-la frente
  às estratégias de uso geral; é possível também observar quais estratégias são adequadas
  para esse algoritmo;
  \item \textbf{comparação SVM} - de forma análoga à \textit{comparação RFw},
  porém com duas estratégias específicas; e,
%   \item \textbf{comparação ELM} - de forma análoga à \textit{comparação RFw},
%   porém com o diferencial de revelar de forma pioneira a viabilidade de se aplicar
%   aprendizado ativo e a estratégia específica com ELMs.
  \end{itemize}

\subsection{Comparação diversa}\label{cdiversa}
% http://research.cs.wisc.edu/techreports/2009/TR1648.pdf
Estratégias são normalmente avaliadas por meio de curvas de aprendizado,
que são os gráficos da medida de interesse em função da quantidade de consultas
\citep{settles2010active}.
% Figure 3 presents learning curves for the first 100 instances labeled using
% uncertainty sampling and random sampling.
% The reported results are for a logistic regression model averaged over ten folds
% using cross-validation.
O comportamento típico da curva de aprendizado ativo seguido por todas as diferentes estratégias
é ilustrado na Figura \ref{curvas}
Apesar da pouca discernibilidade das curvas, a exibição delas para todas as estratégias permite notar
que elas têm a mesma forma logarítmica, com o valor kappa divergindo na medida em que novos
exemplos são consultados.
\input plot
Se todas as bases tivessem a mesma quantidade de exemplos
e o aprendizado prosseguisse, as curvas se encontrariam novamente,
pois tendem ao desempenho passivo.

É possível observar que a curva da DWeuc se destaca negativamente,
mas comparações de curvas neste gráfico são imprecisas devido aos diferentes
pesos que as bases podem ter:
bases mais difíceis tendem a ter um valor mais baixo para kappa e acabam
sub-representadas.
Uma forma de neutralização da desigualdade de nível de dificuldade entre as bases é a adoção
de ranqueamento das médias\footnote{Além das médias,
um gráfico das medianas também foi elaborado e teve um comportamento praticamente igual.
% com leves perturbações irrelevantes
Por motivos de espaço ele foi omitido.}, conforme mostrado na Figura \ref{curvasrank}.
\input rankplot
O fato de nem todas as estratégias agnósticas terem sido favorecidas sugere que a ausência
de premissas baseadas no viés do aprendiz não é condição preponderante para um bom
desempenho em algoritmos de aprendizado variados, como  Rnd e Clu que permaneceram
debaixo da colocação média ($5.5$) por praticamente todo o intervalo de consultas.

Conforme esperado, DWeuc teve o pior desempenho por concentrar as consultas apenas
nas regiões mais densas e de fronteira, deixando de explorar adequadamente o espaço de exemplos.
DWeuc é a estratégia Mar ponderada pela densidade, logo, dada a superioridade de Mar,
a ponderação por densidade pode ser considerada bastante prejudicial quando não leva em
conta os exemplos rotulados.
Por outro lado, as extensões de DW (TU, ATU e GATU) superam as demais, pois ponderam inversamente pela
densidade de exemplos rotulados evitando, assim, as regiões densamente rotuladas.
SGmulti, por sua vez, se manteve próximo à colocação média.
Um evento importante entre as melhores curvas é a inversão entre a estratégia gnóstica
TUmah e sua versão agnóstica ATUmah após aproximadamente $90$ exemplos.
Essa inversão coincide com a intuição de que consultas exploratórias sejam vantajosas no início do
aprendizado, enquanto que consultas prospectivas passem a ser proveitosas mais tardiamente.
Assim, uma estratégia como a GATUmah, capaz de migrar entre agnosticidade e gnosticidade,
pode ter um bom desempenho tanto no início quanto no restante da curva de aprendizado.
A ascensão de Mar também é um indicativo de que a prospecção é prejudicial no início
e vantajosa com o avanço do aprendizado.
A diferença entre EERacu e EERent é um indício de que atacar diretamente a função objetivo
não é tão eficaz quanto o uso da medida de entropia.
Nas análises seguintes, as estratégias DWeuc - por ser claramente superada pelas suas extensões - e
EERacu - por ser melhor representada pela proposta original da EER - foram omitidas.

Para confirmar as conclusões com segurança estatística, os níveis de confiança
($p \in \{0,01; 0,05; 0,10\}$), na Tabela \ref{stratsALCKappaFriedAllReduxall}, indicam
quando uma estratégia na linha é melhor que a outra na coluna.
O critério de vitória é baseado na comparação dos valores da ALC-kappa para todas as bases.
A medida foi calculada com $200$ exemplos nas bases de tamanho suficiente
e $|\mathcal{U}|$ nas demais.
% \input stratsmahALCKappaFriedAllReduxall
\begin{table}[h]
\caption{Um contra um para as estratégias.
Medida: ALC-kappa. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}
\begin{center}\begin{tabular}{lcc|cc|cc|cc}
                        & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8\\
1 - Rnd         & - &   &   &   &   &   &   &   \\
2 - Clu         &   & - &   &   &   &   &   &   \\ \hline
3 - \textbf{ATUmah}     & * & * & - &   & * &   &   &   \\
4 - \textbf{GATUmah}    & * & * &   & - & * & . &   &   \\ \hline
5 - \textbf{SGmulti}    & * &   &   &   & - &   &   &   \\
6 - Mar         & * & * &   &   & . & - &   &   \\ \hline
7 - TUmah       & * & * &   &   & * &   & - &   \\
8 - EERent      & * & * &   &   & * &   &   & - \\ \hline\end{tabular}
\label{stratsALCKappaFriedAllReduxall}
\end{center}
\end{table}

Como um indicativo da viabilidade do aprendizado ativo em geral, Rnd perde de todas exceto Clu.
Ainda assim, o princípio teórico de Clu, que garante um desempenho que não seja pior que a
amostragem aleatória, manteve-se válido.
Dentre as melhores estratégias, a proposta GATUmah é a preferível, pois além de se equiparar
às outras ela foi superior à Mar - ainda que com baixo nível de confiança ($p=0,10$).
SGmulti superou apenas a aleatória.

% Se forem consideradas apenas as primeiras 100 consultas -
% %150 conf/emnlp/SettlesC08
% valor arbitrário frequentemente adotado em outros trabalhos
% \citep{journals/pieee/CrawfordTY13,chermanaprendizado,conf/nips/SettlesCR07,conf/icml/RoyM01} -
% A comparação passa a ser como na Tabela \ref{stratsALCKappaFriedAllReduxHalf}.
% \input stratsmanALCKappaFriedAllReduxall
% \input stratseucALCKappaFriedAllReduxall
% conforme Tabela \ref{stratsALCKappaFriedAllReduxHalf}.
% $50$ exemplos: quantidade máxima antes que o tamanho das bases permita ALCs de tamanhos diferentes
% - conforme Tabela \ref{stratsALCKappaFriedAllRedux50}.
Em aplicações reais, entretanto, a estabilidade do algoritmo pode ser mais importante
do que o desempenho preditivo médio, pois uma grande variabilidade pode colocar o
orçamento sob o risco de ser gasto sem que seja atingido um desempenho adequado e pode levar a custos
de rotulação imprevisíveis.
Assim, a estabilidade da estratégia tem fundamental importância para a análise do risco financeiro
da aplicação. É importante enfatizar que o processo de rotulação ocorre apenas uma vez em uma
dada reserva de exemplos até o término do orçamento, impossibilitando novas tentativas.

De forma análoga às curvas apresentadas para o valor médio de kappa e o ranqueamento
correspondente, dois conjuntos de curvas baseadas no desvio padrão do valor de kappa foram
construídos visando ilustrar o comportamento da variância preditiva a cada instante ao longo
de sucessivos valores de orçamento.
É possível observar, na Figura \ref{curvasdesvio}, que as estratégias ATUmah e GATUmah
seguidas de TUmah detêm os menores valores de desvio padrão durante a maior parte do
processo de rotulação.
\input plotRisco
O mesmo ocorre com os ranqueamentos apresentados na Figura \ref{curvasrankdesvio},
porém com EERent alternando com TUmah.
\input rankplotRisco
A curva de SGmulti ficou abaixo do ranqueamento médio ($4,5$).
Uma propriedade das curvas é a clara tendência de estabilização durante o treinamento,
indicando que em baixos orçamentos a escolha de estratégias mais estáveis é prioritária.
A significância estatística das diferenças pode ser verificada na Tabela
\ref{stratsALCKappaFriedAllRiscoReduxall}.
% \input stratsmahALCKappaFriedAllRiscoReduxall
\begin{table}[h]
\caption{Um contra um para as estratégias. Medida: desvio padrão da ALC-kappa. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}
\begin{center}\begin{tabular}{lcc|cc|cc|cc}
                                 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8\\
1 - Rnd                       & - &   &   &   &   &   &   &   \\
2 - Clu                         &   & - &   &   &   &   &   &   \\ \hline
3 - \textbf{ATUmah}     & * & *  & - &   & *  & * &  & *   \\
4 - \textbf{GATUmah}    & * & * &   & - & * & * &   & * \\ \hline
5 - \textbf{SGmulti}    &   &   &   &    & - &   &   &   \\
6 - Mar                         &   &   &   &   &   & - &   &   \\ \hline
7 - TUmah                       & + & * &   &   & + & * & - & . \\
8 - EERent                      &   &   &   &   &   &   &   & - \\ \hline\end{tabular}
% calculado pelo R
\label{stratsALCKappaFriedAllRiscoReduxall}
\end{center}
\end{table}

Finalmente, pode-se concluir que, segundo o conjunto de bases e algoritmos utilizados,
as versões agnóstica e híbrida propostas (ATUmah e GATUmah) são viáveis enquanto alternativas
à TUmah, com pequena vantagem para GATUmah em acurácia quando considerada
a quantidade de estratégias estatisticamente inferiores a elas.
Com relação à minimização de risco financeiro, 
novamente as estratégias propostas também se mostraram viáveis,
vencendo as mesmas estratégias que TUmah, porém com maior significância estatística.

\subsection{Comparação RFw}\label{crf}
A estratégia específica QBC perdeu de todas, exceto GATUman e Rnd,
conforme Tabela \ref{stratsALCKappaFriedRFwRedux}.
GATUman também teve um desempenho significativamente negativo.
Com o algoritmo RFw, as estratégias mais exploratórias ficaram em desvantagem,
com TUman vencendo todas, exceto Mar, que é uma estratégia puramente
prospectiva.
SGmulti, Mar e EERent também tiveram algum destaque, em oposição ao ocorrido
na comparação de estratégias com algoritmos variados.

\begin{table}[h]
\caption{Um contra um (RFw). Medida: ALCKappa. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}
\begin{center}\begin{tabular}{lcc|cc|cc|cc|c}
                        & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\
1 - Rnd         & - &   &   &   &   &   &   &   &   \\
2 - Clu         &   & - &   &   &   &   &   &   & * \\ \hline
3 - \textbf{ATUmah}     & * &   & - & * &   &   &   &   & * \\
4 - \textbf{GATUmah}    &   &   &   & - &   &   &   &   &   \\ \hline
5 - \textbf{SGmulti}    & * & * &   & * & - &   &   &   & * \\
6 - Mar         & * & * & * & * &   & - &   &   & * \\ \hline
7 - TUmah       & * & * & * & * & * &   & - & * & * \\
8 - EERent      & * & * &   & * &   &   &   & - & * \\ \hline
9 - QBC         &   &   &   &   &   &   &   &   & - \\\end{tabular}
\label{stratsALCKappaFriedRFwRedux}
\end{center}
\end{table}


\subsection{Comparação SVM}\label{csvm}
Diferentemente do que ocorreu com RFw, a SVM favoreceu GATUman.
EERent apareceu como a melhor opção, vencendo praticamente todas.
As estratégias específicas não tiveram tantas derrotas quanto a QBC na Seção \ref{crf}
\begin{table}[h]
\caption{Um contra um (SVM). Medida: ALCKappa. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}
\begin{center}\begin{tabular}{lcc|cc|cc|cc|cc}
                        & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
1 - Rnd         & - &   &   &   &   &   &   &   &   &   \\
2 - Clu         &   & - &   &   &   &   &   &   &   &   \\ \hline
3 - \textbf{ATUmah}     &   &   & - &   &   &   &   &   &   &   \\
4 - \textbf{GATUmah}    & * &   & . & - & * & * &   &   & * & + \\ \hline
5 - \textbf{SGmulti}    &   &   &   &   & - &   &   &   &   &   \\
6 - Mar         &   &   &   &   &   & - &   &   &   &   \\ \hline
7 - TUmah       & . &   &   &   &   &   & - &   &   &   \\
8 - EERent      & * & * & * &   & * & * & * & - & * & * \\ \hline
9 - SVMRBFbal   &   &   &   &   &   &   &   &   & - &   \\
10 - SVMRBFsim  &   &   &   &   &   &   &   &   &   & - \\ \hline\end{tabular}
\label{stratsALCKappaFriedSVMRedux}
\end{center}
\end{table}


% \subsection{Comparação ELM}\label{celm}
% Similarmente ao ocorrido com a QBC, a estratégia específica da ELM (EMC)
% perdeu de todas incluindo a amostragem aleatória.
% Isso sugere que a proposta não é viável.
% Porém, segundo a comparação de classificadores da Seção \ref{algs},
% a ELM teve apenas quatro primeiros lugares dentre as $94$ bases de dados.
% É possível que a seleção de modelos via PRESS tenha influenciado negativamente
% as predições e consequentemente prejudicado a estimativa de mudança no modelo.
% TUmah, EERent e Mar venceram as três estratégias agnósticas com diferentes
% graus de significância estatística.
% SGmulti superou apenas as estratégias Rnd e Clu.
% \begin{table}[h]
% \caption{Um contra um (ELM). Medida: ALCKappa. \textit{Legenda na Tabela \ref{tab:friedClassif}.}}
% \begin{center}\begin{tabular}{lcc|cc|cc|cc|c}
%                         & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\
% 1 - Rnd         & - &   &   &   &   &   &   &   & + \\
% 2 - Clu         &   & - &   &   &   &   &   &   & + \\ \hline
% 3 - \textbf{ATUmah}     &   &   & - &   &   &   &   &   & * \\
% 4 - \textbf{GATUmah}    &   &   &   & - &   &   &   &   & * \\ \hline
% 5 - \textbf{SGmulti}    & + & + &   &   & - &   &   &   & * \\
% 6 - Mar         & * & * & . &   &   & - &   &   & * \\ \hline
% 7 - TUmah       & * & * & + &   &   &   & - &   & * \\
% 8 - EERent      & * & * & + &   &   &   &   & - & * \\ \hline
% 9 - EMC         &   &   &   &   &   &   &   &   & - \\\end{tabular}
% \label{stratsALCKappaFriedELMRedux}
% \end{center}
% \end{table}

\subsection{Síntese das comparações}\label{sintese}
Estratégias agnósticas têm a vantagem de dispensar o aprendiz.
Assim, elas evitam o risco de uma escolha inadequada de algoritmo de aprendizado
para um dado problema.
Consequentemente, ATUmah seria a preferível no caso de algoritmos variados.
Entretanto, os resultados dos quatro experimentos apontam para diferentes melhores
estratégias.
Apesar de ATUmah não ter sido pior que a amostragem aleatória em nenhum deles,
ela perde de Mar, TUmah e EERent em alguns casos.
Logo, se for desejado o melhor desempenho para um dado algoritmo,
então é preciso recorrer a algum procedimento que minimize a chance de
uma escolha inadequada de estratégia.
Além do algoritmo, o orçamento disponível e as características de cada base também
podem favorecer ou prejudicar certas estratégias.

Nesta seção, as estratégias são comparadas com o objetivo de identificar nichos
em que umas possam se sobressair em relação às outras.
Cada nicho corresponde a um algoritmo e um conjunto de bases de dados similares entre si.

Nas árvores exibidas nas figuras \ref{treeBest} e \ref{tree},
é possível observar o papel central do algoritmo de aprendizado sobre
a estratégia de aprendizado ativo, pois é a primeira regra em ambas as árvores.
Elas simulam dois cenários com relação à escolha do algoritmo: quando o mais adequado é conhecido
(\ref{treeBest}) e quando ele é arbitrário (\ref{tree}).
O primeiro caso resulta em $95$ metaexemplos devido a um empate,
e o segundo caso também resulta em torno de $95$ metaexemplos, porém para cada algoritmo,
totalizando $595$.
% Apesar de ilustrativa, a árvore pode não ser segura do ponto de vista de tomada de
% decisão devido ao baixo grau de pureza das folhas.
\input arvorebest
\input arvore

\ref{tree}
A amostragem aleatória aparece apenas na folha que representa o uso do 5NN nas quatro bases que têm
uma proporção de atributos nominais não muito alta (igual ou abaixo de $77$),
poucos atributos em geral (igual ou abaixo de $6$) e não muitos exemplos (igual ou abaixo de $1078$).
Assim, pode-se concluir que não optar pelo aprendizado ativo raramente é a melhor estratégia.
Num nicho similar, porém com muitos exemplos (acima de $1078$), HTUmah é a mais indicada.
ATUmah

\ref{treeBest}
O algoritmo NB produz estimativas de distribuição de probabilidade excessivamente confiantes
que podem ser amenizadas por um \ing{comitê por amostragem}{bagging} \citep{conf/icml/RoyM01}.
Estratégias que dependem dessas estimativas podem ser prejudicadas.
ATUmah por ser agnóstica é independente dessas estimativas e aparece como nó
folha para esse algoritmo de aprendizado.
EERent também aparece e é gnóstico,
mas seu uso da soma das entropias das estimativas de
probabilidade de todos os exemplos da reserva ameniza o efeito do excesso de confiança.

% Algumas ramificações aceitam explicações plausíveis:
% \begin{itemize}
%  \item
% 
% % \esb{When Does Active Learning Work?
% % confirma que atributos não-discretizados favorecem AL,
% % isso justifica z-score para qq classificador ?
% % (ao menos RF, SVM, log reg. e QDA usados no artigo).
% % usa apenas QBC, entropia e random.
% % }
% \end{itemize}




\section{Tempo de espera tolerável}
\ano{para o tempo não é necessário separar por classificador; basta um fried}

Não é possível auferir tempo durante experimentos de desempenho porque eles são
paralelizados e compartilham cache de processador.

limite de espera pra usuário web é 15s, é o máximo aceitável
\citep{conf/amcis/Nah03}

% Miller (1968) argued for the 2-second rule based on the theory of limitations in human short-
% term memory. According to Miller, short-term memory plays a critical role in human information
% processing; interference with short-term memory can occur when an individual senses an awareness of
% waiting after approximately 2 seconds. Thus, to stay uninterrupted in information processing, the 2-
% second guideline is recommended. For tasks where uninterrupted focus is critical, Nielsen (1995)
% suggests that computer response should be kept within one second.
% 
% 
% From this study, we found that Web users expect a response in about 2 seconds for simple
% information retrieval tasks on the Web.
% A 2-second response is needed to ensure 'smooth' interactions
% between the WWW and the users.  The findings from this
% study also suggest that the upper bound for Web users' TWT is 15 seconds when
% the system does not provide any indication or feedback concerning
% the download

\esb{
é melhor comparar tempos minimos do que tempos medios;
pode haver outlier para cima,
mas para baixo há o limite onde todas as otimizações de hardware já
foram atingidas e a ausência de outros processos é total.
Assim, trata-se de uma grandeza mais comparável entre algoritmos. (ref?)
}

\tar{rodar um classif. rápido de treino e um
rápido de teste em todas as bases, registrar tempo médio de consulta de cada
estratégia e gerar friedman (espera-se realçar vantagem dos agnósticos)}

% 
% e uma faixa de orçamentos:
% \begin{itemize}
%  \item orçamento baixo: $|Y|<\cent\leq min(\frac{|\mathcal{U}|}{2},100)$
%  \item orçamento alto: $min(\frac{|\mathcal{U}|}{2},100)<\cent\leq min(|\mathcal{U}|,200)$
% \end{itemize}
