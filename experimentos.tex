%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experimentos e Resultados}\label{experimentos}
Neste capítulo são apresentados os experimentos comparativos de estratégias
e seus resultados.
\ano{descrever cada seção?}

\section{Preparação} \label{prep}
Devido à grande quantidade de fatores envolvidos nos experimentos,
faz-se necessária uma etapa de preparação em que apenas
a parcela mais representativa das estratégias seja mantida e
a diversidade dos algoritmos de aprendizado escolhidos seja verificada.

\subsection{Diversidade dos algoritmos de aprendizado}\label{algs}
Uma forma de ilustrar a diversidade entre os modelos gerados
pelos diferentes algoritmos de aprendizado é por meio da similaridade
entre suas acurácias.
Ela é apresentada na Tabela \ref{passiveDists} de forma análoga à adotada por
\cite{brazdil1994analysis}.
\input passiveDists
% Brazdil faz tabela de distâncias pareadas com taxas de erro sendo
% as dimensões, depois faz decomposição ortogonal para visualizar em duas dimensões.
% Depois ele faz agrupamento hierárquico.
Esses modelos são o resultado de treinamento passivo, ou seja, com todos os
exemplos da reserva.
Considerando-se cada base de dados uma dimensão,
a similaridade é calculada a partir da distância euclidiana $d(\bm{x},\bm{u})$
entre dois vetores $\bm{x},\bm{u} \in \mathbb{R}^{94}$
de valores de acurácia balanceada (Seção \ref{metricas}) de acordo com a mesma fórmula
(Equação \ref{eq:sim}) adotada no cálculo de densidade da Seção \ref{dw}.
As acurácias para cada base são apresentadas nas tabelas \ref{tab:balaccClassif0},
\ref{tab:balaccClassif1} e \ref{tab:balaccClassif2} do Apêndice \ref{detalhes}.
% BalAcc escolhida, e não Kappa, porque brazdil usou taxas de erro.

O algoritmo mais distinto é a SVM, pois apresenta os menores valores em relação a
todos os demais (abaixo ou igual a $0,30$).
Por outro lado, conforme esperado,
a maior similaridade ($0,77$) ocorre entre IELM e CIELM.
\ano{conjugar no presente ou passado?}
Os próximos valores mais relevantes (acima de $0,50$) permitem separar os demais classificadores
em dois grupos, A e B, respectivamente:
5NN, C4.5 e RF; e, VFDT e NB.
\ano{usar essses grupos no futuro além do trecho mais abaixo?}
\ano{se terminar de rodar, é preciso adicionar passiveNintera na tab de dists,
na fried e nas 3 tabelas do apendice  (e atualizar texto)}

Na comparação um contra um da acurácia balanceada (Tabela \ref{tab:friedClassif}),
RF vence todos os demais com significância estatística,
provavelmente por se tratar de um \textit{ensemble}.
C4.5 e 5NN também se destacam, em menor grau,
seguidos de NB e VFDT.
Esse destaque reforça a tabela de similaridade (Tabela \ref{passiveDists}),
pois os melhores classificadores (grupo A) são similares e os piores
(IELM/CIELM e SVM) têm a menor similaridade em relação aos demais.
Apesar disso, a existência de grupos distintos e de classificadores com variados níveis
de desempenho fornece uma diversidade mais representativa do que se
apenas um único classificador fosse empregado arbitrariamente.
Para aumentar a independência entre os classificadores nos experimentos,
optou-se por descartar os resultados referentes à IELM,
por ser inferior à CIELM (Apêndice \ref{detalhes})
e ambas possuírem uma proximidade excessiva com relação a princípio de funcionamento
e desempenho.

\input classifsFried



\subsection{Descarte de estratégias redundantes}
Dentre as estratégias implementadas da literatura e propostas,
é esperada a ocorrência de respostas correlacionadas
para o conjunto de bases de dados escolhido.
Assim, por motivos de espaço e facilitação das análises posteriores,
estratégias muito similares foram removidas.
Com essa finalidade,
analogamente à comparação na Seção \ref{algs},
as similaridades entre estratégias foram calculadas
por meio da distância $d(\bm{x},\bm{u}) \mid \bm{x},\bm{u} \in \mathbb{R}^{658}$
entre acurácias balanceadas ao longo das $94$
bases e $6$
\ano{adicionar RF aos numeros acima, abaixo e tabela}
classificadores e são apresentadas na Tabela \ref{stratDists}.
Os nomes de estratégias propostas estão em negrito.

\afterpage{\clearpage\begin{landscape}
\input stratDists
\end{landscape}\clearpage}

As estratégias que embutem algum tipo de aleatoriedade
(Rnd, Clu, EERent, EERacu e SGmulti)
têm um grau de similaridade acima da média (valor de $0,67$ para as duas agnósticas e
entre $0,44$ e $0,58$ para as restantes), mas foram mantidas pela diversidade de
princípios de funcionamento.
Uma similaridade maior pode ser notada entre as variantes das estratégias
baseadas em densidade.
As seis propostas baseadas na \textit{utilidade de cada classe} (prefixos LU e ALU)
apresentam uma similaridade aproximada de $0,7$ em relação aos seus
algoritmos originais correspondentes (prefixos TU e ATU).
Por esse motivo e pela correspondência direta entre as medidas de acurácia
listadas nas tabelas do Apêndice \ref{detalhes},
optou-se por excluí-las dos experimentos.
As estratégias remanescentes baseadas na distância euclidiana
(TUeuc e ATUeuc) também foram excluídas
por serem, de acordo com a Tabela \ref{stratDists},
excessivamente similares às baseadas na distância de Manhattan.
A distância euclidiana foi preterida porque as distâncias de Manhattan e de Mahalanobis
em conjunto provêem mais diversidade ao experimento pela adequação a atributos nominais
da primeira e pela independência de escala da segunda.
Rnd e Clu foram mantidas por serem abordagens importantes na literatura.
Dentre as estratégias baseadas em simples medida de informatividade
(Unc, Ent e Mar), apenas Mar foi mantida devido à similaridade entre
as três, por ser mais adequada a problemas multiclasse que Unc e por
seu desempenho ser superior ao da Ent.

O grupo reduzido de estratégias é apresentado na Tabela \ref{stratDistsRedux}.
É possível notar nas duas tabelas que a adoção da distância de Mahalanobis
(últimas colunas/linhas da tabela) confere o maior grau de diversidade dentre todas as estratégias.
Apesar dessa particularidade e do alto desempenho reportado na próxima seção (\ref{analise}),
não é do conhecimento do autor a existência de trabalhos que empreguem essa
medida de distância.

\newpage
\input stratDistsRedux

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input exp-analise



\green{manter apenas estratégias que ganharam em algum momento/nicho?}
\blue{assim é possível o avaliar estratégias num cenário em que se sabe de
antemão qual é o melhor learner.
manter todas as combinações learner-dataset serve para o cenário em que
nada se sabe do dataset, ou seja, é o mais esperado,
pois normalmente é preciso ter rótulos suficientes para se testar classificadores;
além disso, quando se conhece o melhor classificador
(a não ser por propriedades dos dados:
ex.: nominal->NB, muitos atributos->SVM etc.)
é por meio de um problema parecido onde as estratégias podem ser testadas}

\blue{plotar (log?) rnd (e clu?) p/ nb,c45 e 5nn até o fim do pool ou
até atingir passiva, assim
serve de panorama do qto as outras estrategias/learners
atingiram da ALC possivel)}

\green{rodar eeg-eye-state pra medir tempo nas principais estrategias/learners,
pra ser a unica base usando nintera (nintera come memória);
rodar como todas as outras, mas em 1x10-fold}
\red{o tempo ficou sempre abaixo de 1s, então está dentro do tolerable
waiting time.
Suponho que a demora do experimento se deva à inicialização das strats
e não às consultas propriamente ditas.}

\subsubsection{Afinidade estratégia-aprendiz, estratégia-budget e outros nichos}

\ano{A primeira árvore é aplicada a todos os datasets; ele servirá apenas para dar algum insight
sobre o motivo de cada afinidade existir (desbalanceamento, agrupamentos, tipos e qtd de atts etc.).
Não serve para ML, pois os atributos e o
claffisifcador devem ser interpretáveis e haverá atributos com informação ``desleal''
da distribuição de classes}

\ano{possiveis atts: proporção da minor., da maj.; entropia* ou medida melhor para medir o grau de desbalanço}

* -> normalized entropy \citep{journals/bioinformatics/LewinSA0P04}:
ajuda a saber que estratégias são boas p/ bases desbalanceadas.

----------

\green{árvore do vencedor accbal e variancia}

\green{árvore do perdedor accbal e variancia (considerar empates? = uma árvore por estrat.?)}

\subsubsection{Comparativo}
\green{friedmenyi de  accbal e variancia}

\green{plotar accBal X budgets p/ cada uma das 15 bases com menos de
200 exemplos?}

\green{plotar p/ accBal (apenas nas 85 bases com mais de
200 exemplos?)): \#topos-de-rank X budgets $[10;200]$
Dois tipos de \#topos-de-rank:
com empate = \#vezes em que ficou entre os vencedores
sem empate = \#vezes em que foi o vencedor}
