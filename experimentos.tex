%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experimento preliminar}\label{sec:exppre}
Um experimento preliminar \citep{conf/hais/SantosC14} foi conduzido visando
a construção de um panorama geral do desempenho das diversas estratégias
diante de variadas bases de dados.
Devido à forte dependência que as estratégias gnósticas têm de seus
modelos internos de classificação, diferentes algoritmos de aprendizado
precisam ser adotados quando alguma comparação entre elas é
pretendida.
Dessa forma, quatro algoritmos comumente usados foram adotados
\citep{books/mk/Quinlan93,conf/ecml/Lewis98,conf/kdd/DomingosH00,journals/tit/Hart68}:
J48\footnote{Implementação do Weka baseada no algoritmo de
árvore de decisão C4.5.}, NB\footnote{\textit{Naive Bayes}},
VFDT \footnote{Very Fast Decision Trees} e
5-NN\footnote{Cinco vizinhos mais próximos.}.

\ano{enumerar bases de dados usadas aqui; referenciar seção}

\subsection{Resultado preliminar}\label{sec:respre}
\ano{é interessante apresentar os resultados preliminares aqui,
pois fizeram parte da definição da metodologia;
assim evita separar exppre de respre e o expprincipal encerra esse capitulo e
jah emenda o inicio do outro com seus resultados}



\subsection{Experimentos}\label{sec:ferramentas}
\ano{para evitar separar as subdescricoes do experimento de seus subresultados,
essa seção apenas dá um overview explicando o porquê da escolha de cada
experimento:
... árvore ...
fazer para cada learner uma tabela de intersecções de metaexemplos
(obviamente com empates);
AG,LU vs DWTU;
metaap pra decidir entre AG, LU ou TU}

\ano{explicar pela arvore quais os nichos de cada estrategia}

\ano{usar clustering para mostrar que estrategias se adequam a nichos parecidos
(a arvore do agrupamento hierarquico pode ilustrar bem isso,
só falta descobrir como fazer o weka imprimir os nomes das strats,
provavelm é colocando um atributo string.)}

\ano{como a predição da melhor não vence a majoritaria preciso usar ranking
(ainda posso testar algumas variações, como fixar
cada um dos learners possíveis)}

 \tar{usar nintera na(s) base(s) à parte?
 ou usar em todas, mas sem strats lentas?}

 \tar{plotar}



\green{baseline p/ AccBal é $1/|Y|$}

\green{manter apenas estratégias que ganharam em algum momento/nicho?}

\blue{assim é possível o avaliar estratégias num cenário em que se sabe de
antemão qual é o melhor learner.
manter todas as combinações learner-dataset serve para o cenário em que
nada se sabe do dataset, ou seja, é o mais esperado,
pois normalmente é preciso ter rótulos suficientes para se testar classificadores;
além disso, quando se conhece o melhor classificador
(a não ser por propriedades dos dados:
ex.: nominal->NB, muitos atributos->SVM etc.)
é por meio de um problema parecido onde as estratégias podem ser testadas}

\blue{plotar (log?) rnd (e clu?) p/ nb,c45 e 5nn até o fim do pool ou
até atingir passiva, assim
serve de panorama do qto as outras estrategias/learners
atingiram da ALC possivel)}

\green{rodar eeg-eye-state pra medir tempo nas principais estrategias/learners,
pra ser a unica base usando nintera (nintera come memória);
rodar como todas as outras, mas em 1x10-fold}
\red{o tempo ficou sempre abaixo de 1s, então está dentro do tolerable
waiting time.
Suponho que a demora do experimento se deva à inicialização das strats
e não às consultas propriamente ditas.}

\subsubsection{Afinidade estratégia-aprendiz, estratégia-budget e outros nichos}

\ano{A primeira árvore é aplicada a todos os datasets; ele servirá apenas para dar algum insight
sobre o motivo de cada afinidade existir (desbalanceamento, agrupamentos, tipos e qtd de atts etc.).
Não serve para ML, pois os atributos e o
claffisifcador devem ser interpretáveis e haverá atributos com informação ``desleal''
da distribuição de classes}

\ano{possiveis atts: proporção da minor., da maj.; entropia* ou medida melhor para medir o grau de desbalanço}

* -> normalized entropy \citep{journals/bioinformatics/LewinSA0P04}:
ajuda a saber que estratégias são boas p/ bases desbalanceadas.

----------

\green{árvore do vencedor accbal e variancia}

\green{árvore do perdedor accbal e variancia (considerar empates? = uma árvore por estrat.?)}

\subsubsection{Comparativo}
\green{friedmenyi de  accbal e variancia}

\green{plotar accBal X budgets p/ cada uma das 15 bases com menos de
200 exemplos?}

\green{plotar p/ accBal (apenas nas 85 bases com mais de
200 exemplos?)): \#topos-de-rank X budgets $[10;200]$
Dois tipos de \#topos-de-rank:
com empate = \#vezes em que ficou entre os vencedores
sem empate = \#vezes em que foi o vencedor}

\subsubsection{Aprendizado meta-ativo}
\ano{ainda é preciso ver se ranking supera ranking medio (default)}

\ano{possibilidades: um experimento para cada learner separadamente;
sortear budget no exp acima;
sortear learners num experimento só;}

