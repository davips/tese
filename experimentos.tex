%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experimentos e Resultados}\label{experimentos}
Neste capítulo são apresentados os experimentos comparativos de estratégias
e seus resultados.
Na Seção \ref{prep}, é definido o subconjunto de estratégias mais relevantes
para os experimentos.
Nas demais seções é feita a demonstração de que as estratégias propostas SGmulti e
agnóstica baseada em densidade (prefixo ATU) são competitivas.
Adicionalmente, constatações relevantes para o problema da escolha de estratégias
são fornecidas.
A análise experimental é dividida em duas partes: \ano{rever}
\textit{geral}, na Seção \ref{geral}, em que as estratégias são comparadas
ao longo de todas as \ano{$xxxx$} combinações de aprendizes e estratégias;
e, \textit{por aprendiz},
na Seção \ref{isolado},
onde a comparação é feita para cada aprendiz separadamente.

\section{Preparação} \label{prep}
Devido à grande quantidade de fatores envolvidos nos experimentos,
faz-se necessária uma etapa de preparação em que apenas
a parcela mais representativa das estratégias e algoritmos de aprendizado
seja mantida.

\subsection{Diversidade dos algoritmos de aprendizado}\label{algs}
Uma forma indireta de ilustrar a diversidade entre os modelos gerados pelos diferentes algoritmos
de aprendizado é por meio da similaridade entre suas acurácias.
Ela é apresentada na Tabela \ref{passiveDists} de forma análoga à adotada por
\cite{brazdil1994analysis}.
\input passiveDists
% Brazdil faz tabela de distâncias pareadas com taxas de erro sendo
% as dimensões, depois faz decomposição ortogonal para visualizar em duas dimensões.
% Depois ele faz agrupamento hierárquico.
Esses modelos são o resultado de treinamento passivo, ou seja, com todos os
exemplos da reserva.
Considerando-se cada base de dados uma dimensão,
a similaridade é calculada a partir da distância euclidiana $d(\bm{x},\bm{u})$
entre dois vetores $\bm{x},\bm{u} \in \mathbb{R}^{94}$
de valores de acurácia balanceada (Seção \ref{metricas}) de acordo com a mesma fórmula
(Equação \ref{eq:sim}) adotada no cálculo de densidade da Seção \ref{dw}.
As acurácias para cada base são apresentadas nas tabelas \ref{tab:balaccClassif0},
\ref{tab:balaccClassif1} e \ref{tab:balaccClassif2} do Apêndice \ref{detalhes}.
% BalAcc escolhida, e não Kappa, porque brazdil usou taxas de erro
% (que é mais comparável com acuracia do que kappa).

% Apesar de passiva, essa é a acurácia com treinamento incremental, desde
% |Y| um a um até |U| para VFDT; talvez por isso o desempenho tenha sido pior
O algoritmo mais distinto é a VFDT, pois apresenta os menores valores em relação a
praticamente todos os demais.
Isso é explicado pelo seu desempenho excessivamente inferior,
ficando, por exemplo, em último lugar trinta vezes e em primeiro apenas seis
(Apêndice \ref{detalhes}).
VFDT teve o pior desempenho possivelmente por ser o único algoritmo incremental do conjunto
e originalmente ter sido proposto para grandes quantidades de exemplos desde o primeiro
treinamento. A acurácia passiva foi obtida após o treinamento incremental desde
$|Y|$ até $|\mathcal{U}|$ exemplos, simulando o progresso de um aprendizado interativo.
Devido a essa inadequação do cenário ao algoritmo, optou-se por excluí-lo dos
experimentos.

A maior similaridade ($0,64$) ocorre entre ELM e CIELM conforme esperado.
Os próximos maiores valores por linha permitem separar os demais algoritmos
em dois grupos, A e B, respectivamente:
5NN, RFw e SVM; e, C4.5w e NB.
O primeiro grupo coincide com os algoritmos mais presentes no primeiro lugar
conforme Tabela \ref{tab:friedClassif}.


Na comparação um contra um da acurácia balanceada (Tabela \ref{tab:friedClassif}),
RF vence todos os demais com significância estatística,
provavelmente por se tratar de um \textit{ensemble}.
C4.5 e 5NN também se destacam, em menor grau,
seguidos de NB e VFDT.
Esse destaque reforça a tabela de similaridade (Tabela \ref{passiveDists}),
pois os melhores algoritmos (grupo A) são similares e os piores
(IELM/CIELM e SVM) têm a menor similaridade em relação aos demais.
Apesar disso, a existência de grupos distintos e de algoritmos com variados níveis
de desempenho fornece uma diversidade mais representativa do que se
apenas um único algoritmo fosse empregado arbitrariamente.
Para aumentar a independência entre os algoritmos nos experimentos,
optou-se por descartar os resultados referentes à IELM,
por ser inferior à CIELM (Apêndice \ref{detalhes})
e ambas possuírem uma proximidade excessiva com relação a princípio de funcionamento
e desempenho.

\ano{mudar para medir distancia apenas das passivas}

% \input classifsFried
\begin{table}[h]
\caption{\textbf{Um contra um e contagem de posições}.
Medida: acurácia balanceada.
\textit{Cada asterisco/cruz/ponto indica quando o algoritmo na linha tem melhor
desempenho que o algoritmo na coluna com intervalo de confiança de 0.99/0.95/0.90.}}
\begin{center}
\begin{tabular}{lcc|cc|cc|cc}
                        & 1 & 2 & 3 & 4 & 5 & 6 & 7\\
1 - 5NN         & - &   &   &   &   &   &   \\
2 - C4.5w       &   & - &   &   &   &   &   \\ \hline
3 - CIELM       &   &   & - &   &   &   &   \\
4 - ELM         &   &   &   & - &   &   &   \\ \hline
5 - NB          &   &   &   &   & - &   &   \\
6 - RFw         & * & * & * & * & * & - &   \\ \hline
7 - SVM         & + & + &   & * & + &   & - \\\end{tabular}
\quad
\begin{tabular}{lcc}
algoritmo & \makecell{primeiros\\lugares} & \makecell{últimos\\lugares} \\
\hline
RFw        &    20       &              3       \\
SVM        &    20       &              8       \\
5NN        &    16       &              21      \\
NB         &    14       &              23      \\
CIELM      &    12       &              9       \\
C4.5w      &    10       &              13      \\
ELM        &    4        &              16      \\
\label{tab:friedClassif}
\end{tabular}
\end{center}
\end{table}


\subsection{Diversidade de estratégias}
Dentre as estratégias implementadas da literatura e propostas,
é esperada a ocorrência de respostas correlacionadas
para o conjunto de bases de dados escolhido.
Assim, por motivos de espaço e facilitação das análises posteriores,
estratégias muito similares foram removidas.
Com essa finalidade,
analogamente à comparação na Seção \ref{algs},
as similaridades entre estratégias foram calculadas
por meio da distância $d(\bm{x},\bm{u}) \mid \bm{x},\bm{u} \in \mathbb{R}^{658}$
entre acurácias balanceadas ao longo das $94$
bases e $6$
\ano{adicionar RF aos numeros acima, abaixo e tabela}
algoritmos e são apresentadas na Tabela \ref{stratDists}.
Os nomes de estratégias propostas estão em negrito.

\afterpage{\clearpage\begin{landscape}
\input stratDists
\end{landscape}\clearpage}

As estratégias que embutem algum tipo de aleatoriedade
(Rnd, Clu, EERent, EERacu e SGmulti)
têm um grau de similaridade acima da média (valor de $0,67$ para as duas agnósticas e
entre $0,44$ e $0,58$ para as restantes), mas foram mantidas pela diversidade de
princípios de funcionamento.
Uma similaridade maior pode ser notada entre as variantes das estratégias
baseadas em densidade.
As seis propostas baseadas na \textit{utilidade de cada classe} (prefixos LU e ALU)
apresentam uma similaridade aproximada de $0,7$ em relação aos seus
algoritmos originais correspondentes (prefixos TU e ATU).
Por esse motivo e pela correspondência direta entre as medidas de acurácia
listadas nas tabelas do Apêndice \ref{detalhes},
optou-se por excluí-las dos experimentos.
As estratégias remanescentes baseadas na distância euclidiana
(TUeuc e ATUeuc) também foram excluídas
por serem, de acordo com a Tabela \ref{stratDists},
excessivamente similares às baseadas na distância de Manhattan.
A distância euclidiana foi preterida porque as distâncias de Manhattan e de Mahalanobis
em conjunto provêem mais diversidade ao experimento pela adequação a atributos nominais
da primeira e pela independência de escala da segunda.
Rnd e Clu foram mantidas por serem abordagens importantes na literatura.
Dentre as estratégias baseadas em simples medida de informatividade
(Unc, Ent e Mar), apenas Mar foi mantida devido à similaridade entre
as três, por ser mais adequada a problemas multiclasse que Unc e por
seu desempenho ser superior ao da Ent.

O grupo reduzido de estratégias é apresentado na Tabela \ref{stratDistsRedux}.
É possível notar nas duas tabelas que a adoção da distância de Mahalanobis
(últimas colunas/linhas da tabela) confere o maior grau de diversidade dentre todas as estratégias.
Apesar dessa particularidade e do alto desempenho reportado na próxima seção (\ref{analise}),
não é do conhecimento do autor a existência de trabalhos que empreguem essa
medida de distância.

\ano{encurtar caption das duas tabelas}

\newpage
\input stratDistsRedux

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input exp-analise



\green{manter apenas estratégias que ganharam em algum momento/nicho?}
\blue{assim é possível o avaliar estratégias num cenário em que se sabe de
antemão qual é o melhor learner.
manter todas as combinações learner-dataset serve para o cenário em que
nada se sabe do dataset, ou seja, é o mais esperado,
pois normalmente é preciso ter rótulos suficientes para se testar classificadores;
além disso, quando se conhece o melhor classificador
(a não ser por propriedades dos dados:
ex.: nominal->NB, muitos atributos->SVM etc.)
é por meio de um problema parecido onde as estratégias podem ser testadas}

\blue{plotar (log?) rnd (e clu?) p/ nb,c45 e 5nn até o fim do pool ou
até atingir passiva, assim
serve de panorama do qto as outras estrategias/learners
atingiram da ALC possivel)}

\green{rodar eeg-eye-state pra medir tempo nas principais estrategias/learners,
pra ser a unica base usando nintera (nintera come memória);
rodar como todas as outras, mas em 1x10-fold}
\red{o tempo ficou sempre abaixo de 1s, então está dentro do tolerable
waiting time.
Suponho que a demora do experimento se deva à inicialização das strats
e não às consultas propriamente ditas.}

\subsubsection{Afinidade estratégia-aprendiz, estratégia-budget e outros nichos}

\ano{A primeira árvore é aplicada a todos os datasets; ele servirá apenas para dar algum insight
sobre o motivo de cada afinidade existir (desbalanceamento, agrupamentos, tipos e qtd de atts etc.).
Não serve para ML, pois os atributos e o
claffisifcador devem ser interpretáveis e haverá atributos com informação ``desleal''
da distribuição de classes}

\ano{possiveis atts: proporção da minor., da maj.; entropia* ou medida melhor para medir o grau de desbalanço}

* -> normalized entropy \citep{journals/bioinformatics/LewinSA0P04}:
ajuda a saber que estratégias são boas p/ bases desbalanceadas.

----------

\green{árvore do vencedor accbal e variancia}

\green{árvore do perdedor accbal e variancia (considerar empates? = uma árvore por estrat.?)}

\subsubsection{Comparativo}
\green{friedmenyi de  accbal e variancia}

\green{plotar accBal X budgets p/ cada uma das 15 bases com menos de
200 exemplos?}

\green{plotar p/ accBal (apenas nas 85 bases com mais de
200 exemplos?)): \#topos-de-rank X budgets $[10;200]$
Dois tipos de \#topos-de-rank:
com empate = \#vezes em que ficou entre os vencedores
sem empate = \#vezes em que foi o vencedor}
