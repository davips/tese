%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experimentos e Resultados}\label{experimentos}
Neste capítulo são apresentados os experimentos comparativos de estratégias
e seus resultados.
\ano{descrever cada seção?}

\section{Preparação} \label{prep}
Devido à grande quantidade de fatores envolvidos nos experimentos,
faz-se necessária uma etapa de preparação em que apenas
a parcela mais representativa das estratégias seja mantida e
a diversidade dos algoritmos de aprendizado escolhidos seja verificada.

\subsection{Diversidade dos algoritmos de aprendizado}\label{algs}
Uma forma de ilustrar a diversidade entre os modelos gerados
pelos diferentes algoritmos de aprendizado é por meio da similaridade
entre suas acurácias.
Ela é apresentada na Tabela \ref{passiveDists} de forma análoga à adotada por
\cite{brazdil1994analysis}.
\input passiveDists
% Brazdil faz tabela de distâncias pareadas com taxas de erro sendo
% as dimensões, depois faz decomposição ortogonal para visualizar em duas dimensões.
% Depois ele faz agrupamento hierárquico.

Esses modelos são o resultado de treinamento passivo, ou seja, com todos os
exemplos da reserva.
Considerando-se cada base de dados uma dimensão,
a similaridade é calculada a partir da distância euclidiana $d(\bm{x},\bm{u})$
entre dois vetores $\bm{x},\bm{u} \in \mathbb{R}^{94}$
de valores de acurácia balanceada (Seção \ref{metricas}) de acordo com a mesma fórmula
(Equação \ref{eq:sim}) adotada no cálculo de densidade da Seção \ref{dw}.
As acurácias para cada base são apresentadas nas tabelas \ref{tab:balaccClassif0},
\ref{tab:balaccClassif1} e \ref{tab:balaccClassif2} do Apêndice \ref{detalhes}.
% BalAcc escolhida, e não Kappa, porque brazdil usou taxas de erro.

Conforme esperado,
a maior similaridade ($0,77$) ocorre entre IELM e CIELM.
Outros valores relevantes são as proximidades entre VFDT e NB ($0,56$)
e entre 5NN e C4.5 ($0,52$).
O algoritmo mais distinto é a SVM, pois apresenta os menores valores em relação a
todos os demais (entre $0,28$ e $0,30$).
% - com exceção do acerto majoritário que se afasta dos demais por ser muito inferior em quase todas as bases.
Dessa forma, uma definição de quatro grupos pode ser útil durante a análise
da influência do classificador nas estratégias de aprendizado ativo:
IELM-CIELM, VFDT-NB, 5NN-C4.5 e SVM.
Pela proximidade excessiva entre IELM e CIELM, pela acurácia superior da CIELM
e visando reduzir a quantidade necessária de análises,
optou-se por manter, dentre as duas, apenas a CIELM nos experimentos.

\ano{se terminar de rodar, é preciso adicionar passiveNintera na tab de dists/fried,
nas 3 tabelas do apendice  (e atualizar texto)}
Na comparação um contra um (Tabela \ref{tab:friedClassif})
SVM e 5NN se destacam com significância estatística,
seguidos de NB e CIELM.

\input classifsFried

Por outro lado, os três pares citados de algoritmos, apesar de similares,
são estatisticamente diferentes:
5NN vence C4.5, NB vence VFDT e CIELM vence IELM.
Isso significa que, apesar de cada par ser composto de algoritmos próximos entre si,
ainda assim trata-se de algoritmos com resposta às
bases de dados adotadas significativamente distinta.


\subsection{Descarte de estratégias redundantes}
Dentre as estratégias implementadas e propostas,
é esperada a ocorrência de respostas fortemente correlacionadas
para o conjunto de bases de dados escolhido.
Por motivos de espaço e facilitação das análises posteriores,
estratégias muito similares foram removidas.
Com essa finalidade, as similaridades entre estratégias foram calculadas
por meio da distância $d(\bm{x},\bm{u}) \mid \bm{x},\bm{u} \in \mathbb{R}^{658}$
entre acurácias balanceadas ao longo das $94$
bases e $7$ classificadores e são apresentadas na Tabela \ref{stratDists}.

\afterpage{\clearpage\begin{landscape}
\input stratDists
\end{landscape}\clearpage}

As estratégias que embutem algum tipo de aleatoriedade
(Rnd, Clu, EERent, EERacu e SGmulti)
têm um grau de similaridade acima da média (valor de $0,67$ para as duas agnósticas e
entre $0,44$ e $0,58$ para as restantes), mas foram mantidas pela diversidade de
princípios de funcionamento.
Uma similaridade maior pode ser notada entre as variantes das estratégias
baseadas em densidade.
As três propostas gnósticas baseadas na \textit{utilidade de cada classe} (prefixo LU)
apresentam uma similaridade aproximada de $0,7$ em relação aos seus
algoritmos originais correspondentes (prefixos TU).
Por esse motivo e pela correspondência direta entre as medidas de acurácia
listadas nas tabelas do Apêndice \ref{detalhes},
optou-se por excluir dos experimentos
as propostas gnósticas baseadas na utilidade de cada classe.
As estratégias remanescentes baseadas na distância euclidiana
(TUeuc, ATUeuc e ALUeuc) também foram excluídas
por serem excessivamente similares às demais.
Adicionalmente, a distância de Manhattan em conjunto com a de Mahalanobis provêem
mais diversidade ao experimento pela adequação a atributos nominais da primeira
e pela independência de escala da segunda.
Rnd e Clu foram mantidas por serem abordagens importantes na literatura.

Dentre as estratégias baseadas em simples medida de informatividade
(Unc, Ent e Mar), apenas Mar foi mantida devido à similaridade entre
as três, por ser mais adequada a problemas multiclasse que Unc e por
seu desempenho ser superior ao da Ent.
O grupo reduzido de estratégias é apresentado na Tabela \ref{stratDistsRedux}.

\newpage
\input stratDistsRedux

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input exp-analise



\green{manter apenas estratégias que ganharam em algum momento/nicho?}
\blue{assim é possível o avaliar estratégias num cenário em que se sabe de
antemão qual é o melhor learner.
manter todas as combinações learner-dataset serve para o cenário em que
nada se sabe do dataset, ou seja, é o mais esperado,
pois normalmente é preciso ter rótulos suficientes para se testar classificadores;
além disso, quando se conhece o melhor classificador
(a não ser por propriedades dos dados:
ex.: nominal->NB, muitos atributos->SVM etc.)
é por meio de um problema parecido onde as estratégias podem ser testadas}

\blue{plotar (log?) rnd (e clu?) p/ nb,c45 e 5nn até o fim do pool ou
até atingir passiva, assim
serve de panorama do qto as outras estrategias/learners
atingiram da ALC possivel)}

\green{rodar eeg-eye-state pra medir tempo nas principais estrategias/learners,
pra ser a unica base usando nintera (nintera come memória);
rodar como todas as outras, mas em 1x10-fold}
\red{o tempo ficou sempre abaixo de 1s, então está dentro do tolerable
waiting time.
Suponho que a demora do experimento se deva à inicialização das strats
e não às consultas propriamente ditas.}

\subsubsection{Afinidade estratégia-aprendiz, estratégia-budget e outros nichos}

\ano{A primeira árvore é aplicada a todos os datasets; ele servirá apenas para dar algum insight
sobre o motivo de cada afinidade existir (desbalanceamento, agrupamentos, tipos e qtd de atts etc.).
Não serve para ML, pois os atributos e o
claffisifcador devem ser interpretáveis e haverá atributos com informação ``desleal''
da distribuição de classes}

\ano{possiveis atts: proporção da minor., da maj.; entropia* ou medida melhor para medir o grau de desbalanço}

* -> normalized entropy \citep{journals/bioinformatics/LewinSA0P04}:
ajuda a saber que estratégias são boas p/ bases desbalanceadas.

----------

\green{árvore do vencedor accbal e variancia}

\green{árvore do perdedor accbal e variancia (considerar empates? = uma árvore por estrat.?)}

\subsubsection{Comparativo}
\green{friedmenyi de  accbal e variancia}

\green{plotar accBal X budgets p/ cada uma das 15 bases com menos de
200 exemplos?}

\green{plotar p/ accBal (apenas nas 85 bases com mais de
200 exemplos?)): \#topos-de-rank X budgets $[10;200]$
Dois tipos de \#topos-de-rank:
com empate = \#vezes em que ficou entre os vencedores
sem empate = \#vezes em que foi o vencedor}
