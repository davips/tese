\newpage
\section{Máquinas Extremas}\label{elmorig}
As \ing{\elms}{Extreme Learning Machines} (ELMs) são redes - não
necessariamente neurais - com treinamento diferenciado que têm recebido crescente
atenção devido à sua simplicidade e performance, comparável com o estado da arte
\citep{journals/tsmc/HuangZDZ12}.
Trata-se de um algoritmo adequado para aprendizado ativo porque
seu ajuste de parâmetros pode ser simplificado de uma forma que não ocorre
com outros algoritmos similares em complexidade
(com a capacidade de aproximação universal)
e nichos de aplicação como a máquina
de vetores de suporte e o Perceptron multicamadas \citep{haykin2004comprehensive}.
Esse último requer, por exemplo, algum critério de parada no treinamento e um processo
de seleção de modelo que envolve o ajuste de topologia e parâmetros.
Essa característica da ELM permite um rápido treinamento,
algo necessário num ambiente interativo.
O motivo para a baixa necessidade ou ausência de iterações de ajuste é explicado a seguir.
% \citep{journals/tsmc/HuangZDZ12} 

Fixado o tipo de nó como o neurônio artificial convencional, seus parâmetros a ajustar são os
valores e quantidade de neurônios/conexões sinápticas da camada oculta.
Dada uma função geradora de pesos aleatórios ou pseudoaleatórios incluída sua semente geradora e
adotada a restrição de sempre se manter os pesos na ordem em que são
gerados\footnote{Do contrário, cada peso deveria ser interpretado como um parâmetro independente.},
a quantidade de
neurônios $L$ na camada oculta pode ser vista como o único parâmetro a se ajustar.
Embora possa ser otimizado, esse parâmetro frequentemente não é crítico
\citep{conf/esann/FrenayV10}.
Essa possível não-criticidade torna a ELM, dentro das restrições apresentadas,
capaz de aprender num passo único e rápido quando comparada a outros algoritmos similares
\citep{journals/tsmc/HuangZDZ12}.

% descrever ELM básica
Uma ELM é uma rede com uma única camada oculta que transmite os sinais apenas na direção
entrada-saída (SLFN\footnote{\textit{Single Hidden Layer Feedforward Network}}),
cujos nós podem ser neurais (aditivo logístico sigmoidal) - como neste trabalho -
ou de diversos outros tipos, como as também frequentemente usadas funções de base radial
\citep{journals/tsmc/HuangZDZ12}.
\ano{relembrar leitor da notação sobre classificação apresentada anteriormente na tese?}
A função preditiva de uma SLFN com $L$ neurônios ocultos pode ser representada como segue:
\begin{equation} \label{eqelm}
f(\bm{x}_{(t)})= \argmax_{\bm{y} \in Y}{\displaystyle\mathop{\sum} _{l=1}^{L}\beta_{l,c(\bm{y})}
g(\bm{a}_l \bm{x}_{(t)} + b_l)} = \bm{y}_{(t)}
\end{equation}
% }, \quad j=1, \cdots, {\it N}.

onde $\beta_{l,o}$ é o peso da sinapse que conecta o neurônio oculto $l$ ao neurônio de saída $o$;
$c(\bm{z})$ é uma função auxiliar que retorna o índice correspondente à classe
representado pelo vetor $\bm{z} \in Y$;
$g$ é, neste trabalho, a função sigmoide logística;
$\bm{a}_l$ é o vetor de pesos do neurônio $l$ com cada valor $a_i$ representando o peso entre a
entrada $i$ e o neurônio $l$ e, sendo o produto interno deste neurônio uma equação de reta no
espaço de parâmetros, $b_l$ é o valor de seu viés de deslocamento em relação à origem.
Mais detalhes da formulação da primeira camada oculta podem ser consultados na literatura sobre o
Perceptron multicamadas convencional \citep{haykin2004comprehensive}.
Se $\beta$ for adotada como uma matriz, a equação \ref{eqelm} pode ser escrita compactamente da
forma:
\begin{equation} \label{eq2}
H \beta = T
\end{equation}

onde $H$ é a \ing{matriz de saídas da camada oculta}{hidden layer output matrix} da SLFN,
ou seja, cada coluna corresponde à saída de um neurônio oculto e cada linha corresponde a um
exemplo do conjunto de treinamento;
$\beta$ é a matriz contendo os pesos que conectam a camada oculta à camada de saída, ou seja, cada
coluna corresponde a um neurônio de saída e cada linha corresponde a um neurônio oculto;
e $T$ é a matriz objetivo, que contém em cada linha a
representação binária $\bm{y}$ da classe de cada exemplo.
Calcular $\beta$, que é análogo a treinar a rede,
pode ser feito por meio do cálculo da pseudoinversa $H^{\dagger}$ de $H$
\citep{rao1971generalized}:
\begin{equation} \label{eq3}
\beta = H^{\dagger} T
\end{equation}
Essa abordagem tem a vantagem de ser também uma minimização da norma dos pesos -
propriedade importante que reduz a possibilidade de sobreajustamento \citep{journals/tit/Bartlett98}.
Uma vez calculada a pseudoinversa,
novos exemplos podem alimentar a entrada da rede e gerar predições conforme a função $f$
presente na Equação \ref{eqelm}.

Para buscar a melhor topologia, é possível estimar o erro de generalização por meio do cálculo da
\textit{soma dos quadrados dos erros de predição} - PRESS\footnote{\textit{PREdiction Sum of Squares}}
\citep{myers2000classical,allan1974relationship}.

\tar {é necessario apresentar extensão multiclasse do press que precisei desenvolver embora seja trivial}

\ano{pegar papéis com fórmulas do press? A fórmula via EM-ELM mais abaixo deve ser suficiente.}

\cite{journals/ijon/HeeswijkMOL11} recalcula a pseudoinversa a cada novo neurônio
acrescentado até encontrar a topologia com a menor PRESS.
Eles implementaram uma ELM específica para \ing{unidades de processamento gráfico}
{Graphics Processing Unit} (GPU).
No presente trabalho, exceto para SGmulti, os conjuntos de treinamento não passam de $200$ exemplos,
não justificando o uso de GPU, especialmente em vista o custo de envio de dados para ela.
Outra diferença é a opção pelo crescimento incremental da
\ing{\elm por minimização do erro}{Error Minimized Extreme Learning Machine} -
EM-ELM \citep{journals/tnn/FengHLG09}.
Além de permitir o crescimento da rede sem recalcular a pseudoinversa,
a EM-ELM permite o cálculo da PRESS a um custo reduzido.

% \ano{PRESS: erro estatistico (de regressão?)}
% 
% \ano{quadrado do resíduo: erro I e CI?}
% 
% diferencia 'statistical error' e 'residual':
% 
% {http://en.wikipedia.org/wiki/Errors\_and\_residuals\_in\_statistics}
% 
% error (or disturbance) of an observed value is the deviation of the observed value from
% the (unobservable) true function value
% residual of an observed value is the difference between the observed value and the
% estimated function value.

\subsection{EM-ELM} \label{emelm}
\ano{falta colocar as fórmulas da EM-ELM}

\tar{colocar fórmula que obtém PRESS da EM-ELM}

\subsection{OS-ELM}\label{oselm}
Em sistemas interativos, frequentemente é adotado o esquema incremental de aprendizado.
O tempo de treinamento é reduzido quando é possível aproveitar o resultado de cálculos
prévios durante todo o processo.
No caso da ELM, isso é possível por meio da
\ing{\elm sequencial}{On-line Sequential Extreme Learning Machine} (OS-ELM)
proposta por \cite{conf/iastedCI/HuangLRSS05}.
A técnica é baseada no algoritmo dos mínimos quadrados recursivo
que utiliza a fórmula de Sherman-Morrison-Woodbury
% http://books.google.com.br/books?hl=en&lr=&id=iD5s0iKXHP8C&oi=fnd&pg=PT15&dq=+An+introduction+to+optimization&ots=3PqthZAq8d&sig=Befcr8te239chWT6UOVyVrMIkSo#v=snippet&q=recursive%20least&f=false
\citep{chong2013introduction}.
$H$ passa a ser considerada em função do tempo - indicado subscrito
para melhor legibilidade: $H_{(t)}$.
Para ser possível encontrar a solução dos mínimos quadrados de
$H_{(0)} \beta_{(0)} = T_{(0)}$,
que se refere ao conjunto inicial de dados rotulados (instante $t=0$),
a pseudoinversa esquerda $H^\dagger_{(0)}$ deve ser calculada por:

\begin{equation} \label{eq4}
P_{(0)}=(H^\top_{(0)}H_{(0)})^{-1}
\end{equation}
\begin{equation} \label{eq5}
H^{\dagger}_{(0)} = P_{(0)}H^\top_{(0)}
\end{equation}

Assim, é possível realizar um treinamento inicial da rede.
Para os lotes de dados subsequentes, ou seja,
quando $t>0$, apenas $\beta_{(t)}$ e $P_{(t)}$ precisam ser mantidos, onde:

\begin{equation} \label{eq6}
P_{(t)} = P_{(t-1)} - P_{(t-1)} H^{\top}_{(t)} (I + H_{(t)} P_{(t-1)} H^{\top}_{(t)})^{-1} H_{(t)}
P_{(t-1)}
\end{equation}
\begin{equation} \label{eq7}
\beta_{(t)} = \beta_{(t-1)} + P_{(t)} H^{\top}_{(t)} (T_{(t)} - H_{(t)} \beta_{(t-1)})
\end{equation}

O cálculo incremental de $\beta_{(t)}$ e $P_{(t)}$ evita os custos de se recalcular a
pseudoinversa para cada novo lote de dados.



\subsection{I-ELM}\label{ielm}
Apesar da vantagem do cálculo da pseudoinversa ser uma etapa única no
aprendizado da ELM, trata-se de um cálculo que pode ser custoso.
Uma alternativa é a \elm \textit{incremental} (I-ELM) proposta por
\cite{journals/tnn/HuangCS06}.
O aprendizado da I-ELM começa com um neurônio e
progride com a adição de novos neurônios, um a um.
O valor do peso é calculado de forma a reduzir o erro entre o
valor predito e o valor esperado.
Cada neurônio adicionado na iteração $t$ requer um novo peso $\beta_{1,t}$
para conectá-lo ao neurônio de saída.
Assumindo, por simplicidade, apenas um atributo preditivo,
a matriz alvo $T$ se torna um \textit{vetor coluna}, representado aqui por $\bm{\tau}$.
Sendo $\bm{h}_{(t)}$ o vetor de valores da função de ativação do novo neurônio,
ou seja, com os valores da coluna $t$ de $H$,
o valor do peso é calculado segundo a Equação \ref{eq:ielm}.
\begin{equation}\label{eq:ielm0}
\bm{e}_{(0)} = \bm{\tau}
\end{equation}
\begin{equation}\label{eq:ielm}
\beta_{1,t}=\frac{\bm{e}_{(t-1)}\cdot \bm{h}_{(t)}}
{\bm{h}_{(t)}\cdot \bm{h}_{(t)}}
\end{equation}
Onde $\bm{e}_{(t)}$ é o vetor de erros residuais antes da inserção do
novo neurônio na iteração $t$.
Todos os vetores têm cada uma de suas componentes associadas a um dos exemplos do conjunto de treinamento.
A predição da classe de novos exemplos se dá da mesma forma que na ELM original.

\subsection{CI-ELM}
Uma proposta similar à I-ELM, chamada \textit{convexa incremental} (CI-ELM),
opta pelo reajuste de todos os pesos da camada de saída a cada novo neurônio
acrescentado \citep{journals/ijon/HuangC07}.
Diferentemente da I-ELM, ela é baseada na otimização convexa de Barron
\citep{journals/tit/Barron93}, mas mantém a capacidade de redução do erro
treinamento de forma monotônica até qualquer valor arbitrariamente pequeno.
Ela é capaz de atingir uma convergência maior que a I-ELM
para um mesmo número de iterações.
Assim, dada uma meta de erro, a CI-ELM possibilita a indução de redes mais compactas.

Para cada novo neurônio, seu peso é calculado de forma análoga à apresentada na
Seção \ref{ielm}, porém os valores de saída do novo neurônio representados por
$\bm{h}_{(t)}$ são substituídos pela diferença $\bm{d}_{(t)}$
entre o erro corrente e o erro devido ao novo neurônio,
conforme equações \ref{eq:cielm} e \ref{eq:cielm2}.
\begin{equation}\label{eq:cielm}
\bm{d}_{(t)}=\bm{e}_{(t-1)} - (\bm{\tau} - \bm{h}_{(t)})
\end{equation}
\begin{equation}\label{eq:cielm2}
\beta_{1,t}=\frac{\bm{e}_{(t-1)}\cdot \bm{d}_{(t)}}
{\bm{d}_{(t)}\cdot \bm{d}_{(t)}}
\end{equation}
% Onde $T$ é o vetor alvo, ou seja, contém os valores do atributo preditivo.
A etapa adicional de reajuste é feita para todo o conjunto de pesos anteriormente
acrescentados ($\{\beta_i \mid 1 \leq i < t\}$)
de acordo com a Equação \ref{reajuste}.
\begin{equation}\label{reajuste}
\beta_{1,i}^* = (1 - \beta_{1,t}) \cdot \beta_{1,i}
\end{equation}
Assim como na I-ELM, a CI-ELM realiza as predições por meio da fórmula da Equação \ref{eqelm}.


\ano{citar as outras ELMs que crescem ou aprendem incrementalmente?}
% Além da OS-ELM, outras variantes da ELM têm sido propostas:
% ROS-ELM, que evita matrizes mal-condicionadas por meio do ajuste dos vieses $b_i$ \cite
% {conf/isnn/HoangHVW07};
% EI-ELM ou EM-ELM, não-incrementais, que fazem a rede crescer \textit{congelando}
% \citep{huang2008enhanced} ou \textit{atualizando} \citep{journals/tnn/FengHLG09}
% nós antigos;
% e, CEOS-ELM, que faz a rede crescer durante o aprendizado \textit{on-line} \citep{conf/ijcnn/LanSH09}.
%
% Para o presente trabalho, a OS-ELM ``canônica'' foi adotada, pois cada variante tem seus próprias
% vicissitudes e o propósito deste trabalho é apenas dar uma primeira impressão a respeito da
% performance da ELM com diferentes estratégias.
% Também é importante lembrar que, na presença de uma matriz $H_{(0)}$ mal-condicionada,
% OS-ELM não converge para ELM.

\tar{Citar von Zuben e outros brasileiros}