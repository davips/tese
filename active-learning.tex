\section{Aprendizado Ativo} \label{aprendizado-ativo}
\ing{Aprendizado ativo}{Active learning} é o estudo de máquinas
de aprendizado capazes de se aprimorar fazendo perguntas \citep{series/synthesis/2012Settles}.
A origem do termo remete à Pedagogia, especificamente à forma de ensino centrada no aluno.
A ideia básica é aproveitar a individualidade de cada aluno e seu próprio ritmo de aprendizado.
Assim, ele pode ser auxiliado pelo professor nos aspectos em que experimenta maior dificuldade.
Esse tipo ativo de aprendizado humano - com foco no aluno - tem mostrado evidências
de sua eficácia \citep{michael2006s}.
Analogamente, guardadas as devidas proporções,
pode-se traçar um paralelo com o aprendizado de máquina:
um algoritmo pode usufruir de uma atenção seletiva que
priorize os exemplos mais difíceis para ele em um dado momento.

Em sua forma mais geral, como esboçado por \cite{forman2012programmer},
o aprendizado de máquina ativo pode lançar mão de todo conhecimento que um professor
humano seja capaz de transmitir dentro das limitações de configurabilidade do sistema.
Alguns pontos de configuração seriam, por exemplo:
reescrita do código\footnote{Código escrito na linguagem de
programação que implementa o sistema ou em alguma linguagem específica do domínio.}
de extração de atributos visando maior separabilidade entre as
 classes; composição de expressões regulares para extrair termos adequados de textos técnicos;
e, criação de regras de classificação.
Outras informações, mais diretamente obteníveis do supervisor humano incluiriam
 valores de atributos, classes associadas com atributos, exemplos completos sob demanda e outros.
Em linhas gerais, sua aquisição deve ser guiada por duas noções
 \citep{krishnapuram2011cost}:
preferir aquela para a qual o estado corrente do modelo é incerto e
preferir aquela estimada como a mais relevante.

Dentre as perguntas que as máquinas de aprendizado ativo são capazes de
elaborar, a mais direta é ``\textit{Qual é a classe do exemplo $\bm{x}$?}''.
Dado que a obtenção de um rótulo confiável normalmente é um processo custoso,
o problema de se decidir qual seria o melhor $\bm{x}$ é a
motivação basilar desta tese.
Adicionalmente,
a quantidade de exemplos disponíveis pode ser abundante e o esforço humano disponível limitado -
do professor, no caso da analogia com o aprendizado humano.
Dessa forma, apenas uma parcela criteriosamente escolhida dos exemplos deve
ser rotulada, ou \textit{consultada}, na terminologia de aprendizado ativo.
Essa abordagem se dá em oposição ao
\ing{aprendizado por exemplos}{learning by example} convencional
\citep{journals/cacm/Valiant84}, também chamado de \novo{passivo}.
No aprendizado passivo,
procura-se pelo maior conjunto de treinamento possível ou realiza-se
uma amostragem aleatória.
No primeiro caso, o custo de rotulação pode se tornar proibitivo; no segundo caso,
a decisão quanto à relevância dos exemplos é deixada ao acaso.
Em ambos os casos, dependendo da aplicação,
a construção do conjunto de treinamento pode ser crítica.
Por exemplo, quando a consulta de um exemplo envolve reações químicas
destrutivas, é desejável fazer o mínimo possível de consultas visando um reduzido
custo material.
Similarmente, se o mecanismo rotulador, normalmente chamado de \novo{oráculo},
for um especialista humano ou mesmo um robô \citep{journals/etai/BryantMOKRK01},
é desejável parcimônia nas consultas para não se incorrer num esforço elevado de
atenção humana ou movimento mecânico.
Assim, um direcionamento adequado do esforço de aprendizado tem como resultado um
processo de rotulação mais econômico.
A variedade de abordagens existentes para esse direcionamento é assunto da
Seção \ref{estrategias}.
A notação necessária é definida na Seção \ref{notacao}

\input notacao

\section{Estratégias de consulta}\label{estrategias}
Na literatura de aprendizado ativo há diversos sub-casos, cenários e estratégias.
O sub-caso e o cenário de aprendizado ativo mais comuns na literatura,
e onde se situa a presente tese, são a busca por rótulos e
o cenário baseado em \pool, respectivamente - os
cenários alternativos são apresentados no Apêndice \ref{cenarios}.
No caso das estratégias,
elas são frequentemente baseadas em diferentes concepções de relevância de
exemplos ou mesmo diferentes teorias do aprendizado.
A amostragem por incerteza,
por exemplo, assume que os exemplos e seus rótulos pertencem a uma
distribuição de probabilidades;
% - em linha com a teoria do aprendizado estatístico \citep{books/daglib/0097035};
a amostragem por busca no espaço de hipóteses, por sua vez, assume a existência
de hipóteses integrantes de um \ing{\versionspace}{version space} \citep{books/daglib/0087929}
que enquadram ou não cada exemplo.
Estratégias agnósticas \citep{journals/jcss/BalcanBL09}, por outro lado,
são independentes de algoritmo de aprendizado.
Essa diversidade de embasamentos configura-se praticamente como um conjunto de paradigmas
de amostragem ativa cujos principais representantes são apresentados nas
seções seguintes juntamente com suas principais características e seus princípios de funcionamento.
Na apresentação das ordens de complexidade, é assumido que todos os cálculos
possíveis de serem feitos antes do processo de amostragem já foram realizados
e seus resultados estão disponíveis em memória.
Essa premissa se baseia no cenário especificado na Seção \ref{cenario}.
Ele garante a disponibilidade de todos os exemplos antes do início da amostragem.
Dessa forma apenas o custo computacional entre consultas se configura como potencial
custo financeiro porque consome o tempo do oráculo.

\tar{há mais alguma adaptação para adotar algum learn ou strat}





% Retomando na Figura \ref{fig:fronteira-vs-aleatoria} o exemplo de espaço de atributos de duas dimensões do Capítulo \ref{cap:intro}, é possível observar o efeito esperado do aprendizado ativo: apenas os exemplos mais difíceis são consultados - aqueles mais próximos da fronteira de decisão.
% \begin{figure}
% \begin{center}
% \begin{tikzpicture}
% \begin{axis}[axis y line=left, xmin=20, xmax=72, ymin=1.45, ymax=1.9, axis x line=bottom, grid, xlabel=peso (kg),   ylabel=altura (m),
% legend style={at={(1.3,1)}},]
%
% \addplot[only marks,mark=text,text mark=\C{$+$},mark options={blue,scale=1}] plot coordinates {(47.5,1.62) (50,1.5) (55.1,1.52) (63.2,1.58) (60.2,1.71) (67,1.73) (59,1.51)};\addlegendentry{positivo}
%
% \addplot[only marks,mark=text,text mark=\Q{$-$},mark options={red,scale=1}] plot coordinates {(30,1.60) (25,1.47) (26.55,1.85) (23,1.64) (24,1.7) (31,1.69) (32,1.76) (50,1.78)(33,1.53)}; \addlegendentry{negativo}
%
% \addplot[thick, only marks,mark=text,text mark=\C{\phantom{\Q{$-$}}},mark options={black, scale=1.1}] plot coordinates {(59,1.51) (50,1.78)}; \addlegendentry{consultados}
%
% \addplot[thick, mark=none, teal] plot coordinates {(20,1.5) (70,1.7)}; \addlegendentry{fronteira}
%
% \addplot[thick, dashed, only marks,mark=text,text mark=\C{\phantom{\Q{$-$}}},mark options={black, scale=1.1}] plot coordinates {(47.5,1.62) (33,1.53)}; \addlegendentry{a consultar}
%
% \addplot[thick, mark=none, teal, dashed] plot coordinates {(34,1.45) (59,1.9)}; \addlegendentry{futura fronteira}
% \end{axis}
% \end{tikzpicture}
% \caption{A consulta de exemplos de fronteira tende a ser mais proveitosa do que a amostragem aleatória. [os rótulos dos exemplos não consultados são desconhecidos, mas são mostrados para fins ilustrativos]}
% \label{fig:fronteira-vs-aleatoria}
% \end{center}
% \end{figure}


% \begin{algorithm}
% \caption{Seleção do classificador com melhor acurácia recente.}
% \label{alg:sbe}
% \Entrada{
% \begin{itemize}
%  \item um fluxo de dados $D$ de exemplos;
%  \item um tamanho de amostra $w$ para a medida de acurácia;
%  \item uma lista $C$ de classificadores;
%  \item um par de funções $treina(c,\langle x,y \rangle)$ e $testa(c,\langle x,y \rangle): \langle C,\langle X,Y \rangle \rangle \rightarrow \{1=acerto,0=erro\}$ aplicáveis a um classificador $c$ dado um par exemplo/rótulo $\langle x,y \rangle$;
% \item uma lista vazia $C_{selecionados}$ de classificadores.
% \end{itemize}
% }
% \Resultado{
% \begin{itemize}
%  \item a lista $C_{selecionados}$ de classificadores preenchida.
% \end{itemize}
% }
% % $C_{selected} \leftarrow \emptyset$
% $B \leftarrow \emptyset$
%
% \lParaCada{$c \in C$} {
%     $A(c) \leftarrow \emptyset$
% }
%
% \ParaCada{$\langle x,y \rangle \in D$}{
%     \lParaCada{$c \in C$}{
%         $treina(c,\langle x,y \rangle)$
%     }
%
%     $B \leftarrow \langle x,y \rangle \cup B$
%
%     \Se{$|B| > w$}{
%         $B \leftarrow B - ultimo(B)$
%
%         \lParaCada{$c \in C$}{
%             $A(c) \leftarrow A(c) - ultimo[A(c)]$
%         }
%     }
%     \lParaCada{$c \in C$, $\langle x_{ts},y_{ts} \rangle \in B$}{
%         $A(c) \leftarrow testa(c,\langle x_{ts},y_{ts} \rangle) \cup A(c)$
%     }
%     $C_{selected} \leftarrow \argmax_c\{   \displaystyle\sum\limits_{}^{}A(c)\}$
% }
% \end{algorithm}
%
% Uma consequência imediata é a menor necessidade de \textit{consultas} ao mecanismo rotulador e, possivelmente, uma maior acurácia.
% Dessa maneira, o aprendizado ativo é indicado nas situações em que o processo de rotulação é custoso em termos de tempo ou de recursos físicos.
% Isso é desejável quando existe uma \textbf{cota}\footnote{[\textit{budget}]}: somente uma parcela do conjunto pode ser rotulada, ela normalmente é definida como um percentual do total de exemplos disponíveis.
%
%
%
%
%
%
% É possível observar na Figura \ref{fig:ap-ativo} um esquema de aprendizado ativo.
% \begin{figure} %[H]
%     \centering
%     \input{imagens/aprendizado-ativo-esquema.tex}
%     \caption{Esquema de aprendizado ativo: as consultas ao oráculo dependem da estratégia adotada e da medida de informatividade $m(\bm{x})$ em que ela se baseia. [um modelo probabilístico é dado como exemplo de classificador base]}
%     \label{fig:ap-ativo}
% \end{figure}
% Cada exemplo $\bm{x}$ é obtido do conjunto de dados não rotulados
% $\mathcal{U}$ e apresentado a um modelo $\theta$ que seja probabilístico, que gere saídas similares diretamente proporcionais a probabilidades ou que forneça alguma outra maneira de se estimar seu grau de confiança.
% Com base no grau de confiança, é possível calcular a medida de informatividade de cada exemplo.
% Esse grau de confiança permite o cálculo da medida de \textit{informatividade}.
%
% A medida de \textbf{informatividade} $m(\bm{x})$ é a base da tomada de decisão da estratégia de consulta e pode ser implementada de diversas maneiras conforme explicado na Seção \ref{sec:isolada}.
% Uma vez definida a medida de informatividade, uma estratégia de consulta precisa ser definida; diferentes estratégias são estudadas na Seção \ref{sec:estrategias}.



\green{apontar parâmetros escolhidos neste trabalho para as estratégias,
quando houver}

\subsection{Amostragem aleatória}
A amostragem aleatória corresponde ao aprendizado passivo aplicado a apenas
uma parte dos exemplos.
Não há uma ordem de preferência ou critério para a realização das
consultas - apenas a aleatoriedade.
Suas principais características são: ser totalmente exploratória, ou seja,
não enfoca nenhuma região especial do espaço de exemplos; e,
ser agnóstica, pois não requer um aprendiz.
Seu custo computacional pode ser considerado nulo.

\subsection{Amostragem por incerteza}\label{unc}
% least confident
Provavelmente a mais simples medida de informatividade
% $Inf(\bm{x})$
para se decidir quando selecionar um exemplo $\bm{x}$
(ou grupo de exemplos, na proposta original) é a máxima probabilidade a posteriori
dada por um modelo probabilístico \citep{journals/sigir/Lewis95a}:
\begin{equation}
P_{max}(\bm{x})=\max_{\bm{y}\in Y}P(\bm{y}|\bm{x})
\end{equation}
Classificadores não probabilísticos e com saídas numéricas podem simular uma
distribuição de probabilidades por meio da aplicação da função sigmoide logística
$g=\frac{1}{1+e^{-\bm{x}}}$
\ano{qual seria uma boa ref para sigmoide?}:
\begin{equation} \label{eqprob}
 P(y_o=1|\bm{x}) = \frac{g(f_o(\bm{x}))}{\sum_{1 \leq p \leq |Y|}g(f_p(\bm{x})) }
\end{equation}

Onde $f_o(\bm{x})$ é a função preditiva da classe $o$ para o exemplo $\bm{x}$;
valores próximos de $1$ indicam pertinência à classe e próximos de $0$, o oposto.

A estratégia de amostragem por incerteza consiste em consultar o exemplo
mais informativo $\bm{x}^*$,
ou seja, aquele com a menor $P_{max}(\bm{x})$,
com o intuito de se explorar a fronteira de decisão no espaço de exemplos, conforme
Equação \ref{equnc}.
A complexidade dessa estratégia é $\mathcal{O}(1)$ - equivalente
a apenas um treinamento por consulta.
\begin{equation} \label{equnc}
 \bm{x}^*= \argmin_{\bm{x}\in\mathcal{U}}P_{max}(\bm{x})
\end{equation}


\subsection{Amostragem por margem ou entropia}\label{mar}
Em problemas multiclasse, o menor $P_{max}(\bm{x})$ pode não indicar o exemplo
mais controverso, pois pode existir um exemplo com duas ou mais classes igualmente prováveis,
porém com maior $P_{max}(\bm{x})$.
A medida da margem, apresentada nas Equações \ref{eqz} e \ref{eqmar},
evita esse problema utilizando o valor da diferença entre as duas maiores probabilidades.
Outra possibilidade é a medida de entropia normalizada
\citep{journals/bioinformatics/LewinSA0P04}, apresentada na Equação \ref{eqent}.
\begin{eqnarray} \label{eqz}
\bm{z}(\bm{x})=\argmax_{\bm{y}\in Y}P(\bm{y}|\bm{x})
\\
M(\bm{x})=P(\bm{z}(\bm{x})|\bm{x})-\max_{\bm{y}\in Y\setminus\{\bm{z}(\bm{x})\}}P(\bm{y}|\bm{x})
\label{eqmar}
\end{eqnarray}
\begin{equation} \label{eqent}
E(\bm{x})=-\log^{-1}|Y|\sum_{\bm{y}\in Y}P(\bm{y}|\bm{x})\log P(\bm{y}|\bm{x})
\end{equation}

\subsection{Margem simples - SVMsim}
A estratégia de amostragem por margem pode ser estendida para um espaços de
atributos $\mathcal{F}$ transformado por uma \ing{função núcleo}{kernel function}.
Essa foi a abordagem de \cite{journals/jmlr/TongK01} para SVMs,
cuja variante mais empregada é chamada \ing{margem simples}{simple margin} (SVMsim).
%  If asking each query is expensive relative to computing time then using either the MaxMin or Ratio
% may be preferable. However, ifthe cost ofasking each query is relatively cheap and more emphasis
% is placed upon fast feedback then the Simple method may be more suitable.
Ela consiste em selecionar o exemplo mais próximo do hiperplano que é a fronteira de decisão
que divide linearmente o espaço $\mathcal{F}$.
%  algoritmo: learn an SVM on the existing labeled data and choose as the next instance to
%  query the instance that comes closest to the hyperplane in F.

\subsection{Balanceamento exploração-prospecção - SVMbal}
A natureza puramente prospectiva da amostragem por margem simples tem o viés de enfocar
prioritariamente a fronteira de decisão, deixando de explorar as demais regiões do espaço
$\mathcal{F}$.
Por esse motivo, \cite{conf/icdm/OsugiKS05} propuseram um balanceamento entre prospecção
e a exploração realizada pelo algoritmo de se escolher \ing{primeiro os mais distantes pelo núcleo}
{Kernel Farthest First} (KFF).
A heurística de se adotar os mais distantes primeiro, sem a transformação pelo núcleo,
foi usada previamente para calcular agrupamentos aproximadamente ótimos
\citep{Hochbaum1985}.

O algoritmo de balanceamento exploração-prospecção (SVMbal) inicia com a aplicação do KFF.
Seu primeiro exemplo é aleatório e o segundo é seu par mais distante.
Esse par consiste no conjunto inicial que vai ser estendido com exemplos,
um a um, da mesma maneira que o segundo foi escolhido.
Esse processo exploratório é alternado com a estratégia de margem simples
de acordo com uma probabilidade definida em função da distância entre as predições
% para todos os exemplos
antes e depois da última consulta.

\subsection{Consulta por comitê}\label{qbc}
Comitês
% também chamados de classificadores baseados em \textit{ensemble},
são combinações de modelos com o objetivo de superar as predições de modelos únicos.
A \ing{consulta por grupo de amostras}{query by bagging} e
a \ing{consulta por grupo de amostras impulsionador}{query by boosting}
são dois exemplos de \ing{consulta por comitê}{Query By Committee} - QBC
\citep{conf/icml/AbeM98}.
Dependendo do tipo de saída fornecida pelo modelo, diferentes medidas de desacordo
podem ser usadas,
% The possibility to take measures about the \textbf{disagreement between concurrent hypotheses},
% rather than a single model probability output, is the main feature of this strategy.

% In data-based ensembles, subsampling techniques are the most popular,
% specifically \textit{boosting} and \textit{bagging}.
% While boosting \cite{schapire1990strength} explores instances uncovered
% (incorrectly classified) by previous models to generate the next one,
% bagging \cite{breiman1996bagging} tries to force different biases by randomly
% selecting considerably different subsets of instances for each classifier.
% In the active learning context,
% the several flavors of Query by Committee are similar to both uncertainty sampling and
% \textit{query by disagreement}.
% They unite the localized notion of uncertainty from the former with the multiple opinions from
% the latter into a single measure.
% Due to its enforced diversity, \textit{Decorate} ensembles are also worth to mention.
%
% In this paper,
% % \textit{soft vote entropy} \cite{settles2012active} is considered when generating queries from
% committees apart from the fact that non-probabilistic classifiers like decision trees are adopted
% instead of probabilistic ones.

% two such measures are \textit{JS-divergence} and \textit{KL-divergence}.
% They have been described as good measures to achieve accurate class probability estimates
%mccallum1998employing}.

A divergência de Jensen-Shannon \cite{journals/tit/Lin91} é uma medida da teoria da informação
que compara distribuições de probabilidade, comumente usada em comitês para
avaliar o grau de desacordo entre os membros \cite{Melville:2004:DEA:1015330.1015385}.
A divergência não-ponderada de Jensen-Shannon é definida em termos da entropia das distribuições
na Equação \ref{js}.
\begin{equation}\label{js}
 JS(\{\theta^{(m)} \forall m \in Y\}) = E(\sum_{m \in Y}{P(\theta^{(m)},\bm{x})}) - \sum_m{E(P(\theta^{(m)},\bm{x})})
\end{equation}
Onde $\theta^{(m)}$ é o modelo numerado $m$.
Quanto maior o valor de $JS$, mais distante os membros estão de um consenso.
Assim, o exemplo com o maior valor deve ser consultado primeiro.
A complexidade computacional é $\mathcal{O}(1)$,
se o comitê for visto como um único algoritmo de aprendizado;
ou $\mathcal{O}(M)$, se o número de membros $M$ for considerado.

\subsection{Busca no espaço de hipóteses}\label{sgnet}
É possível fazer uma amostragem ativa baseada na perspectiva do espaço de hipóteses.
A intuição dessa abordagem é que os exemplos mais importantes residem na região onde
as hipóteses se contradizem.
Isso equivale a consultar os exemplos que reduziriam o \versionspace 
\citep{books/daglib/0087929} depois de inseridos no conjunto de treinamento.
A busca no espaço de hipóteses é feita pelo acompanhamento das hipóteses
mais específicas e as mais gerais pertencentes aos conjuntos $S$ e $G$ de todas as hipóteses possíveis,
denominadas $h_S \in S$ e $h_G \in G$, respectivamente.
\tar{colocar figura? para esse texto confuso fazer sentido e evitar formalismo do mittchel}
Uma característica distintiva desse paradigma com relação aos demais neste capítulo é
seu \textbf{modelo de decisão binário}: todos os exemplos controversos são considerados
igualmente informativos,
podendo ser consultados em qualquer ordem ou em lotes.

\textit{SG-network} \cite{journals/ml/CohnAL94},
também chamado de CAL \citep{journals/tcs/Dasgupta11} em referência a seus proponentes,
é baseado na busca no espaço de hipóteses e foi um dos primeiros algoritmos de aprendizado ativo.
Ele faz uma aproximação para ser capaz de induzir os modelos específico
$\theta_S$ e geral $\theta_G$, pois a quantidade de hipóteses possível pode ser infinita.
A aproximação é feita pela geração ou amostragem de \ing{exemplos de fundo}{background instances}
e rotulação artificial deles de acordo com a meta desejada de treinamento:
especificidade ou generalidade.
Depois de criados os modelos iniciais, eventuais exemplos que causem desacordo entre $\theta_S$ e $\theta_G$
são selecionados para consulta.
Duas redes \ing{perceptron multicamadas}{multilayer perceptron} \citep{haykin2004comprehensive}
foram empregadas no trabalho original,
mas qualquer classificador apto a lidar com exemplos ponderados poderia ser usado.
A ordem de complexidade das estratégias desse paradigma é $\mathcal{O}(|Y|)$.

\ano{TODO: ampliar ou descartar infos adicionais que estão no tex}
%  \red{infos dos txts sobre SG-network cohn1994improving:}
% \esb{Se concentra em membership queries, cita angluin86 e valiant84.
% Em problemas formais, como encontrar uma fronteira no "unit line interval"
%  requer O(1/e ln(1/e))
% exemplos de treinamento aleatórios para se atingir um erro 'e'.
% Se for permitida a síntese de membership queries, 'e' pode ser atingido em O(ln(1/e)).
% Formaliza o aprendiz capaz de determinar a região de incerteza e nomeia como
% Selective Sampling.
% Pode-se calcular a região de inc. em lotes para reduzir a complexidade.
% Apresenta primeiro "a naive neural network querying algorithm":
% 0.1 < o < 0.9 = exemplo na região de incerteza
% judd88 diferencia configuração de arquitetura da MLP.
% Uma única rede pode descrever apenas um conceito, ou seja, uma pequena parte da região de incerteza,
% principalmente porque a MLP tende a ser excessivamente confiante em diversas partes do espaço de
% atributos.
% Os tamanhos dos conjuntos S e G crescem exponencialmente com o número de exemplos. O mesmo é válida
% para a quantidade de configurações de redes.
% Propõe a SG-network baseado em busca do version-space do mitchel82.
% Usa o conceito de "partial ordering in generality of the concepts".
% The version space (space of plausible queries) is reduced with every query.
% Ver algoritmo na página 10.
% Eles propõe mesclar s e G numa só rede.
% Na prática, em conjuntos grandes, é mais eficiente retreinar a rede do zero quando novos exemplos
% são adicionados.
% Experimentos:
% o problema do (par de) triângulo
% --------------------
% topologia 2-8-3-1
% 
% 12 redes treinadas inicialmente com 10, 20, ..., 150 pontos.
% Compara com random e com naive mlp.
% Plota o espaço de parâmetros com a fronteira de decisão criada pela rede comparada com a
%  fronteira real (há também os exemplos + e - espalhados inutilmente).
% Plota error X queries.
% Compararou erros com diferença significativa com mais de 90% de confiança.
% }
% \red{-------------------------- fim das info}

% 


\subsection{\Eer}
A estratégia de redução de erro adotada neste trabalho é baseada no
\ing{exemplo de redução de entropia}{entropy reduction example} proposto por
\cite{conf/ijcai/GuoG07}.
É um método que busca pelo exemplo que mais reduz a entropia na predição geral
do modelo para todo o conjunto de dados;
considera, assim, implicitamente a informação sobre eventuais agrupamentos subjacentes,
evitando depender apenas dos escassos exemplos rotulados.
% Essa variante de estratégias de redução de erro foi adotada dado que uma performance superior à
% original foi reportada pelos autores.

Para cada exemplo candidato com vetor descritivo $\bm{x}$
obtido da reserva $\mathcal{U}$,
sua classe mais provável,
representada pelo vetor preditivo $\bm{y}'$, é calculada de forma
otimista:
\begin{equation}
 \bm{y}' = \argmin_{\bm{y}}{\sum_{\bm{u} \in \mathcal{U}} O(\bm{x}, \theta_{\mathcal{L}\cup
\{\langle\bm{u},y\rangle\}})}
\end{equation}
onde $O$ é a função objetivo.
A complexidade computacional é $\mathcal{O}(|Y||\mathcal{U}|^2)$.
% \ano{está correto colocar duas variáveis com potências diferentes em $\mathcal{O}$?}
Após cada consulta, caso a classe real seja diferente da esperada,
o método recorre à estratégia de amostragem por incerteza (Seção \ref{unc})
como medida de contingência.
No artigo original, optou-se pela entropia como função objetivo.
Outras medidas também podem ser adequadas, dependendo da meta,
como a acurácia balanceada ou kappa multiclasse (Seção \ref{metricas}).

\subsection{Impacto esperado no modelo}
\ano{EER e EMC fazem amostragem de 100}
O futuro impacto de um exemplo sobre o modelo,
chamado de \ing{mudança esperada no modelo}{expected model change} (EMC),
é uma indicação de sua possível contribuição para o aprendizado.
A maneira proposta por \cite{conf/nips/SettlesCR07} é chamada
de \ing{comprimento esperado do gradiente}{expected gradient length} (EGL).
Ela se aplica a modelos baseados na técnica de gradiente descendente \citep{haykin2004comprehensive}:
deve ser escolhido para treinamento o exemplo capaz de contribuir com uma descida de maior magnitude
na curva de erro.
Como o rótulo não é sabido de antemão,
usa-se a soma das contribuições de cada rótulo ponderada pelas respectivas probabilidades condicionais.

\ano{colocar fórmula?}

\subsection{Amostragem ponderada por densidade}\label{dw}
A proposta geral das amostragens ponderadas por densidade é o uso da medida de
\textit{densidade de informação}, que atribui diferentes pesos à medida de
informatividade conforme o nível de concentração de exemplos não rotulados no entorno de $\bm{x}$
\citep{settles2008curious}:
\begin{equation}\label{eqid}
 ID(\bm{x}) = Inf(\bm{x})\frac{1}{|\mathcal{U}|} \sum_{\bm{u} \in \mathcal{U}} sim(\bm{x},\bm{u})
\end{equation}
Seu desdobramento natural é a \textit{utilidade de treinamento},
que é a densidade de informação inversamente ponderada pela concentração de exemplos rotulados,
resultando num afastamento das regiões mais consultadas
\citep{journals/coling/FujiiITT98}:
\begin{equation}\label{eqtu}
 TU(\bm{x}) = ID(\bm{x}) (\sum_{\bm{l} \in \mathcal{L}} sim(\bm{x},\bm{l}))^{-1}
\end{equation}


Qualquer medida de similaridade $sim(\bm{x},\bm{u})$
e de informatividade $Inf(\bm{x})$ podem ser adotadas.
Neste trabalho, $Inf(\bm{x}) = 1 - M$ e três medidas de distância $d(\bm{x},\bm{u})$
(euclidiana, Manhattan e Mahalanobis) foram transformadas em medidas de similaridade
$sim(\bm{x},\bm{u})$ pela fórmula \ref{eq:sim}.
\begin{equation}\label{eq:sim}
 sim(\bm{x},\bm{u}) = \frac{1}{1 + d(\bm{x},\bm{u})}
\end{equation}

A ordem de complexidade é $\mathcal{O}(1)$, se os $|\mathcal{U}|^2$ cálculos de distância forem
devidamente armazenados em memória para futuro acesso rápido.

\ano{expoentes ponderadores nem são mencionados}

\subsection{Amostragem por agrupamento}
O processo de aprendizado pode explorar agrupamentos naturais na \pool,
pois são independentes da existência de rótulos.
Essa abordagem é uma alternativa à realização de consultas que enfocam a fronteira de decisão ou
o manejo de hipóteses citados anteriormente.
Uma importante representante desse paradigma é a \textit{amostragem hierárquica}
proposta por \cite{journals/tcs/Dasgupta11} baseada em
agrupamento hierárquico \citep{journals/cj/Murtagh83}.
O método de agrupamento hierárquico organiza os exemplos numa hierarquia que pode
ser representada por uma árvore.
Cada nó folha simboliza um exemplo e cada nó pai representa uma relação de
proximidade/similaridade entre seus filhos.
Os filhos, por sua vez, podem ser exemplos isolados ou novas relações.
Qualquer nó tem o potencial de ser visto como o grupo dos exemplos representados
pelos nós folhas mais abaixo na hierarquia.
Na árvore como um todo, as diferentes podas possíveis definem a organização em grupos.
\ano{por figura?}

A amostragem hierárquica faz uso da árvore para definir a relevância dos exemplos.
Eles têm maior probabilidade de serem consultados se pertencerem aos grupos
mais impuros e representativos.
A implementação original do autor fez uso do algoritmo de agrupamento chamado
\textit{Ward's average linkage method}.
\ano{como traduzir?}

\tar{dar mais detalhes? replicar o algoritmo(ele tem formulas por todo o artigo))?
essa abordagem é complexa}.

\ano{Aplicar Ward no Weka. Gerar SVG e citar
http://www.trex.uqam.ca/view.php
usando em alguma base 2D interessante. Gerar com e sem ramos proporcionais.
Gravei SVGs no PC de casa.}
\ano{feature: agnóstica}

% \ano{Desvantagem do cluster-based:        é pesado, mesmo que o aprendiz seja leve}

% Em classificadores probabilísticos, como é o caso do \textit{Naive Bayes} \citep{duda2001pattern},
% Árvores de decisão \citep{quinlan1993c4}, $k$-vizinhos mais próximos \citep{aha1991instance} e máquinas de vetores de suporte \citep{cristianini2000introduction} também têm sido usados para a estratégia de \textit{uncertainty sampling}.
% A medida de incerteza, nesses casos, pode ser respectivamente: a pureza do nó, a proporção de vizinhos positivos e a distância exemplo-fronteira \citep{settles2010active}.
% 
% Decomposição viés-variância do erro.
% Ruído intrínseco é o erro esperado do preditor bayesiano ótimo\cite{zhang2012empirical}.
% Viés é o desvio sistemático normalmente esperado ao longo de diferentes experimentos
% (diferentes conjuntos de treinamento).
% Variância é a variabilidade esperada em torno do viés dados diferentes experimentos.
% \begin{figure}
% \begin{center}
% \begin{tikzpicture}
% \begin{axis}[axis y line=left, xmin=20, xmax=72, ymin=1.45, ymax=1.9, axis x line=bottom, grid, xlabel=peso (kg),   ylabel=altura (m)]
% \addplot[only marks,mark=text,text mark=\C{$+$},mark options={blue,scale=1}] plot coordinates {
%     (50,1.5)
% }; \addlegendentry{positivo}
% \addplot[only marks,mark=text,text mark=\T{?},mark options={gray,scale=1}] plot coordinates {
%     (51.6,1.76) (48,1.55) (36,1.55) (38,1.61) (43,1.5)
% }; \addlegendentry{não rotulado}
% \addplot[only marks,mark=text,text mark=\Q{$-$},mark options={red,scale=1}] plot coordinates {
%     (30,1.60)
% }; \addlegendentry{negativo}
% 
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_a}$, mark options={black,scale=1}] plot coordinates {
%     (51.6,1.73)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_d}$, mark options={black,scale=1}] plot coordinates {
%   (48,1.52)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_c}$, mark options={black,scale=1}] plot coordinates {
%   (36,1.52)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_b}$, mark options={black,scale=1}] plot coordinates {
%   (38,1.58)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_e}$, mark options={black,scale=1}] plot coordinates {
%   (43,1.47)};
% 
% \addplot[thick, mark=none, teal] plot coordinates {
%     (54.5,1.86) (35,1.45)
% };
% % \node[small dot,pin=-45:{$\boldsymbol{x^*}$}] at (333,300) {};
% % \node[small dot,pin=45:{$\boldsymbol{x_b}$}] at (290,110) {};
% % \node[small dot,pin=45:{$\boldsymbol{x_a}$}] at (160,110) {};
% \end{axis}
% \end{tikzpicture}
% \caption{O exemplo mais controverso ($\boldsymbol{x_a}$), ou seja, o mais próximo da fronteira, nem sempre é o mais representativo da distribuição dos dados.}
% \label{fig:incerteza_vs_importancia}
% \end{center}
% \end{figure}
% % Density-Weighted Methods
% % \subsection{Notas}
% 

\subsection{Outras estratégias}
\ano{Não implementei Variance reduction pois exige um sistema muito complexo
e com otimizações e ainda assim é ordens de magnitude mais lento que  Unc. Sampl.}
% % Variance Reduction
% Uma forma indireta de se fazer a minimização do erro de generalização
%  é a \textbf{redução da variância}\footnote{[\textit{variance reduction}]
% }.
% Apesar do enfoque diferente, a ordem de complexidade continua sendo um
% problema, pois depende quadraticamente do número de parâmetros do modelo.
% Mesmo quando se reduz essa complexidade por amostragem, redução de
%  dimensionalidade, etc., essa abordagem, assim como outras de medidas conjuntas, permanece empiricamente muito mais lenta que medidas isoladas como \textit{uncertainty sampling} \citep{settles2010active}.

% os experimentos.

\tar{outras - mencionar as que ficaram de fora (Beygelzimmer)}


\subsection{Considerações}
\ano{a ordem de complexidade muda se o learner for incremental ou batch}

\ano{deixar aqui apenas as da literatura, depois repeti-las junto com as propostas numa outra tabela
no prox capitulo}

\begin{table}
\caption{Características de cada estratégia.
\textit{A ordem de complexidade é dada conforme a quantidade de exemplos
a aprender para viabilizar cada consulta. \ano{é aceito O(0)?}}
}
\scalebox{0.88}{
\begin{tabular}{c|c|c|c|c|c}
\textbf{estratégia} & \textbf{\makecell{forma\\ de busca}}&\textbf{\makecell{presença \\de aprendiz}} & \textbf{\makecell{definição da \\sequência de \\consultas}} & \textbf{\makecell{dependência\\entre\\consultas}}&\textbf{\makecell{ordem de\\complexidade}}\\ \hline
Rnd & \makecell{exploratória\\aleatória} & \makecell{agnóstica}&autônoma&nenhuma&$\mathcal{O}(0)$\\ \hline
Clu&\makecell{balanceada:\\exploratória e\\prospectiva}& agnóstica&interativa&total&\makecell{não\\especificada}\\ \hline
\makecell{Unc/Mar/Ent\\QBC/DW}&prospectiva&gnóstica&interativa&total&$\mathcal{O}(1)$\\ \hline
SVMsim&prospectiva&\makecell{gnóstica\\(aprendiz\\específico)}&interativa&total&$\mathcal{O}(|\mathcal{U}||\mathcal{L}|)$\\ \hline
SVMbal&\makecell{alternada:\\exploratória e\\prospectiva}&\makecell{gnóstica\\(aprendiz\\específico)}&interativa&total&$\mathcal{O}(|\mathcal{U}||\mathcal{L}|)$\\ \hline
SGmulti&\makecell{exploratória\\limitada e\\aleatória}&gnóstica&interativa&total&$\mathcal{O}(|Y|)$\\ \hline
EGL&prospectiva&\makecell{gnóstica\\(aprendiz\\específico)}&interativa&total&$\mathcal{O}(|Y||\mathcal{U}|)$\\ \hline
EER&prospectiva&gnóstica&interativa&total&$\mathcal{O}(|Y||\mathcal{U}|^2)$\\ \hline
TU&\makecell{balanceada:\\exploratória e\\prospectiva}&gnóstica&interativa&\makecell{após etapa\\exploratória}&$\mathcal{O}(1)$\\ \hline
\end{tabular}
}
\label{stratsparcial}
\end{table}

\ano{diferenciar de aprendizado semisuperv. colocar algoritmos se der tempo}

\esb{apresenta cada uma com uma figura padrão ilustrando sua particularidade}

\tar{usar semisupervised somente na fase de predição não faria muito sentido.
usar semisupervised no learner faz sentido pelo fato de se ter tantos exemplos
unlabeled à disposição}

\tar{citar relação com crowd sourcing/labeling?}


\ano{TODO: ver tex}
% \citep{conf/ijcnn/SalperwyckL11}
% Learning with few examples: An empirical study on leading classifiers 2011
% associa AL com incremental learning, mas não é sobre AL
% faz ALC com AUC e log2
% investiga tipos de AL especificos para poucos exemplos
% compara ?bastante? datasets:
% The study presented in this paper aims to
% study a larger panel of both algorithms (9 different kinds) and
% data sets (17 UCI bases).
% % http://ieeexplore.ieee.org/xpls/icp.jsp?arnumber=6033333
% % combina AUC final com ALC num grafico 2D

% Activized Learning: Transforming Passive to Active with Improved Label Complexity 2012 Hanneke
% First, since we are lacking a complete understanding of the potential capabilities of active learning, we are not yet sure to what standards we should aspire for active learning algorithms to meet, and in particular this challenges our ability to characterize how a ?good? active learning algorithm should behave. Second, since we have yet to identify a complete set of general principles for the design of effective active learning algorithms, in many cases the most effective known active learning algorithms have problem-specific designs (e.g., designed specifically for linear separators, or decision trees, etc., under specific assumptions on the data distribution), and it is not clear what components of their design can be abstracted and transferred to the design of active learning algorithms for different learning problems (e.g., with different types of classifiers,
% or different data distributions). Finally, we have yet to fully understand the scope of the relative
% benefits of active learning over passive learning, and in particular the conditions under which such
% improvements are achievable, as well as a general characterization of the potential magnitudes of
% these improvements. In the present work, we take steps toward closing this gap in our understanding
% of the capabilities, general principles, and advantages of active learning.
% ...
% REALIZABLE CASE
% In the realizable case, there are obvious examples of learning problems where
% active learning can provide a significant advantage compared to passive learning ...
%  binary search strategy for selecting which examples to request labels for naturally leads to exponential
% improvements in label complexity compared to learning from random labeled examples (passive
% learning). ?
% Disagreement-based methods are sometimes referred to as ?mellow? active learning, since in some
% sense this is the least we can expect from a reasonable active learning algorithm; it never requests
% the label of an example whose label it can infer from information already available, but otherwise
% makes no attempt to seek out particularly informative examples to request the labels of. T
% ?
% Balcan, Hanneke, and Vaughan
% (2010) noted that if we do not require the algorithm to be self-verifying, instead simply measuring
% the number of label requests the algorithm needs to find a good classifier, rather than the number
% needed to both find a good classifier and verify that it is indeed good, then these negative results
% vanish. In fact, (shockingly) they were able to show that for any concept space with finite VC
% dimension, and any fixed data distribution, for any given passive learning algorithm there is an
% active learning algorithm with asymptotically superior label complexity for every nontrivial target
% concept!

