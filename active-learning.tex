\chapter{Aprendizado Ativo} \label{cap:aprendizado-ativo}
O \ing{aprendizado ativo}{active learning} é o estudo de máquinas
de aprendizado capazes de se aprimorar fazendo perguntas \citep{series/synthesis/2012Settles}.
A origem do termo remete à Pedagogia, especificamente à forma didática centrada no aluno.
A ideia básica é aproveitar a individualidade de cada aluno e seu próprio ritmo de aprendizado,
assim ele pode ser auxiliado pelo professor nos aspectos em que experimenta maior dificuldade.
Esse tipo ativo de aprendizado humano - com foco no aluno - tem mostrado evidências
de sua eficácia \citep{michael2006s}.
Analogamente, guardadas as devidas proporções,
pode-se traçar um paralelo com o aprendizado de máquina:
um algoritmo pode usufruir de uma atenção seletiva que
priorize os exemplos mais difíceis para ele em um dado momento.

Em sua forma mais geral, como esboçado por \cite{forman2012programmer},
o aprendizado de máquina ativo pode lançar mão de todo conhecimento que um professor
humano seja capaz de transmitir dentro das limitações de configurabilidade do sistema.
Alguns pontos de configuração seriam, por exemplo:
reescrita do \textit{código}\footnote{\textit{Código} usualmente escrito na linguagem de
 programação que implementa o sistema ou em alguma linguagem específica de domínio.}
de extração de atributos visando maior separabilidade entre as
 classes; composição de expressões regulares para extrair termos adequados de textos técnicos;
e, criação de regras de classificação.

Outras informações, mais diretamente obteníveis do supervisor humano incluiriam
 valores de atributos, rótulos associados com atributos, exemplos completos sob demanda e outros.
Em linhas gerais, sua aquisição deve ser guiada por duas noções
 \citep{krishnapuram2011cost}:
preferir aquela para a qual o estado corrente do modelo é incerto e
preferir aquela estimada como a mais relevante.

O sub-caso e a cenário de aprendizado ativo mais presentes na literatura,
e onde se situa a presente tese, são a busca por rótulos e
o cenário baseado em \pool - respectivamente.
A quantidade de exemplos disponíveis pode ser abundante e o esforço humano disponível
(do professor, no caso da analogia acima) limitado.
Dessa forma, apenas uma parcela criteriosamente escolhida dos exemplos precisa ser
rotulada - em oposição ao \ing{aprendizado por exemplos}{learning by example} convencional
\citep{journals/cacm/Valiant84}, também chamado de passivo.
No aprendizado passivo, procura-se pelo maior conjunto de treinamento possível ou por uma amostragem aleatória.
No primeiro caso, o custo de rotulação pode se tornar proibitivo; no segundo caso,
a decisão quanto à relevância dos exemplos é deixada ao acaso.
Em ambos os casos, dependendo da aplicação, a construção do conjunto de treinamento pode ser crítica.
Por exemplo, quando a consulta de um exemplo envolve reações químicas destrutivas,
é desejável fazer o mínimo possível de consultas visando um reduzido custo material.
Similarmente, se o mecanismo rotulador, normalmente chamado de \novo{oráculo},
for um especialista humano ou mesmo um robô \citep{journals/etai/BryantMOKRK01},
é desejável parcimônia nas consultas para não se incorrer num esforço elevado de
atenção humana/movimento mecânico.
Assim, um direcionamento adequado do esforço de aprendizado tem como resultado um
processo de rotulação mais econômico.

Na literatura de aprendizado ativo há diversas propostas.
Elas são frequentemente baseadas em diferentes concepções de relevância de
exemplos ou mesmo diferentes teorias do aprendizado.
A amostragem por incerteza, por exemplo, assume que os exemplos e suas classes pertencem a uma
distribuição de probabilidades - em linha com a teoria do aprendizado
estatístico \citep{books/daglib/0097035};\red{( <- verificar)}
a amostragem por busca no espaço de hipóteses, por sua vez, assume a existência
de hipóteses integrantes de um \ing{\versionspace}{version space} \citep{books/daglib/0087929}
que enquadram ou não cada exemplo. \red{( <- verificar)}
Estratégias agnósticas \citep{journals/jcss/BalcanBL09}, por outro lado,
são independentes de algoritmo de aprendizado. \red{( <- verificar)}
Essa diversidade de embasamentos configura-se praticamente como um \textit{conjunto de paradigmas}
de amostragem ativa cujos principais representantes são apresentados na seção seguinte.


\section{Estratégias de consulta}\label{sec:estrategias}

\red{xxxxx até aqui o capítulo está feito xxxxx}

% Esses problemas se dividem nos cenários apresentados com as respectivas estratégias na Tabela
% \ref{tab:compara-cenarios-ativos}.
% % \setlength{\tabcolsep}{0pt}
% % \left|{\mathcal{U}}\right|$
% \begin{table}[h]
% \begin{center}
% \begin{tabular}{|l|c|c|}
% %   \cline{2-13}
% %   \multicolumn{1}{l|}{} &
% %   \multicolumn{4}{c|}{2011} &
% %   \multicolumn{4}{c|}{2012} &
% %   \multicolumn{4}{c|}{2013} \\
%   \hline
%   \textbf{cenário} & \textbf{característica} & \textbf{estratégias} \\
%                    & \textbf{do repositório} & \textbf{aplicáveis} \\
%   \hline
%   \textit{membership query} & $|\mathcal{U}|=0$ & \textit{não há amostragem} \\
%   \textit{synthesis}        &                   &  \\
%   \hline
%   amostragem seletiva baseada & $|\mathcal{U}|=1$ & informatividade isolada \\
%   em fluxo - estrita          &                   &   \\
%   \hline
%   amostragem seletiva baseada & $1 < |\mathcal{U}| < |\mathcal{D}|$ & informatividade isolada \\
%   em fluxo - em blocos        &                                     & informatividade conjunta \\
%                               &                               & informativo-representatividade \\
%   \hline
%   \textit{pool-based sampling} & $\mathcal{U} = \mathcal{D}$ & informatividade isolada \\
%                                &                               & informatividade conjunta \\
%                                &                               & informativo-representatividade \\
%   \hline
% \end{tabular}
% \end{center}
% \caption{Comparação de cenários de aprendizado ativo.}
% \label{tab:compara-cenarios-ativos}
% \end{table}





% Retomando na Figura \ref{fig:fronteira-vs-aleatoria} o exemplo de espaço de atributos de duas dimensões do Capítulo \ref{cap:intro}, é possível observar o efeito esperado do aprendizado ativo: apenas os exemplos mais difíceis são consultados - aqueles mais próximos da fronteira de decisão.
% \begin{figure}
% \begin{center}
% \begin{tikzpicture}
% \begin{axis}[axis y line=left, xmin=20, xmax=72, ymin=1.45, ymax=1.9, axis x line=bottom, grid, xlabel=peso (kg),   ylabel=altura (m),
% legend style={at={(1.3,1)}},]
%
% \addplot[only marks,mark=text,text mark=\C{$+$},mark options={blue,scale=1}] plot coordinates {(47.5,1.62) (50,1.5) (55.1,1.52) (63.2,1.58) (60.2,1.71) (67,1.73) (59,1.51)};\addlegendentry{positivo}
%
% \addplot[only marks,mark=text,text mark=\Q{$-$},mark options={red,scale=1}] plot coordinates {(30,1.60) (25,1.47) (26.55,1.85) (23,1.64) (24,1.7) (31,1.69) (32,1.76) (50,1.78)(33,1.53)}; \addlegendentry{negativo}
%
% \addplot[thick, only marks,mark=text,text mark=\C{\phantom{\Q{$-$}}},mark options={black, scale=1.1}] plot coordinates {(59,1.51) (50,1.78)}; \addlegendentry{consultados}
%
% \addplot[thick, mark=none, teal] plot coordinates {(20,1.5) (70,1.7)}; \addlegendentry{fronteira}
%
% \addplot[thick, dashed, only marks,mark=text,text mark=\C{\phantom{\Q{$-$}}},mark options={black, scale=1.1}] plot coordinates {(47.5,1.62) (33,1.53)}; \addlegendentry{a consultar}
%
% \addplot[thick, mark=none, teal, dashed] plot coordinates {(34,1.45) (59,1.9)}; \addlegendentry{futura fronteira}
% \end{axis}
% \end{tikzpicture}
% \caption{A consulta de exemplos de fronteira tende a ser mais proveitosa do que a amostragem aleatória. [os rótulos dos exemplos não consultados são desconhecidos, mas são mostrados para fins ilustrativos]}
% \label{fig:fronteira-vs-aleatoria}
% \end{center}
% \end{figure}


% \begin{algorithm}
% \caption{Seleção do classificador com melhor acurácia recente.}
% \label{alg:sbe}
% \Entrada{
% \begin{itemize}
%  \item um fluxo de dados $D$ de exemplos;
%  \item um tamanho de amostra $w$ para a medida de acurácia;
%  \item uma lista $C$ de classificadores;
%  \item um par de funções $treina(c,\langle x,y \rangle)$ e $testa(c,\langle x,y \rangle): \langle C,\langle X,Y \rangle \rangle \rightarrow \{1=acerto,0=erro\}$ aplicáveis a um classificador $c$ dado um par exemplo/rótulo $\langle x,y \rangle$;
% \item uma lista vazia $C_{selecionados}$ de classificadores.
% \end{itemize}
% }
% \Resultado{
% \begin{itemize}
%  \item a lista $C_{selecionados}$ de classificadores preenchida.
% \end{itemize}
% }
% % $C_{selected} \leftarrow \emptyset$
% $B \leftarrow \emptyset$
%
% \lParaCada{$c \in C$} {
%     $A(c) \leftarrow \emptyset$
% }
%
% \ParaCada{$\langle x,y \rangle \in D$}{
%     \lParaCada{$c \in C$}{
%         $treina(c,\langle x,y \rangle)$
%     }
%
%     $B \leftarrow \langle x,y \rangle \cup B$
%
%     \Se{$|B| > w$}{
%         $B \leftarrow B - ultimo(B)$
%
%         \lParaCada{$c \in C$}{
%             $A(c) \leftarrow A(c) - ultimo[A(c)]$
%         }
%     }
%     \lParaCada{$c \in C$, $\langle x_{ts},y_{ts} \rangle \in B$}{
%         $A(c) \leftarrow testa(c,\langle x_{ts},y_{ts} \rangle) \cup A(c)$
%     }
%     $C_{selected} \leftarrow \argmax_c\{   \displaystyle\sum\limits_{}^{}A(c)\}$
% }
% \end{algorithm}
%
% Uma consequência imediata é a menor necessidade de \textit{consultas} ao mecanismo rotulador e, possivelmente, uma maior acurácia.
% Dessa maneira, o aprendizado ativo é indicado nas situações em que o processo de rotulação é custoso em termos de tempo ou de recursos físicos.
% Isso é desejável quando existe uma \textbf{cota}\footnote{[\textit{budget}]}: somente uma parcela do conjunto pode ser rotulada, ela normalmente é definida como um percentual do total de exemplos disponíveis.
%
%
%
%
%
%
% É possível observar na Figura \ref{fig:ap-ativo} um esquema de aprendizado ativo.
% \begin{figure} %[H]
%     \centering
%     \input{imagens/aprendizado-ativo-esquema.tex}
%     \caption{Esquema de aprendizado ativo: as consultas ao oráculo dependem da estratégia adotada e da medida de informatividade $m(\bm{x})$ em que ela se baseia. [um modelo probabilístico é dado como exemplo de classificador base]}
%     \label{fig:ap-ativo}
% \end{figure}
% Cada exemplo $\bm{x}$ é obtido do conjunto de dados não rotulados
% $\mathcal{U}$ e apresentado a um modelo $\theta$ que seja probabilístico, que gere saídas similares diretamente proporcionais a probabilidades ou que forneça alguma outra maneira de se estimar seu grau de confiança.
% Com base no grau de confiança, é possível calcular a medida de informatividade de cada exemplo.
% Esse grau de confiança permite o cálculo da medida de \textit{informatividade}.
%
% A medida de \textbf{informatividade} $m(\bm{x})$ é a base da tomada de decisão da estratégia de consulta e pode ser implementada de diversas maneiras conforme explicado na Seção \ref{sec:isolada}.
% Uma vez definida a medida de informatividade, uma estratégia de consulta precisa ser definida; diferentes estratégias são estudadas na Seção \ref{sec:estrategias}.

% \section{Medidas de informatividade}\label{sec:informatividade}
% \subsection{Máxima probabilidade a posteriori}
% \subsection{Margem}
% \subsection{Entropia}


Nesta seção são elencadas as estratégias investigadas neste trabalho.
São apresentados suas ordens de complexidade
% espaciais e temporais,
suas principais características e seus princípios de funcionamento.

\subsection{Amostragem por incerteza}
Provavelmente a mais simples medida de informatividade \ano{definir infor.} para se decidir quando selecionar um exemplo $\bm{x}$
(ou grupo de exemplos, na proposta original) é a máxima probabilidade a posteriori dada por um
modelo probabilístico \citep{journals/sigir/Lewis95a}:

\tar{definir yo Y e f}

\begin{equation}
P_{max}(\bm{x})=\max_{\bm{y}\in Y}{P(\bm{y}|\bm{x})}
\end{equation}

Classificadores não probabilísticos e com saídas numéricas podem simular uma
distribuição de probabilidades por meio da aplicação da função sigmoide logística
$g=\frac{1}{1+e^{-\bm{x}}}$:
\begin{equation} \label{eqprob}
 P(y_o=1|\bm{x}) = \frac{g(f_o(\bm{x}))}{\sum_{1 \leq p \leq |Y|}g(f_p(\bm{x})) }
\end{equation}

A estratégia de amostragem por incerteza consiste em consultar o exemplo mais informativo,
ou seja, aquele com a menor $P_{max}(\bm{x})$,
com o intuito de se explorar a fronteira de decisão no espaço de exemplos.
A complexidade dessa estratégia é $\mathcal{O}(1)$ - equivalente a apenas um treinamento por consulta.

\subsection{Busca no espaço de hipóteses}
É possível fazer uma amostragem ativa baseada na perspectiva do espaço de hipóteses.
A intuição dessa abordagem é que os exemplos mais importantes residem na região onde
as hipóteses se contradizem.
Isso equivale a consultar os exemplos que reduziriam o \versionspace 
\citep{books/daglib/0087929} depois de inseridos no conjunto de treinamento.
A busca no espaço de hipóteses é feita pelo acompanhamento das hipóteses
mais específicas e as mais gerais pertencentes aos conjuntos $S$ e $G$ de todas as hipóteses possíveis,
denominadas $h_S \in S$ e $h_G \in G$, respectivamente.
\tar{colocar figura? para esse texto confuso fazer sentido e evitar formalismo do mittchel}
Uma característica distintiva deste paradigma com relação aos demais neste capítulo é
seu \textbf{modelo de decisão binário}: todos os exemplos controversos são considerados
igualmente informativos,
podendo ser consultados em qualquer ordem ou em lotes.

\textit{SG-network} \cite{journals/ml/CohnAL94},
também chamado de CAL \citep{journals/tcs/Dasgupta11} em referência a seus proponentes,
é baseado na busca no espaço de hipóteses e foi um dos primeiros algoritmos de aprendizado ativo.
Ele faz uma aproximação para ser capaz de induzir os modelos específico
$\theta_S$ e geral $\theta_G$, pois a quantidade de hipóteses possível pode ser infinita.
A aproximação é feita pela geração ou amostragem de \ing{exemplos de fundo}{background instances}
e rotulação artificial deles de acordo com a meta desejada de treinamento:
especificidade ou generalidade.
Depois de criados os modelos iniciais, eventuais exemplos que causem desacordo entre $\theta_S$ e $\theta_G$
são selecionados para consulta.
Duas redes \ing{perceptron multicamadas}{multilayer perceptron} \citep{haykin2004comprehensive}
foram empregadas no trabalho original,
mas qualquer classificador apto a lidar com exemplos ponderados poderia ser usado.
A ordem de complexidade das estratégias desse paradigma é $\mathcal{O}(|Y|)$.

Existem outras três abordagens, baseadas em \svm que podem ser interpretadas como
uma busca de sucessivas divisões no \versionspace \cite{tong2002support}:
\ing{margem simples}{simple margin}, \ing{margem maxmin}{maxmin margin} e
\ing{margem razão}{ratio margin}.
Sob outra ótica, elas podem também serem vistas como um tipo de
amostragem por incerteza, vista na seção anterior.



%  \red{infos dos txts sobre SG-network cohn1994improving:}
% \esb{Se concentra em membership queries, cita angluin86 e valiant84.
% Em problemas formais, como encontrar uma fronteira no "unit line interval" requer O(1/e ln(1/e))
% exemplos de treinamento aleatórios para se atingir um erro 'e'.
% Se for permitida a síntese de membership queries, 'e' pode ser atingido em O(ln(1/e)).
% Formaliza o aprendiz capaz de determinar a região de incerteza e nomeia como Selective Sampling.
% Pode-se calcular a região de inc. em lotes para reduzir a complexidade.
% Apresenta primeiro "a naive neural network querying algorithm":
% 0.1 < o < 0.9 = exemplo na região de incerteza
% judd88 diferencia configuração de arquitetura da MLP.
% Uma única rede pode descrever apenas um conceito, ou seja, uma pequena parte da região de incerteza,
% principalmente porque a MLP tende a ser excessivamente confiante em diversas partes do espaço de
% atributos.
% Os tamanhos dos conjuntos S e G crescem exponencialmente com o número de exemplos. O mesmo é válida
% para a quantidade de configurações de redes.
% Propõe a SG-network baseado em busca do version-space do mitchel82.
% Usa o conceito de "partial ordering in generality of the concepts".
% The version space (space of plausible queries) is reduced with every query.
% Ver algoritmo na página 10.
% Eles propõe mesclar s e G numa só rede.
% Na prática, em conjuntos grandes, é mais eficiente retreinar a rede do zero quando novos exemplos
% são adicionados.
% Experimentos:
% o problema do (par de) triângulo
% --------------------
% topologia 2-8-3-1
% 
% 12 redes treinadas inicialmente com 10, 20, ..., 150 pontos.
% Compara com random e com naive mlp.
% Plota o espaço de parâmetros com a fronteira de decisão criada pela rede comparada com a
%  fronteira real (há também os exemplos + e - espalhados inutilmente).
% Plota error X queries.
% Compararou erros com diferença significativa com mais de 90% de confiança.
% }
% \red{-------------------------- fim das info}

% 
% \subsection{Query by Committee}
% Committees, also called ensemble-based classifiers,
% are combinations of models whose united predictions are meant to achieve better accuracy than a
% single model.
% Query by Bagging and Query by Boosting are two examples of active learning committees
% \cite{conf/icml/AbeM98}.
% Depending on the member models output,
% several measures of disagreement are possible.
% % The possibility to take measures about the \textbf{disagreement between concurrent hypotheses},
% % rather than a single model probability output, is the main feature of this strategy.
% 
% % In data-based ensembles, subsampling techniques are the most popular,
% % specifically \textit{boosting} and \textit{bagging}.
% % While boosting \cite{schapire1990strength} explores instances uncovered
% % (incorrectly classified) by previous models to generate the next one,
% % bagging \cite{breiman1996bagging} tries to force different biases by randomly
% % selecting considerably different subsets of instances for each classifier.
% % In the active learning context,
% % the several flavors of Query by Committee are similar to both uncertainty sampling and
% \textit{query by disagreement}.
% % They unite the localized notion of uncertainty from the former with the multiple opinions from
% the latter into a single measure.
% % Due to its enforced diversity, \textit{Decorate} ensembles are also worth to mention.
% %
% In this paper,
% % \textit{soft vote entropy} \cite{settles2012active} is considered when generating queries from
% committees apart from the fact that non-probabilistic classifiers like decision trees are adopted
% instead of probabilistic ones.
% since the base learning algorithms of all strategies are not ensembles,
% a comparison that includes \textit{Query by Committee} is deferred to future work.
% Moreover, a fair comparison between strategies requires the same base learner,
% otherwise accuracies of classifiers trained on the actively sampled instances could not be
% compared.
% % Additionally, JS-divergence is implemented for Random Forest.
% 
% % More elaborate measures quantify the difference/spread between the probability distribution of
% the ensemble as a whole and its members;
% % two such measures are \textit{JS-divergence} and \textit{KL-divergence}.
% % They have been described as good measures to achieve accurate class probability estimates
% \cite{melville2004diverse}. %mccallum1998employing}.
% 
% The complexity of Query by Committee is considered here as $\mathcal{O}(1)$,
% if the ensemble is seen as a single base learner or $\mathcal{O}(M)$, if the number of members $M$
% is considered.


\subsection{\eer}
A estratégia de redução de erro adotada neste trabalho é baseada no
\ing{exemplo de redução de entropia}{entropy reduction example} proposto por
\cite{conf/ijcai/GuoG07}.
É um método que busca pelo exemplo que mais reduz a entropia na predição geral
do modelo para todos o conjunto de dados;
considera, assim, implicitamente a informação sobre eventuais agrupamentos subjacentes,
evitando depender apenas dos escassos exemplos rotulados.
% Essa variante de estratégias de redução de erro foi adotada dado que uma performance superior à
% original foi reportada pelos autores.

Para cada exemplo candidato com vetor descritivo $\bm{x}$ obtido da reserva $\mathcal{U}$,
seu rótulo mais provável, representado pelo vetor preditivo $\bm{y}'$, é calculado de forma
otimista:
\begin{equation}
 \bm{y}' = \argmin_{\bm{y}}{\sum_{\bm{u} \in \mathcal{U}} O(\bm{x}, \theta_{\mathcal{L}\cup
\{\langle\bm{u},y\rangle\}})}
\end{equation}
onde $O$ é a função objetivo.
A complexidade computacional é $\mathcal{O}(|\mathcal{U}|^2)$.
 
Neste trabalho, seguindo a escolha do artigo original,
optou-se pela entropia como função objetivo.
Adicionalmente, a acurácia balanceada foi adotada como uma variação do método,
porém devido ao constatado desempenho inferior
% nas primeiras 50 queries
e alto custo computacional,
ela foi excluída dos experimentos.
% 
% Apenas cem exemplos foram amostrados de $\mathcal{U}$ em cada iteração devido à alta


\subsection{Amostragem ponderada por densidade}
A proposta geral das amostragens ponderadas por densidade é o uso da medida de \textit{densidade de
informação} \citep{settles2008curious}:
\ano{tá certo esse $O$?}
\begin{equation}
 ID(\bm{x}) = O(\bm{x})\frac{1}{|\mathcal{U}|} \sum_{\bm{u} \in \mathcal{U}} sim(\bm{x},\bm{u})
\end{equation}
ou a \textit{utilidade de treinamento} \cite{journals/coling/FujiiITT98},
seu desdobramento natural:
\begin{equation}
 TU(\bm{x}) = ID(\bm{x}) (\sum_{\bm{l} \in \mathcal{L}} sim(\bm{x},\bm{l}))^{-1}
\end{equation}


Qualquer medida de similaridade $sim(\bm{x},\bm{u})$
e de informatividade $H(\bm{x})$ podem ser adotadas.
Neste trabalho, três medidas de distância $d(\bm{x},\bm{u})$
(euclidiana, Manhattan e Mahalanobis) foram transformadas em medidas de similaridade
$sim(\bm{x},\bm{u})$ pela seguinte fórmula:
\begin{equation}
 sim(\bm{x},\bm{u}) = \frac{1}{1 + d(\bm{x},\bm{u})}
\end{equation}

A ordem de complexidade é $\mathcal{O}(1)$, se os $|\mathcal{U}|^2$ cálculos de distância forem
devidamente armazenados em memória para futuro acesso rápido.

\subsection{Amostragem por agrupamento}
O processo de aprendizado pode explorar agrupamentos naturais na \pool,
pois são independentes da existência de rótulos.
Essa abordagem é uma alternativa à realização de consultas que enfocam a fronteira de decisão ou
o manejo de hipóteses citados anteriormente.
Uma tal abordagem é a \textit{amostragem hierárquica} proposta por \cite{journals/tcs/Dasgupta11}.
Os exemplos têm maior probabilidade de serem consultados se pertencerem aos grupos mais impuros e
representativos.
A implementação original do autor foi adotada neste trabalho com o mesmo algoritmo de agrupamento:
\textit{Ward's average linkage method}\footnote{
Implementação disponível no Weka \cite{journals/sigkdd/HallFHPRW09}.}
\ano{como traduzir?}

\tar{dar mais detalhes? replicar o algoritmo(ele tem formulas por todo o texto))?
essa abordagem é complexa}.


% Há diferentes propostas para a determinação de quais exemplos são informativos para consulta.
% Por conveniência, aqui elas estão separadas entre aquelas baseadas na análise de \textit{informatividade isolada} de cada exemplo, aquelas baseadas na \textit{informatividade conjunta} e aquelas baseadas numa análise que combina \textit{informatividade com representatividade}.
% Cada uma das três tem uma perspectiva própria, portanto devem ser vistas como não excludentes entre si; ou seja, elas estão sujeitas a sobreposição, especialmente da primeira em relação às demais.
% 
% \subsection{Informatividade isolada}\label{sec:isolada}
% Uma medida isolada se baseia numa informação extraída do modelo quando apresentado a um exemplo candidato.
% 
% Em classificadores probabilísticos, como é o caso do \textit{Naive Bayes} \citep{duda2001pattern},
% é possível selecionar os exemplos mais relevantes pelos valores de probabilidade condicional atribuídos pelo modelo.
% Essa estratégia é conhecida como \textbf{\textit{uncertainty sampling}}\footnote{[amostragem por incerteza]
% } \citep{lewis:1994:SAT:188490.188495}.
% Ela é simples e bastante difundida.
% Nela, o exemplo com a probabilidade de pertencer à classe mais provável mais próxima de $0,5$ é considerado o candidato ideal a ser enviado ao oráculo.
% No caso com mais de duas classes, pode-se medir a entropia 
% CITAR
% ou considerar a diferença entre os valores de probabilidade dos dois rótulos melhor cotados. Essa variação é conhecida como \textit{margin sampling} \citep{scheffer2001active}.
% Tem sido argumentado que a margem é mais indicada quando se desejar reduzir o erro de classificação, enquanto que a entropia é mais indicada quando se deseja aperfeiçoar a resposta probabilística do modelo CITAR.
% 
% 
% Árvores de decisão \citep{quinlan1993c4}, $k$-vizinhos mais próximos \citep{aha1991instance} e máquinas de vetores de suporte \citep{cristianini2000introduction} também têm sido usados para a estratégia de \textit{uncertainty sampling}.
% A medida de incerteza, nesses casos, pode ser respectivamente: a pureza do nó, a proporção de vizinhos positivos e a distância exemplo-fronteira \citep{settles2010active}.
% 
% % Expected Model Change
% O futuro impacto de um exemplo sobre o modelo, chamado de \textit{\textbf{expected model change}}\footnote{[mudança esperada no modelo]
% }, também é uma indicação razoável de sua possível contribuição para o aprendizado.
% A maneira proposta por \cite{settles2008multiple} é o \textit{\textbf{expected gradient length}}\footnote{[comprimento esperado do gradiente]
% }.
% Ela se aplica a modelos baseados na técnica de gradiente descendente:
% %citar???
% deve ser escolhido para treinamento o exemplo capaz de contribuir com uma descida de maior magnitude.
% Como o rótulo não é sabido de antemão, usa-se a soma das contribuições de cada rótulo ponderada pelas respectivas probabilidades condicionais.
% 
% % Query-By-Committee
% Por fim, a \textbf{consulta por comitê}\footnote{[\textit{query-by-committee}]
% }, facilitada pela própria natureza dos \textit{ensembles}, privilegia os exemplos a respeito dos quais há maior discordância entre os modelos-membro \citep{seung1992query}.
% NOVAMENTE, VERIFICAR ENTROPIA, SE É EQUIVALENTE
% 
% \textit{Active-Decorate} \citep{melville2004diverse} é uma estratégia de aprendizado ativo baseada em \textit{ensemble} do tipo \textit{Decorate} \citep{melville:phd2005}; ela mede a margem das duas maiores probabilidades a posteriori dadas pelo comitê como um todo - uma adaptação da margem de votos usada por \citet{mamitsuka1998query}.
% \textit{Ensembles Decorate} foram reportados recentemente \cite{zhang2012empirical} como superiores a \textit{Boosting} e \textit{Bagging} na escassez de exemplos de treinamento e equivalentes nas demais situações.
% Por isso, é um forte candidato para ser o classificador base do aprendizado ativo, especialmente em casos de cota reduzida.
% \textit{Adaboost} melhor para conjuntos maiores. \textit{Random forests} 
% Os mesmos autores reportaram que \textit{JS-Divergence}\footnote{
%   \textit{JS-divergence} é uma versão simétrica e suavizada de \textit{KL-divergence} \citep{settles2012active}.
% }, além de mais complexa, é menos efetiva em termos de acurácia do que a medida de margem proposta.
% 
% !!passar para um capitulo mais adequado!!
% Decomposição viés-variância do erro.
% Ruído intrínseco é o erro esperado do preditor bayesiano ótimo\cite{zhang2012empirical}.
% Viés é o desvio sistemático normalmente esperado ao longo de diferentes experimentos (diferentes conjuntos de treinamento).
% Variância é a variabilidade esperada em torno do viés dados diferentes experimentos.
% 
% 
% 
% ???Essa é a medida de informatividade isolada adotada na proposta ??ainda é?? (Capítulo \ref{cap:plano}),
% pois é independente da forma de composição do \textit{ensemble}.
% Isso abre a possibilidade de aplicação das diversas técnicas enumeradas na
% Seção \ref{sec:ensemble}.
% O uso dessa medida pode ser parte de outras medidas mais complexas como as mencionadas nas Seções \ref{sec:conjunta} e \ref{sec:inf_representativa}.
% 
% 
% % \citep{dagan1995committee} HMM, part of speech
% % \citep{freund1997selective} mesma laia do dagan e seung, mas mais comprido
% 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Informatividade conjunta}\label{sec:conjunta}
% Uma medida conjunta se baseia em uma informação extraída do modelo quando,
%  além do exemplo candidato sob análise, os candidatos restantes também são utilizados.
% 
% % Expected Error Reduction
% A intensidade de redução no erro de generalização, por exemplo,
%  é uma medida sugestiva quanto à utilidade de um exemplo.
% Ela foi proposta por \cite{roy2001toward} em uma abordagem chamada
% \textit{\textbf{expected error reduction}}\footnote{[redução do erro esperado]
% }.
% Ela assume que os exemplos não rotulados restantes podem ser usados
%  como conjunto de validação desde que as predições atuais para eles
%  sejam consideradas como os rótulos verdadeiros - ou como probabilidades
%  condicionais se for o caso do classificador.
% % citar SVM e outros modelos???
% A medida do erro de generalização é custosa, com ordem de complexidade
%  de pelo menos $\mathcal{O}(|U||L|)$, o que torna desejável alguma maneira de estimá-lo.
% 
% % Variance Reduction
% Uma forma indireta de se fazer a minimização do erro de generalização
%  é a \textbf{redução da variância}\footnote{[\textit{variance reduction}]
% }.
% Apesar do enfoque diferente, a ordem de complexidade continua sendo um
% problema, pois depende quadraticamente do número de parâmetros do modelo.
% Mesmo quando se reduz essa complexidade por amostragem, redução de
%  dimensionalidade, etc., essa abordagem, assim como outras de medidas conjuntas, permanece empiricamente muito mais lenta que medidas isoladas como \textit{uncertainty sampling} \citep{settles2010active}.
% 
% Métodos mais promissores são descritos na Seção \ref{sec:inf_representativa}.
% 
% \subsection{Informativo-representatividade}\label{sec:inf_representativa}
% A incerteza a respeito do rótulo de um exemplo não é necessariamente indicativa da importância do mesmo.
% Isso pode ser notado na Figura \ref{fig:incerteza_vs_importancia}.
% O exemplo mais controverso é $\boldsymbol{x_a}$ - aquele mais próximo da fronteira de decisão.
% Apesar disso, qualquer dos exemplos $\boldsymbol{x_b}$, $\boldsymbol{x_c}$, $\boldsymbol{x_d}$ ou $\boldsymbol{x_e}$ discriminaria melhor a região onde a maioria dos dados se encontra.
% \begin{figure}
% \begin{center}
% \begin{tikzpicture}
% \begin{axis}[axis y line=left, xmin=20, xmax=72, ymin=1.45, ymax=1.9, axis x line=bottom, grid, xlabel=peso (kg),   ylabel=altura (m)]
% \addplot[only marks,mark=text,text mark=\C{$+$},mark options={blue,scale=1}] plot coordinates {
%     (50,1.5)
% }; \addlegendentry{positivo}
% \addplot[only marks,mark=text,text mark=\T{?},mark options={gray,scale=1}] plot coordinates {
%     (51.6,1.76) (48,1.55) (36,1.55) (38,1.61) (43,1.5)
% }; \addlegendentry{não rotulado}
% \addplot[only marks,mark=text,text mark=\Q{$-$},mark options={red,scale=1}] plot coordinates {
%     (30,1.60)
% }; \addlegendentry{negativo}
% 
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_a}$, mark options={black,scale=1}] plot coordinates {
%     (51.6,1.73)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_d}$, mark options={black,scale=1}] plot coordinates {
%   (48,1.52)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_c}$, mark options={black,scale=1}] plot coordinates {
%   (36,1.52)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_b}$, mark options={black,scale=1}] plot coordinates {
%   (38,1.58)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_e}$, mark options={black,scale=1}] plot coordinates {
%   (43,1.47)};
% 
% \addplot[thick, mark=none, teal] plot coordinates {
%     (54.5,1.86) (35,1.45)
% };
% % \node[small dot,pin=-45:{$\boldsymbol{x^*}$}] at (333,300) {};
% % \node[small dot,pin=45:{$\boldsymbol{x_b}$}] at (290,110) {};
% % \node[small dot,pin=45:{$\boldsymbol{x_a}$}] at (160,110) {};
% \end{axis}
% \end{tikzpicture}
% \caption{O exemplo mais controverso ($\boldsymbol{x_a}$), ou seja, o mais próximo da fronteira, nem sempre é o mais representativo da distribuição dos dados.}
% \label{fig:incerteza_vs_importancia}
% \end{center}
% \end{figure}
% % Density-Weighted Methods
% Por esse motivo existem os métodos baseados em \textbf{ponderação por densidade}\footnote{[\textit{density-weighted}]
% }, que podem, entre outras possibilidades, dividir o espaço de atributos por agrupamentos; ponderar a medida de relevância do exemplo pela sua representatividade na distribuição dos dados; ou escolher o candidato com maior afinidade em relação ao conjunto não rotulado e maior diferença em relação ao conjunto de treinamento \citep{settles2010active}.
% 
% Segundo \cite{settles2008multiple}, os resultados reportados com esse tipo de abordagem se mostraram superiores àqueles não baseados em densidade ou representatividade.
% % conferir??
% Além disso, eles mostram que é viável a manutenção de um registro de densidades pré-computadas com o objetivo de atingir um tempo de processamento similar ao da estratégia de \textit{uncertainty sampling} (a referência natural da área no quesito custo computacional).
% 
% % \subsection{Notas}
% \cite{mccallum1998employing} fazem uso da ponderação por densidade e de comitês (Seção \ref{sec:isolada}) em dados de distribuição estacionária.
% Eles conseguiram bons resultados em bases diversas, chegando a duplicar a acurácia quando comparada a uma seleção por consulta aleatória.
% Esse resultado, relativamente antigo, somado à já citada observação de \cite{settles2008multiple},
% direciona o presente trabalho para o uso de comitês e ponderação da discordância interna (informatividade isolada) por densidade (informativo-representatividade).
% 
% A forma de obtenção das medidas de informatividade é afetada pelas particularidades de cada cenário.
% Eles são descritos na Seção \ref{sec:cenarios}.

\subsection{Outras estratégias}
Os códigos originais dos autores das seguintes estratégias \textit{margem simples},
\textit{self-conf}, \textit{KFF} e \textit{balancedEE}
\citep{journals/jmlr/TongK01,journals/jmlr/BaramEL04,conf/icdm/OsugiKS05}
foram adaptados para contemplar problemas multiclasse por meio da aplicação de
\ing{rodízio}{round-robin} entre sub-estratégias.
A cada sub-estratégia foi atribuída uma classe principal, na configuração \textit{um para muitos}.
Porém tal configuração resultou em estratégias excessivamente piores que a amostragem aleatória.
Isso poderia ser um indício de problemas na implementação original ou na adaptação,
ou mesmo da ineficácia do rodízio.
Por esses motivos elas foram excluídas deste trabalho.
% os experimentos.

%mais detalhes sobre essas estratégias:
% Online choice of active learning algorithms
% A simple active-learning heuristic based on ``farthest-first'' traversal sequences
%                     in kernel space. Farthest-first (FF) sequences have been previously used for computing provably
%                     approximate optimal clustering for k-center problems (Hochbaum and Shmoys, 1985). The FF
%                     traversal of the points in a data set is defined as follows. Start with any point x and find the farthest
%                     point from x. Then find the farthest point from the first two (where the distance of a point from a set
%                     is defined to be the minimum distance to a point in the set), etc. In any metric space, FF traversals
%                     can be used for computing 2-approximation solutions to the k-center clustering problem in which
%                     one seeks an optimal k-clustering of the data and optimality is measured by the maximum diameter
%                     of the clusters. In particular, by taking the first k elements in the FF traversal as ``centroids`` and then
%                     assigning each other point to its closest ``centroid``, one obtains a k-clustering whose cost is within
%                     a factor 2 of the optimal (Hochbaum and Shmoys, 1985).
% 
%                  * Parece que é o sucessor do MAB3.
%                  * The idea is similar to COMB (by Luz et. al.). We use two learners:
%                  * SIMPLE and KFF. the latter exploits and the former explores the data.
%                  * the context switch between the two methods is done randomly using a biased coin.
%                  * the bias is dynamically chosen and reflects the `effectivness' of exploration,
%                  * which is measured by a distance function between two hypothesis.
%                  *
%                  * the implemention corresponds the paper:
%                  * Thomas Osugi, Deng Kun, and Stephen Scott.
%                  * Balancing Exploration and Exploitation: A New Algorithm for Active Machine Learning.
%                  * In Proceedings of the Fifth IEEE International Conference on Data Mining. November 2005.
%                  */


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Considerações}\label{sec:consideracoes-ativo}
% Neste capítulo, foram introduzidos os aspectos básicos do aprendizado de máquina,
% a notação adotada neste documento e os conceitos relevantes para situar o leitor nos próximos
% capítulos.
% % Além disso,
% % uma revisão breve forneceu mais detalhes de como o problema da mudança de conceito tem sido
% tratado na literatura.
% %
% % No geral, o material deste capítulo esboça as particularidades da tarefa que é servida pelo
% aprendizado ativo em estudo: a classificação em fluxos de dados e o uso de \textit{ensembles}.
% % Igualmente, todos os problemas aqui citados afetam as \textit{estratégias de consulta} que são
% abordadas no Capítulo \ref{cap:aprendizado-ativo}.



