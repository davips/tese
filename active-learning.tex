\chapter{Aprendizado Ativo} \label{cap:aprendizado-ativo}
O \ing{aprendizado ativo}{active learning} é o estudo de máquinas
de aprendizado capazes de se aprimorar fazendo perguntas \citep{series/synthesis/2012Settles}.
A origem do termo remete à Pedagogia, especificamente à forma didática centrada no aluno.
A ideia básica é a individualidade de cada aluno em relação a seu próprio ritmo de aprendizado, assim ele pode ser auxiliado pelo professor nos aspectos em que experimenta maior dificuldade.
Esse tipo ativo de aprendizado humano - com foco no aluno - tem mostrado evidências
de sua eficácia \citep{michael2006s}.
Analogamente, guardadas as devidas proporções,
pode-se traçar um paralelo com o aprendizado de máquina:
um algoritmo pode usufruir de uma atenção seletiva que
priorize os exemplos mais difíceis para ele em um dado momento.

Em sua forma mais geral, como esboçado por \cite{forman2012programmer},
o aprendizado de máquina ativo pode lançar mão de todo conhecimento que um professor
humano seja capaz de transmitir dentro das limitações de configurabilidade do sistema.
Alguns pontos de configuração seriam, por exemplo:
reescrita do código\footnote{\textit{Reescrita do código}, usualmente, na linguagem de
 programação que implementa o sistema.} de extração de atributos visando maior separabilidade entre as
 classes; composição de expressões regulares para extrair termos adequados de textos técnicos;
e, criação de regras de classificação.

Outras informações, mais diretamente obteníveis do supervisor humano incluiriam
 valores de atributos, rótulos associados com atributos, exemplos completos sob demanda etc.
 Em linhas gerais, sua aquisição deve ser guiada por duas noções
 \citep{krishnapuram2011cost}:
preferir aquela para a qual o estado corrente do modelo é incerto e
preferir aquela estimada como a mais valorosa de se adquirir.

O sub-caso e a cenário de aprendizado ativo mais presentes na literatura,
e onde se situa a presente tese, são a busca por rótulos e
o cenário baseado em \pool - respectivamente.
Esses exemplos seriam, na analogia com o aprendizado humano, aqueles a respeito dos quais o aluno é
mais hesitante e necessita maior esclarecimento.
Dessa forma, apenas uma parcela criteriosamente escolhida dos exemplos precisa ser
rotulada - em oposição ao \ing{aprendizado por exemplos}{learning by example} convencional
\citep{journals/cacm/Valiant84}, também chamado de passivo.
No aprendizado passivo, procura-se pelo maior conjunto de treinamento possível ou por uma amostragem aleatória.
No primeiro caso, o custo de rotulação pode se tornar proibitivo; no segundo caso,
a decisão quanto à relevância dos exemplos é deixada ao acaso.
Em ambos os casos, dependendo da aplicação, a construção do conjunto de treinamento pode ser crítica.
Por exemplo, quando a consulta de um exemplo envolve reações químicas destrutivas,
é desejável fazer o mínimo possível de consultas visando um reduzido custo material.
Similarmente, se o mecanismo rotulador, normalmente chamado de \novo{oráculo},
for um especialista humano ou mesmo um robô \citep{journals/etai/BryantMOKRK01},
é desejável parcimônia nas consultas para não se incorrer num esforço elevado de
atenção humana/movimento mecânico.
Assim, um direcionamento adequado do esforço de aprendizado tem como resultado um
processo de rotulação mais econômico.

Na literatura de aprendizado ativo há diversas propostas.
Elas são frequentemente baseadas em diferentes concepções de relevância de exemplos
ou mesmo diferentes teorias do aprendizado.
A amostragem por incerteza, por exemplo, assume que os exemplos e suas classes pertencem a uma
distribuição de probabilidades - em linha com a teoria do aprendizado
estatístico \citep{books/daglib/0097035};\red{( <- verificar)}
a amostragem por busca no espaço de hipóteses, por sua vez, assume a existência
de hipóteses integrantes de um \ing{espaço de versões}{version space} \citep{books/daglib/0087929}
que enquadram ou não cada exemplo. \red{( <- verificar)}
Estratégias agnósticas \citep{journals/jcss/BalcanBL09}, por outro lado,
são independentes de algoritmo de aprendizado. \red{( <- verificar)}
Essa diversidade de embasamentos configura-se praticamente como um conjunto de paradigmas
de amostragem ativa cujos principais representantes são apresentados na seção seguinte.


\section{Estratégias de consulta}\label{sec:estrategias}

\red{xxxxx até aqui o capítulo está feito xxxxx}

% Esses problemas se dividem nos cenários apresentados com as respectivas estratégias na Tabela
% \ref{tab:compara-cenarios-ativos}.
% % \setlength{\tabcolsep}{0pt}
% % \left|{\mathcal{U}}\right|$
% \begin{table}[h]
% \begin{center}
% \begin{tabular}{|l|c|c|}
% %   \cline{2-13}
% %   \multicolumn{1}{l|}{} &
% %   \multicolumn{4}{c|}{2011} &
% %   \multicolumn{4}{c|}{2012} &
% %   \multicolumn{4}{c|}{2013} \\
%   \hline
%   \textbf{cenário} & \textbf{característica} & \textbf{estratégias} \\
%                    & \textbf{do repositório} & \textbf{aplicáveis} \\
%   \hline
%   \textit{membership query} & $|\mathcal{U}|=0$ & \textit{não há amostragem} \\
%   \textit{synthesis}        &                   &  \\
%   \hline
%   amostragem seletiva baseada & $|\mathcal{U}|=1$ & informatividade isolada \\
%   em fluxo - estrita          &                   &   \\
%   \hline
%   amostragem seletiva baseada & $1 < |\mathcal{U}| < |\mathcal{D}|$ & informatividade isolada \\
%   em fluxo - em blocos        &                                     & informatividade conjunta \\
%                               &                               & informativo-representatividade \\
%   \hline
%   \textit{pool-based sampling} & $\mathcal{U} = \mathcal{D}$ & informatividade isolada \\
%                                &                               & informatividade conjunta \\
%                                &                               & informativo-representatividade \\
%   \hline
% \end{tabular}
% \end{center}
% \caption{Comparação de cenários de aprendizado ativo.}
% \label{tab:compara-cenarios-ativos}
% \end{table}





% Retomando na Figura \ref{fig:fronteira-vs-aleatoria} o exemplo de espaço de atributos de duas dimensões do Capítulo \ref{cap:intro}, é possível observar o efeito esperado do aprendizado ativo: apenas os exemplos mais difíceis são consultados - aqueles mais próximos da fronteira de decisão.
% \begin{figure}
% \begin{center}
% \begin{tikzpicture}
% \begin{axis}[axis y line=left, xmin=20, xmax=72, ymin=1.45, ymax=1.9, axis x line=bottom, grid, xlabel=peso (kg),   ylabel=altura (m),
% legend style={at={(1.3,1)}},]
%
% \addplot[only marks,mark=text,text mark=\C{$+$},mark options={blue,scale=1}] plot coordinates {(47.5,1.62) (50,1.5) (55.1,1.52) (63.2,1.58) (60.2,1.71) (67,1.73) (59,1.51)};\addlegendentry{positivo}
%
% \addplot[only marks,mark=text,text mark=\Q{$-$},mark options={red,scale=1}] plot coordinates {(30,1.60) (25,1.47) (26.55,1.85) (23,1.64) (24,1.7) (31,1.69) (32,1.76) (50,1.78)(33,1.53)}; \addlegendentry{negativo}
%
% \addplot[thick, only marks,mark=text,text mark=\C{\phantom{\Q{$-$}}},mark options={black, scale=1.1}] plot coordinates {(59,1.51) (50,1.78)}; \addlegendentry{consultados}
%
% \addplot[thick, mark=none, teal] plot coordinates {(20,1.5) (70,1.7)}; \addlegendentry{fronteira}
%
% \addplot[thick, dashed, only marks,mark=text,text mark=\C{\phantom{\Q{$-$}}},mark options={black, scale=1.1}] plot coordinates {(47.5,1.62) (33,1.53)}; \addlegendentry{a consultar}
%
% \addplot[thick, mark=none, teal, dashed] plot coordinates {(34,1.45) (59,1.9)}; \addlegendentry{futura fronteira}
% \end{axis}
% \end{tikzpicture}
% \caption{A consulta de exemplos de fronteira tende a ser mais proveitosa do que a amostragem aleatória. [os rótulos dos exemplos não consultados são desconhecidos, mas são mostrados para fins ilustrativos]}
% \label{fig:fronteira-vs-aleatoria}
% \end{center}
% \end{figure}


% \begin{algorithm}
% \caption{Seleção do classificador com melhor acurácia recente.}
% \label{alg:sbe}
% \Entrada{
% \begin{itemize}
%  \item um fluxo de dados $D$ de exemplos;
%  \item um tamanho de amostra $w$ para a medida de acurácia;
%  \item uma lista $C$ de classificadores;
%  \item um par de funções $treina(c,\langle x,y \rangle)$ e $testa(c,\langle x,y \rangle): \langle C,\langle X,Y \rangle \rangle \rightarrow \{1=acerto,0=erro\}$ aplicáveis a um classificador $c$ dado um par exemplo/rótulo $\langle x,y \rangle$;
% \item uma lista vazia $C_{selecionados}$ de classificadores.
% \end{itemize}
% }
% \Resultado{
% \begin{itemize}
%  \item a lista $C_{selecionados}$ de classificadores preenchida.
% \end{itemize}
% }
% % $C_{selected} \leftarrow \emptyset$
% $B \leftarrow \emptyset$
%
% \lParaCada{$c \in C$} {
%     $A(c) \leftarrow \emptyset$
% }
%
% \ParaCada{$\langle x,y \rangle \in D$}{
%     \lParaCada{$c \in C$}{
%         $treina(c,\langle x,y \rangle)$
%     }
%
%     $B \leftarrow \langle x,y \rangle \cup B$
%
%     \Se{$|B| > w$}{
%         $B \leftarrow B - ultimo(B)$
%
%         \lParaCada{$c \in C$}{
%             $A(c) \leftarrow A(c) - ultimo[A(c)]$
%         }
%     }
%     \lParaCada{$c \in C$, $\langle x_{ts},y_{ts} \rangle \in B$}{
%         $A(c) \leftarrow testa(c,\langle x_{ts},y_{ts} \rangle) \cup A(c)$
%     }
%     $C_{selected} \leftarrow \argmax_c\{   \displaystyle\sum\limits_{}^{}A(c)\}$
% }
% \end{algorithm}
%
% Uma consequência imediata é a menor necessidade de \textit{consultas} ao mecanismo rotulador e, possivelmente, uma maior acurácia.
% Dessa maneira, o aprendizado ativo é indicado nas situações em que o processo de rotulação é custoso em termos de tempo ou de recursos físicos.
% Isso é desejável quando existe uma \textbf{cota}\footnote{[\textit{budget}]}: somente uma parcela do conjunto pode ser rotulada, ela normalmente é definida como um percentual do total de exemplos disponíveis.
%
%
%
%
%
%
% É possível observar na Figura \ref{fig:ap-ativo} um esquema de aprendizado ativo.
% \begin{figure} %[H]
%     \centering
%     \input{imagens/aprendizado-ativo-esquema.tex}
%     \caption{Esquema de aprendizado ativo: as consultas ao oráculo dependem da estratégia adotada e da medida de informatividade $m(\bm{x})$ em que ela se baseia. [um modelo probabilístico é dado como exemplo de classificador base]}
%     \label{fig:ap-ativo}
% \end{figure}
% Cada exemplo $\bm{x}$ é obtido do conjunto de dados não rotulados
% $\mathcal{U}$ e apresentado a um modelo $\theta$ que seja probabilístico, que gere saídas similares diretamente proporcionais a probabilidades ou que forneça alguma outra maneira de se estimar seu grau de confiança.
% Com base no grau de confiança, é possível calcular a medida de informatividade de cada exemplo.
% Esse grau de confiança permite o cálculo da medida de \textit{informatividade}.
%
% A medida de \textbf{informatividade} $m(\bm{x})$ é a base da tomada de decisão da estratégia de consulta e pode ser implementada de diversas maneiras conforme explicado na Seção \ref{sec:isolada}.
% Uma vez definida a medida de informatividade, uma estratégia de consulta precisa ser definida; diferentes estratégias são estudadas na Seção \ref{sec:estrategias}.

% \section{Medidas de informatividade}\label{sec:informatividade}
% \subsection{Máxima probabilidade a posteriori}
% \subsection{Margem}
% \subsection{Entropia}


Nesta seção são elencadas as estratégias investigadas neste trabalho.
São apresentados suas ordens de complexidade espaciais e temporais,
suas principais características e seus princípios de funcionamento.

\subsection{Amostragem por incerteza}
% Provavelmente a mais simples medida de informatividade para se decidir quando selecionar um exemplo
% (ou grupo de exemplos, na proposta original) é a máxima probabilidade a posteriori dada por um
% modelo probabilístico \cite{journals/sigir/Lewis95a}:
% \begin{equation}
% P_{max}(\bm{x})=\max_{\bm{y}\in Y}{P(\bm{y}|\bm{x})}
% \end{equation}
% 
% 
% % Para ELMs e outras redes neurais, o achatamento da saída é uma forma comum e simples de se simular
% % uma distribuição de probabilidades.
% % Trata-se do primeiro exemplo de adaptação necessária para se adequar a ELM a uma estratégia de AA.
% Neste trabalho,
% a mesma função logística $g$ aplicada no cálculo das saídas da camada oculta é adotada na fase
% preditiva da camada de saída:
% \begin{equation} \label{eqprob}
%  P(y_o=1|\bm{x}) = \frac{g(f(\bm{x})_o)}{\sum_{1 \leq p \leq |Y|}g(f(\bm{x})_p) }
% \end{equation}
% 
% A estratégia de amostragem por incerteza consiste em consultar o exemplo mais informativo,
% ou seja, aquele com a menor $P_{max}(\bm{x})$,
% com o intuito de se explorar a fronteira de decisão no espaço de exemplos.
% A complexidade dessa estratégia é $\mathcal{O}(1)$.
% Isso significa que ela requer apenas um treinamento por consulta.

\subsection{Busca no espaço de hipóteses}
 \red{infos dos txts sobre SG-network cohn1994improving:}
Se concentra em membership queries, cita angluin86 e valiant84.
Em problemas formais, como encontrar uma fronteira no "unit line interval" requer O(1/e ln(1/e)) exemplos de treinamento aleatórios para se atingir um erro 'e'.
Se for permitida a síntese de membership queries, 'e' pode ser atingido em O(ln(1/e)).

Formaliza o aprendiz capaz de determinar a região de incerteza e nomeia como Selective Sampling.
Pode-se calcular a região de inc. em lotes para reduzir a complexidade.

Apresenta primeiro "a naive neural network querying algorithm":
0.1 < o < 0.9 = exemplo na região de incerteza
judd88 diferencia configuração de arquitetura da MLP.
Uma única rede pode descrever apenas um conceito, ou seja, uma pequena parte da região de incerteza, principalmente porque a MLP tende a ser excessivamente confiante em diversas partes do espaço de atributos.
Os tamanhos dos conjuntos S e G crescem exponencialmente com o número de exemplos. O mesmo é válida para a quantidade de configurações de redes.

Propõe a SG-network baseado em busca do version-space do mitchel82.
Usa o conceito de "partial ordering in generality of the concepts".
The version space (space of plausible queries) is reduced with every query.
Ver algoritmo na página 10.
Eles propõe mesclar s e G numa só rede.
Na prática, em conjuntos grandes, é mais eficiente retreinar a rede do zero quando novos exemplos são adicionados.

Experimentos:
o problema do (par de) triângulo
--------------------
topologia 2-8-3-1
12 redes treinadas inicialmente com 10, 20, ..., 150 pontos.
Compara com random e com naive mlp.
Plota o espaço de parâmetros com a fronteira de decisão criada pela rede comparada com a fronteira real (há também os exemplos + e - espalhados inutilmente).
Plota error X queries.
Compararou erros com diferença significativa com mais de 90% de confiança.

\red{-------------------------- fim das info}

% Duas estratégias que exploram o espaço de hipóteses são \textit{SGmulti} e \textit{SGmultiJS}
% \cite{conf/hais/SantosDP14}.
% Elas induzem modelos específicos para cada rótulo.
% Cada modelo, assim, tem uma aproximação das hipótese mais geral ($\theta_G$) e a conjunção de todos
% os modelos contém uma aproximação das hipóteses mais específicas de cada rótulo ($\theta_S$).
% Isso feito por meio da rotulação artificial de todos os exemplos presentes na reserva de acordo com
% a meta de cada modelo,
% que é a representar a hipótese mais geral para um dado rótulo.
% Uma vez gerados os modelos com os exemplos artificiais,
% os exemplos para consulta passam a ser amostrados da região de desacordo entre todos os modelos.
% A ordem de complexidade do \textit{SG-multi} é $\mathcal{O}(|Y|)$.

It is possible to perform active learning directly from the hypothesis space perspective.
The rationale is to query the most controversial instances when different valid hypotheses are
compared with each other, i.e. to query instances that would reduce the \textit{version space}
\cite{books/daglib/0087929} after its inclusion in the training set.
One way to search through the hypothesis space is to track the sets $S$ and $G$ of specific and
general hypotheses during learning and consider only the most specific $h_S \in S$ and the most
general $h_G \in G$ hypotheses.

One important feature of this family of strategies is its \textbf{binary decision model}: all
instances for which the hypotheses disagree can be queried at once or in any arbitrary order, i.e.
there is no precedence among them.

One of the first active learning algorithms is a \textit{query by disagreement}, called
\textit{SG-network} \cite{journals/ml/CohnAL94}.
It approximately induces specific/general models $\theta_S$ and $\theta_G$ by means of generating
or sampling random ``background'' instances and labeling them artificially according to the desired
training goal: specificity or generality.
Instances are sampled from the region of disagreement between $\theta_S$ and $\theta_G$.
%Two MLP networks are used as classifiers in the original work,
%but any classification algorithm able to handle weighted instances apply.

% There are also three SVM-based approaches that can be interpreted as a version space search
\cite{tong2002support}: \textit{simple margin}, \textit{maxmix margin} and \textit{ratio margin};
however, they can also be seen as a type of uncertainty measure as in the previous section.

The comparison performed in this work is delimited by the pool-based setting,
independent on the learning algorithm and the number of classes.
Therefore, to fit \textit{SG-network} into the experimental requirements,
two sensible adaptations were adopted,
\textit{SG-multi} and \textit{SG-multiJS}.
The order of complexity of the original work (only binary problems)
and the following adaptations is $\mathcal{O}(|Y|)$.

\subsubsection{SG-multi}
For each class $c \in Y$, there is a pair model/training set  $\langle\theta_c,
\mathcal{L}_c\rangle$ properly designed to represent the most general hypothesis $h^c_G$ w.r.t. the
class $c$.
Initially, all instances $\langle\bm{x},y,w\rangle \in \mathcal{L}_c$ are the same instances
present in the pool, except for two differences:
they are labeled as ``positive'' to the corresponding class ($y=c$) and weighted to have only a
small fraction of the importance of the real labeled instances ($w << 1$),
as suggested in the literature \cite{series/synthesis/2012Settles}.
The weight value adopted in this work is $w=\frac{1}{|Y||\mathcal{U}|}$,
since it ensures that the summed influence of all background instances is no larger than a single
real instance.
This measure avoids misleadings due to the scarce initial real training instances.

The prediction function $f(\theta_c, \bm{x})$ returns the most probable class to a given instance
$\bm{x}$ according to the provided model $\theta_c$.
It is possible to determine an instance under disagreement $\bm{x}^*$
by comparing the outcomes from all different prediction functions.
Each prediction function represents the most general concept of each class:
\[
  \forall a,b \in Y, a \neq b, \exists \bm{x}^* \mid f(\theta_a,\bm{x}^*) \neq f(\theta_b,\bm{x}^*)
\]

As soon as the instances from the region of disagreement $\bm{x}^*$,
i.e. those with no consensus, are sampled and queried,
 they replace their counterparts in all training sets with the real labels and integral weights:
 \[
  \mathcal{L}_c \leftarrow (\mathcal{L}_c - \{\langle\bm{x}^*,c,w\rangle\}) \cup
\{\langle\bm{x}^*,c,1\rangle\} \forall c \in Y
 \]

In this adapted strategy (\textit{SG-multi}),
the decisions based on disagreement were kept binary, i.e. there is no ordering in the sequence of
queries,
except the precedence of the group of controversial instances over the rest.
% This implementation decision is not optimized for tiny budgets,
% % since the first queried instances are no different from the last controversial ones,
% but it has the some margin for randomness like in the \textit{randomized uncertainty} approach
suggested for use in data streams \cite{zliobaite2011active}.
% Beyond data streams,
% the injection of randomness is well suited for pools,
% because the learner can be overly confident about instances inside a region of the decision space
which in reality is a non-contiguous concept.

\subsubsection{SG-multiJS}
A real-valued measure of disagreement can be adopted to soften
%smooth
the binary querying criterion of \textit{SG-multi}.
It assumes that the  probability distributions $P(\theta_c, \bm{x})$ can be estimated from the
models $\theta_c \forall c \in Y$.
Besides the constraint on the classification algorithm being able to output probabilities,
\textit{SG-multiJS} differs from \textit{SG-multi} in the querying criterion: the Jensen-Shannon
divergence \cite{journals/tit/Lin91}.
It is an information theoretic measure that compares probability distributions, commonly used in
ensembles to assess the degree of agreement between their members.
The non-weighted Jensen-Shannon divergence is defined by the entropy of the distributions:
\[
 JS(\{\theta_c \forall c \in Y\}) = E(\sum_{c \in Y}{P(\theta_c,\bm{x})}) -
\sum_c{E(P(\theta_c,\bm{x})})
\]
The higher the $JS$, the further the members are from a consensus.
Therefore, the instance with the highest value should be queried first.
This criterion disrupts with the binary decision model underlying its theoretical background
inspiration and may be more adequate to select instances from the disagreement area.

\subsection{Query by Committee}
Committees, also called ensemble-based classifiers,
are combinations of models whose united predictions are meant to achieve better accuracy than a
single model.
Query by Bagging and Query by Boosting are two examples of active learning committees
\cite{conf/icml/AbeM98}.
Depending on the member models output,
several measures of disagreement are possible.
% The possibility to take measures about the \textbf{disagreement between concurrent hypotheses},
% rather than a single model probability output, is the main feature of this strategy.

% In data-based ensembles, subsampling techniques are the most popular,
% specifically \textit{boosting} and \textit{bagging}.
% While boosting \cite{schapire1990strength} explores instances uncovered
% (incorrectly classified) by previous models to generate the next one,
% bagging \cite{breiman1996bagging} tries to force different biases by randomly
% selecting considerably different subsets of instances for each classifier.
% In the active learning context,
% the several flavors of Query by Committee are similar to both uncertainty sampling and
\textit{query by disagreement}.
% They unite the localized notion of uncertainty from the former with the multiple opinions from
the latter into a single measure.
% Due to its enforced diversity, \textit{Decorate} ensembles are also worth to mention.
%
In this paper,
% \textit{soft vote entropy} \cite{settles2012active} is considered when generating queries from
committees apart from the fact that non-probabilistic classifiers like decision trees are adopted
instead of probabilistic ones.
since the base learning algorithms of all strategies are not ensembles,
a comparison that includes \textit{Query by Committee} is deferred to future work.
Moreover, a fair comparison between strategies requires the same base learner,
otherwise accuracies of classifiers trained on the actively sampled instances could not be
compared.
% Additionally, JS-divergence is implemented for Random Forest.

% More elaborate measures quantify the difference/spread between the probability distribution of
the ensemble as a whole and its members;
% two such measures are \textit{JS-divergence} and \textit{KL-divergence}.
% They have been described as good measures to achieve accurate class probability estimates
\cite{melville2004diverse}. %mccallum1998employing}.

The complexity of Query by Committee is considered here as $\mathcal{O}(1)$,
if the ensemble is seen as a single base learner or $\mathcal{O}(M)$, if the number of members $M$
is considered.


\subsection{\eer}
% A estratégia de redução de erro adotada neste trabalho é baseada na \textit{Entropy Reduction
% Example}.
% É um método que busca pelo exemplo que mais reduz a entropia, e considera implicitamente a
% informação sobre o agrupamento subjacente, ao invés de depender apenas dos escassos exemplos
% rotulados \cite{conf/ijcai/GuoG07}.
% Essa variante de estratégias de redução de erro foi adotada dado que uma performance superior à
% original foi reportada pelos autores.
% 
% Para cada exemplo candidato com vetor descritivo $\bm{x}$ obtido da reserva $\mathcal{U}$,
% seu rótulo mais provável, representado pelo vetor preditivo $\bm{y}'$, é calculado de forma
% otimista:
% \begin{equation}
%  \bm{y}' = \argmin_{\bm{y}}{\sum_{\bm{u} \in \mathcal{U}} O(\bm{x}, \theta_{\mathcal{L}\cup
% \{\langle\bm{u},y\rangle\}})}
% \end{equation}
% 
% onde $O$ é a função objetivo.
% 
% Seguindo a escolha do artigo original, neste trabalho, optou-se pela entropia como função objetivo.
% Adicionalmente, a acurácia também foi adotada.
% 
% Apenas cem exemplos foram amostrados de $\mathcal{U}$ em cada iteração devido à alta complexidade
% computacional do método ($\mathcal{O}(|\mathcal{U}|^2)$).

\subsection{Amostragem ponderada por densidade}
% A proposta geral das amostragens ponderadas por densidade é o uso da medida de \textit{densidade de
% informação} \cite{settles2008curious}:
% \begin{equation}
%  ID(\bm{x}) = O(\bm{x})\frac{1}{|\mathcal{U}|} \sum_{\bm{u} \in \mathcal{U}} sim(\bm{x},\bm{u})
% \end{equation}
% 
% ou a \textit{utilidade de treinamento} \cite{journals/coling/FujiiITT98},
% sua sucessora natural e adotada neste trabalho:
% \begin{equation}
%  TU(\bm{x}) = ID(\bm{x}) (\sum_{\bm{l} \in \mathcal{L}} sim(\bm{x},\bm{l}))^{-1}
% \end{equation}
% 
% 
% Qualquer medida de similaridade $sim(\bm{x},\bm{u})$ e informatividade $H(\bm{x})$ podem ser
% adotadas.
% Neste trabalho, duas distâncias $d(\bm{x},\bm{u})$ foram comparadas (euclidiana e Manhattan)
% e transformadas numa medida de similaridade pela seguinte fórmula:
% \begin{equation}
%  sim(\bm{x},\bm{u}) = \frac{1}{1 + d(\bm{x},\bm{u})}
% \end{equation}
% 
% A ordem de complexidade é $\mathcal{O}(1)$, se os $|\mathcal{U}|^2$ cálculos de distância forem
% devidamente armazenados em memória para futuro acesso rápido.

\subsection{Amostragem por agrupamento}
% O processo de aprendizado pode explorar agrupamentos naturais na reserva,
% pois são independentes da existência de rótulos.
% Essa abordagem é uma alternativa à realização de consultas que enfocam a fronteira de decisão ou
% o manejo de hipóteses citados anteriormente.
% Uma tal abordagem é a \textit{amostragem hierárquica} \cite{journals/tcs/Dasgupta11}.
% Os exemplos têm maior probabilidade de serem consultados se pertencerem aos grupos mais impuros e
% representativos.
% A implementação original do autor foi adotada neste trabalho com o mesmo algoritmo de agrupamento:
% \textit{Ward's average linkage method}\footnote{
% Implementação disponível no Weka \cite{journals/sigkdd/HallFHPRW09}.}.


% Há diferentes propostas para a determinação de quais exemplos são informativos para consulta.
% Por conveniência, aqui elas estão separadas entre aquelas baseadas na análise de \textit{informatividade isolada} de cada exemplo, aquelas baseadas na \textit{informatividade conjunta} e aquelas baseadas numa análise que combina \textit{informatividade com representatividade}.
% Cada uma das três tem uma perspectiva própria, portanto devem ser vistas como não excludentes entre si; ou seja, elas estão sujeitas a sobreposição, especialmente da primeira em relação às demais.
% 
% \subsection{Informatividade isolada}\label{sec:isolada}
% Uma medida isolada se baseia numa informação extraída do modelo quando apresentado a um exemplo candidato.
% 
% Em classificadores probabilísticos, como é o caso do \textit{Naive Bayes} \citep{duda2001pattern},
% é possível selecionar os exemplos mais relevantes pelos valores de probabilidade condicional atribuídos pelo modelo.
% Essa estratégia é conhecida como \textbf{\textit{uncertainty sampling}}\footnote{[amostragem por incerteza]
% } \citep{lewis:1994:SAT:188490.188495}.
% Ela é simples e bastante difundida.
% Nela, o exemplo com a probabilidade de pertencer à classe mais provável mais próxima de $0,5$ é considerado o candidato ideal a ser enviado ao oráculo.
% No caso com mais de duas classes, pode-se medir a entropia 
% CITAR
% ou considerar a diferença entre os valores de probabilidade dos dois rótulos melhor cotados. Essa variação é conhecida como \textit{margin sampling} \citep{scheffer2001active}.
% Tem sido argumentado que a margem é mais indicada quando se desejar reduzir o erro de classificação, enquanto que a entropia é mais indicada quando se deseja aperfeiçoar a resposta probabilística do modelo CITAR.
% 
% 
% Árvores de decisão \citep{quinlan1993c4}, $k$-vizinhos mais próximos \citep{aha1991instance} e máquinas de vetores de suporte \citep{cristianini2000introduction} também têm sido usados para a estratégia de \textit{uncertainty sampling}.
% A medida de incerteza, nesses casos, pode ser respectivamente: a pureza do nó, a proporção de vizinhos positivos e a distância exemplo-fronteira \citep{settles2010active}.
% 
% % Expected Model Change
% O futuro impacto de um exemplo sobre o modelo, chamado de \textit{\textbf{expected model change}}\footnote{[mudança esperada no modelo]
% }, também é uma indicação razoável de sua possível contribuição para o aprendizado.
% A maneira proposta por \cite{settles2008multiple} é o \textit{\textbf{expected gradient length}}\footnote{[comprimento esperado do gradiente]
% }.
% Ela se aplica a modelos baseados na técnica de gradiente descendente:
% %citar???
% deve ser escolhido para treinamento o exemplo capaz de contribuir com uma descida de maior magnitude.
% Como o rótulo não é sabido de antemão, usa-se a soma das contribuições de cada rótulo ponderada pelas respectivas probabilidades condicionais.
% 
% % Query-By-Committee
% Por fim, a \textbf{consulta por comitê}\footnote{[\textit{query-by-committee}]
% }, facilitada pela própria natureza dos \textit{ensembles}, privilegia os exemplos a respeito dos quais há maior discordância entre os modelos-membro \citep{seung1992query}.
% NOVAMENTE, VERIFICAR ENTROPIA, SE É EQUIVALENTE
% 
% \textit{Active-Decorate} \citep{melville2004diverse} é uma estratégia de aprendizado ativo baseada em \textit{ensemble} do tipo \textit{Decorate} \citep{melville:phd2005}; ela mede a margem das duas maiores probabilidades a posteriori dadas pelo comitê como um todo - uma adaptação da margem de votos usada por \citet{mamitsuka1998query}.
% \textit{Ensembles Decorate} foram reportados recentemente \cite{zhang2012empirical} como superiores a \textit{Boosting} e \textit{Bagging} na escassez de exemplos de treinamento e equivalentes nas demais situações.
% Por isso, é um forte candidato para ser o classificador base do aprendizado ativo, especialmente em casos de cota reduzida.
% \textit{Adaboost} melhor para conjuntos maiores. \textit{Random forests} 
% Os mesmos autores reportaram que \textit{JS-Divergence}\footnote{
%   \textit{JS-divergence} é uma versão simétrica e suavizada de \textit{KL-divergence} \citep{settles2012active}.
% }, além de mais complexa, é menos efetiva em termos de acurácia do que a medida de margem proposta.
% 
% !!passar para um capitulo mais adequado!!
% Decomposição viés-variância do erro.
% Ruído intrínseco é o erro esperado do preditor bayesiano ótimo\cite{zhang2012empirical}.
% Viés é o desvio sistemático normalmente esperado ao longo de diferentes experimentos (diferentes conjuntos de treinamento).
% Variância é a variabilidade esperada em torno do viés dados diferentes experimentos.
% 
% 
% 
% ???Essa é a medida de informatividade isolada adotada na proposta ??ainda é?? (Capítulo \ref{cap:plano}),
% pois é independente da forma de composição do \textit{ensemble}.
% Isso abre a possibilidade de aplicação das diversas técnicas enumeradas na
% Seção \ref{sec:ensemble}.
% O uso dessa medida pode ser parte de outras medidas mais complexas como as mencionadas nas Seções \ref{sec:conjunta} e \ref{sec:inf_representativa}.
% 
% 
% % \citep{dagan1995committee} HMM, part of speech
% % \citep{freund1997selective} mesma laia do dagan e seung, mas mais comprido
% 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Informatividade conjunta}\label{sec:conjunta}
% Uma medida conjunta se baseia em uma informação extraída do modelo quando,
%  além do exemplo candidato sob análise, os candidatos restantes também são utilizados.
% 
% % Expected Error Reduction
% A intensidade de redução no erro de generalização, por exemplo,
%  é uma medida sugestiva quanto à utilidade de um exemplo.
% Ela foi proposta por \cite{roy2001toward} em uma abordagem chamada
% \textit{\textbf{expected error reduction}}\footnote{[redução do erro esperado]
% }.
% Ela assume que os exemplos não rotulados restantes podem ser usados
%  como conjunto de validação desde que as predições atuais para eles
%  sejam consideradas como os rótulos verdadeiros - ou como probabilidades
%  condicionais se for o caso do classificador.
% % citar SVM e outros modelos???
% A medida do erro de generalização é custosa, com ordem de complexidade
%  de pelo menos $\mathcal{O}(|U||L|)$, o que torna desejável alguma maneira de estimá-lo.
% 
% % Variance Reduction
% Uma forma indireta de se fazer a minimização do erro de generalização
%  é a \textbf{redução da variância}\footnote{[\textit{variance reduction}]
% }.
% Apesar do enfoque diferente, a ordem de complexidade continua sendo um
% problema, pois depende quadraticamente do número de parâmetros do modelo.
% Mesmo quando se reduz essa complexidade por amostragem, redução de
%  dimensionalidade, etc., essa abordagem, assim como outras de medidas conjuntas, permanece empiricamente muito mais lenta que medidas isoladas como \textit{uncertainty sampling} \citep{settles2010active}.
% 
% Métodos mais promissores são descritos na Seção \ref{sec:inf_representativa}.
% 
% \subsection{Informativo-representatividade}\label{sec:inf_representativa}
% A incerteza a respeito do rótulo de um exemplo não é necessariamente indicativa da importância do mesmo.
% Isso pode ser notado na Figura \ref{fig:incerteza_vs_importancia}.
% O exemplo mais controverso é $\boldsymbol{x_a}$ - aquele mais próximo da fronteira de decisão.
% Apesar disso, qualquer dos exemplos $\boldsymbol{x_b}$, $\boldsymbol{x_c}$, $\boldsymbol{x_d}$ ou $\boldsymbol{x_e}$ discriminaria melhor a região onde a maioria dos dados se encontra.
% \begin{figure}
% \begin{center}
% \begin{tikzpicture}
% \begin{axis}[axis y line=left, xmin=20, xmax=72, ymin=1.45, ymax=1.9, axis x line=bottom, grid, xlabel=peso (kg),   ylabel=altura (m)]
% \addplot[only marks,mark=text,text mark=\C{$+$},mark options={blue,scale=1}] plot coordinates {
%     (50,1.5)
% }; \addlegendentry{positivo}
% \addplot[only marks,mark=text,text mark=\T{?},mark options={gray,scale=1}] plot coordinates {
%     (51.6,1.76) (48,1.55) (36,1.55) (38,1.61) (43,1.5)
% }; \addlegendentry{não rotulado}
% \addplot[only marks,mark=text,text mark=\Q{$-$},mark options={red,scale=1}] plot coordinates {
%     (30,1.60)
% }; \addlegendentry{negativo}
% 
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_a}$, mark options={black,scale=1}] plot coordinates {
%     (51.6,1.73)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_d}$, mark options={black,scale=1}] plot coordinates {
%   (48,1.52)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_c}$, mark options={black,scale=1}] plot coordinates {
%   (36,1.52)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_b}$, mark options={black,scale=1}] plot coordinates {
%   (38,1.58)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_e}$, mark options={black,scale=1}] plot coordinates {
%   (43,1.47)};
% 
% \addplot[thick, mark=none, teal] plot coordinates {
%     (54.5,1.86) (35,1.45)
% };
% % \node[small dot,pin=-45:{$\boldsymbol{x^*}$}] at (333,300) {};
% % \node[small dot,pin=45:{$\boldsymbol{x_b}$}] at (290,110) {};
% % \node[small dot,pin=45:{$\boldsymbol{x_a}$}] at (160,110) {};
% \end{axis}
% \end{tikzpicture}
% \caption{O exemplo mais controverso ($\boldsymbol{x_a}$), ou seja, o mais próximo da fronteira, nem sempre é o mais representativo da distribuição dos dados.}
% \label{fig:incerteza_vs_importancia}
% \end{center}
% \end{figure}
% % Density-Weighted Methods
% Por esse motivo existem os métodos baseados em \textbf{ponderação por densidade}\footnote{[\textit{density-weighted}]
% }, que podem, entre outras possibilidades, dividir o espaço de atributos por agrupamentos; ponderar a medida de relevância do exemplo pela sua representatividade na distribuição dos dados; ou escolher o candidato com maior afinidade em relação ao conjunto não rotulado e maior diferença em relação ao conjunto de treinamento \citep{settles2010active}.
% 
% Segundo \cite{settles2008multiple}, os resultados reportados com esse tipo de abordagem se mostraram superiores àqueles não baseados em densidade ou representatividade.
% % conferir??
% Além disso, eles mostram que é viável a manutenção de um registro de densidades pré-computadas com o objetivo de atingir um tempo de processamento similar ao da estratégia de \textit{uncertainty sampling} (a referência natural da área no quesito custo computacional).
% 
% % \subsection{Notas}
% \cite{mccallum1998employing} fazem uso da ponderação por densidade e de comitês (Seção \ref{sec:isolada}) em dados de distribuição estacionária.
% Eles conseguiram bons resultados em bases diversas, chegando a duplicar a acurácia quando comparada a uma seleção por consulta aleatória.
% Esse resultado, relativamente antigo, somado à já citada observação de \cite{settles2008multiple},
% direciona o presente trabalho para o uso de comitês e ponderação da discordância interna (informatividade isolada) por densidade (informativo-representatividade).
% 
% A forma de obtenção das medidas de informatividade é afetada pelas particularidades de cada cenário.
% Eles são descritos na Seção \ref{sec:cenarios}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Considerações}\label{sec:consideracoes-ativo}
% Neste capítulo, foram introduzidos os aspectos básicos do aprendizado de máquina,
% a notação adotada neste documento e os conceitos relevantes para situar o leitor nos próximos
% capítulos.
% % Além disso,
% % uma revisão breve forneceu mais detalhes de como o problema da mudança de conceito tem sido
% tratado na literatura.
% %
% % No geral, o material deste capítulo esboça as particularidades da tarefa que é servida pelo
% aprendizado ativo em estudo: a classificação em fluxos de dados e o uso de \textit{ensembles}.
% % Igualmente, todos os problemas aqui citados afetam as \textit{estratégias de consulta} que são
% abordadas no Capítulo \ref{cap:aprendizado-ativo}.



\red{filosofia roy2001toward:}
Note that this process is not first-order Markov - the optimal query
depends on how many more queries can be made before testing time;
for example, if this is the last query before testing,
the optimal current query may be different than it
is if there are fifty more queries available.