\section{Aprendizado Ativo} \label{aprendizado-ativo}
Activized Learning: Transforming Passive to Active with Improved Label Complexity 2012 Hanneke
First, since we are lacking a complete understanding of the potential capabilities of active learning, we are not yet sure to what standards we should aspire for active learning algorithms to meet, and in particular this challenges our ability to characterize how a ?good? active learning algorithm should behave. Second, since we have yet to identify a complete set of general principles for the design of effective active learning algorithms, in many cases the most effective known active learning algorithms have problem-specific designs (e.g., designed specifically for linear separators, or decision trees, etc., under specific assumptions on the data distribution), and it is not clear what components of their design can be abstracted and transferred to the design of active learning algorithms for different learning problems (e.g., with different types of classifiers,
or different data distributions). Finally, we have yet to fully understand the scope of the relative
benefits of active learning over passive learning, and in particular the conditions under which such
improvements are achievable, as well as a general characterization of the potential magnitudes of
these improvements. In the present work, we take steps toward closing this gap in our understanding
of the capabilities, general principles, and advantages of active learning.
...
REALIZABLE CASE
In the realizable case, there are obvious examples of learning problems where
active learning can provide a significant advantage compared to passive learning ...
 binary search strategy for selecting which examples to request labels for naturally leads to exponential
improvements in label complexity compared to learning from random labeled examples (passive
learning). ?
Disagreement-based methods are sometimes referred to as ?mellow? active learning, since in some
sense this is the least we can expect from a reasonable active learning algorithm; it never requests
the label of an example whose label it can infer from information already available, but otherwise
makes no attempt to seek out particularly informative examples to request the labels of. T
?
Balcan, Hanneke, and Vaughan
(2010) noted that if we do not require the algorithm to be self-verifying, instead simply measuring
the number of label requests the algorithm needs to find a good classifier, rather than the number
needed to both find a good classifier and verify that it is indeed good, then these negative results
vanish. In fact, (shockingly) they were able to show that for any concept space with finite VC
dimension, and any fixed data distribution, for any given passive learning algorithm there is an
active learning algorithm with asymptotically superior label complexity for every nontrivial target
concept!


Learning with few examples: An empirical study on leading classifiers 2011
associa AL com incremental learning
faz ALC com AUC e log2
investiga tipos de AL especificos para poucos exemplos
?
comparar ?bastante? datasets:
The study presented in this paper aims to
study a larger panel of both algorithms (9 different kinds) and
data sets (17 UCI bases).
% http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6033333&tag=1
 

\ing{Aprendizado ativo}{Active learning} é o estudo de máquinas
de aprendizado capazes de se aprimorar fazendo perguntas \citep{series/synthesis/2012Settles}.
A origem do termo remete à Pedagogia, especificamente à forma de ensino centrada no aluno.
A ideia básica é aproveitar a individualidade de cada aluno e seu próprio ritmo de aprendizado.
Assim, ele pode ser auxiliado pelo professor nos aspectos em que experimenta maior dificuldade.
Esse tipo ativo de aprendizado humano - com foco no aluno - tem mostrado evidências
de sua eficácia \citep{michael2006s}.
Analogamente, guardadas as devidas proporções,
pode-se traçar um paralelo com o aprendizado de máquina:
um algoritmo pode usufruir de uma atenção seletiva que
priorize os exemplos mais difíceis para ele em um dado momento.

Em sua forma mais geral, como esboçado por \cite{forman2012programmer},
o aprendizado de máquina ativo pode lançar mão de todo conhecimento que um professor
humano seja capaz de transmitir dentro das limitações de configurabilidade do sistema.
Alguns pontos de configuração seriam, por exemplo:
reescrita do código\footnote{Código escrito na linguagem de
programação que implementa o sistema ou em alguma linguagem específica do domínio.}
de extração de atributos visando maior separabilidade entre as
 classes; composição de expressões regulares para extrair termos adequados de textos técnicos;
e, criação de regras de classificação.
Outras informações, mais diretamente obteníveis do supervisor humano incluiriam
 valores de atributos, classes associadas com atributos, exemplos completos sob demanda e outros.
Em linhas gerais, sua aquisição deve ser guiada por duas noções
 \citep{krishnapuram2011cost}:
preferir aquela para a qual o estado corrente do modelo é incerto e
preferir aquela estimada como a mais relevante.

Dentre as perguntas que as máquinas de aprendizado ativo são capazes de
elaborar, a mais direta é ``\textit{Qual é a classe do exemplo $\bm{x}$?}''.
Dado que a obtenção de um rótulo confiável normalmente é um processo custoso,
o problema de se decidir qual seria o melhor $\bm{x}$ é a
motivação basilar desta tese.
Adicionalmente,
a quantidade de exemplos disponíveis pode ser abundante e o esforço humano disponível limitado -
do professor, no caso da analogia com o aprendizado humano.
Dessa forma, apenas uma parcela criteriosamente escolhida dos exemplos deve
ser rotulada, ou \textit{consultada}, na terminologia de aprendizado ativo.
Essa abordagem se dá em oposição ao
\ing{aprendizado por exemplos}{learning by example} convencional
\citep{journals/cacm/Valiant84}, também chamado de \novo{passivo}.
No aprendizado passivo,
procura-se pelo maior conjunto de treinamento possível ou realiza-se
uma amostragem aleatória.
No primeiro caso, o custo de rotulação pode se tornar proibitivo; no segundo caso,
a decisão quanto à relevância dos exemplos é deixada ao acaso.
Em ambos os casos, dependendo da aplicação,
a construção do conjunto de treinamento pode ser crítica.
Por exemplo, quando a consulta de um exemplo envolve reações químicas
destrutivas, é desejável fazer o mínimo possível de consultas visando um reduzido
custo material.
Similarmente, se o mecanismo rotulador, normalmente chamado de \novo{oráculo},
for um especialista humano ou mesmo um robô \citep{journals/etai/BryantMOKRK01},
é desejável parcimônia nas consultas para não se incorrer num esforço elevado de
atenção humana ou movimento mecânico.
Assim, um direcionamento adequado do esforço de aprendizado tem como resultado um
processo de rotulação mais econômico.
A variedade de abordagens existentes para esse direcionamento são assunto da Seção \ref{estrategias}.
A notação necessária é definida na Seção \ref{notacao}

\input notacao

\section{Estratégias de consulta}\label{estrategias}
Na literatura de aprendizado ativo há diversos sub-casos, cenários e estratégias.
O sub-caso e o cenário de aprendizado ativo mais comuns na literatura,
e onde se situa a presente tese, são a busca por rótulos e
o cenário baseado em \pool, respectivamente - os
cenários alternativos são apresentados no Apêndice \ref{cenarios}.
No caso das estratégias,
elas são frequentemente baseadas em diferentes concepções de relevância de
exemplos ou mesmo diferentes teorias do aprendizado.
A amostragem por incerteza,
por exemplo, assume que os exemplos e seus rótulos pertencem a uma
distribuição de probabilidades - em linha com a teoria do aprendizado
estatístico \citep{books/daglib/0097035};\red{( <- verificar)}
a amostragem por busca no espaço de hipóteses, por sua vez, assume a existência
de hipóteses integrantes de um \ing{\versionspace}{version space} \citep{books/daglib/0087929}
que enquadram ou não cada exemplo. \red{( <- verificar)}
Estratégias agnósticas \citep{journals/jcss/BalcanBL09}, por outro lado,
são independentes de algoritmo de aprendizado. \red{( <- verificar)}
Essa diversidade de embasamentos configura-se praticamente como um \textit{conjunto de paradigmas}
de amostragem ativa cujos principais representantes são apresentados nas
seções seguintes juntamente com suas ordens de complexidade,
\ano{a ordem de complexidade muda se o learner for incremental ou batch}
% espaciais e temporais,
suas principais características e seus princípios de funcionamento.
Na apresentação das ordens de complexidade, é assumido que todos os cálculos
possíveis de serem feitos antes do processo de amostragem já foram realizados
e seus resultados estão disponíveis em memória.
Essa premissa se baseia no cenário especificado na Seção \ref{cenarios}.
Ele garante a disponibilidade de todos os exemplos antes do início da amostragem.
Dessa forma apenas o custo computacional entre consultas se configura como potencial
custo financeiro porque consome o tempo do oráculo.

\tar{há mais alguma adaptação para adotar algum learn ou strat}





% Retomando na Figura \ref{fig:fronteira-vs-aleatoria} o exemplo de espaço de atributos de duas dimensões do Capítulo \ref{cap:intro}, é possível observar o efeito esperado do aprendizado ativo: apenas os exemplos mais difíceis são consultados - aqueles mais próximos da fronteira de decisão.
% \begin{figure}
% \begin{center}
% \begin{tikzpicture}
% \begin{axis}[axis y line=left, xmin=20, xmax=72, ymin=1.45, ymax=1.9, axis x line=bottom, grid, xlabel=peso (kg),   ylabel=altura (m),
% legend style={at={(1.3,1)}},]
%
% \addplot[only marks,mark=text,text mark=\C{$+$},mark options={blue,scale=1}] plot coordinates {(47.5,1.62) (50,1.5) (55.1,1.52) (63.2,1.58) (60.2,1.71) (67,1.73) (59,1.51)};\addlegendentry{positivo}
%
% \addplot[only marks,mark=text,text mark=\Q{$-$},mark options={red,scale=1}] plot coordinates {(30,1.60) (25,1.47) (26.55,1.85) (23,1.64) (24,1.7) (31,1.69) (32,1.76) (50,1.78)(33,1.53)}; \addlegendentry{negativo}
%
% \addplot[thick, only marks,mark=text,text mark=\C{\phantom{\Q{$-$}}},mark options={black, scale=1.1}] plot coordinates {(59,1.51) (50,1.78)}; \addlegendentry{consultados}
%
% \addplot[thick, mark=none, teal] plot coordinates {(20,1.5) (70,1.7)}; \addlegendentry{fronteira}
%
% \addplot[thick, dashed, only marks,mark=text,text mark=\C{\phantom{\Q{$-$}}},mark options={black, scale=1.1}] plot coordinates {(47.5,1.62) (33,1.53)}; \addlegendentry{a consultar}
%
% \addplot[thick, mark=none, teal, dashed] plot coordinates {(34,1.45) (59,1.9)}; \addlegendentry{futura fronteira}
% \end{axis}
% \end{tikzpicture}
% \caption{A consulta de exemplos de fronteira tende a ser mais proveitosa do que a amostragem aleatória. [os rótulos dos exemplos não consultados são desconhecidos, mas são mostrados para fins ilustrativos]}
% \label{fig:fronteira-vs-aleatoria}
% \end{center}
% \end{figure}


% \begin{algorithm}
% \caption{Seleção do classificador com melhor acurácia recente.}
% \label{alg:sbe}
% \Entrada{
% \begin{itemize}
%  \item um fluxo de dados $D$ de exemplos;
%  \item um tamanho de amostra $w$ para a medida de acurácia;
%  \item uma lista $C$ de classificadores;
%  \item um par de funções $treina(c,\langle x,y \rangle)$ e $testa(c,\langle x,y \rangle): \langle C,\langle X,Y \rangle \rangle \rightarrow \{1=acerto,0=erro\}$ aplicáveis a um classificador $c$ dado um par exemplo/rótulo $\langle x,y \rangle$;
% \item uma lista vazia $C_{selecionados}$ de classificadores.
% \end{itemize}
% }
% \Resultado{
% \begin{itemize}
%  \item a lista $C_{selecionados}$ de classificadores preenchida.
% \end{itemize}
% }
% % $C_{selected} \leftarrow \emptyset$
% $B \leftarrow \emptyset$
%
% \lParaCada{$c \in C$} {
%     $A(c) \leftarrow \emptyset$
% }
%
% \ParaCada{$\langle x,y \rangle \in D$}{
%     \lParaCada{$c \in C$}{
%         $treina(c,\langle x,y \rangle)$
%     }
%
%     $B \leftarrow \langle x,y \rangle \cup B$
%
%     \Se{$|B| > w$}{
%         $B \leftarrow B - ultimo(B)$
%
%         \lParaCada{$c \in C$}{
%             $A(c) \leftarrow A(c) - ultimo[A(c)]$
%         }
%     }
%     \lParaCada{$c \in C$, $\langle x_{ts},y_{ts} \rangle \in B$}{
%         $A(c) \leftarrow testa(c,\langle x_{ts},y_{ts} \rangle) \cup A(c)$
%     }
%     $C_{selected} \leftarrow \argmax_c\{   \displaystyle\sum\limits_{}^{}A(c)\}$
% }
% \end{algorithm}
%
% Uma consequência imediata é a menor necessidade de \textit{consultas} ao mecanismo rotulador e, possivelmente, uma maior acurácia.
% Dessa maneira, o aprendizado ativo é indicado nas situações em que o processo de rotulação é custoso em termos de tempo ou de recursos físicos.
% Isso é desejável quando existe uma \textbf{cota}\footnote{[\textit{budget}]}: somente uma parcela do conjunto pode ser rotulada, ela normalmente é definida como um percentual do total de exemplos disponíveis.
%
%
%
%
%
%
% É possível observar na Figura \ref{fig:ap-ativo} um esquema de aprendizado ativo.
% \begin{figure} %[H]
%     \centering
%     \input{imagens/aprendizado-ativo-esquema.tex}
%     \caption{Esquema de aprendizado ativo: as consultas ao oráculo dependem da estratégia adotada e da medida de informatividade $m(\bm{x})$ em que ela se baseia. [um modelo probabilístico é dado como exemplo de classificador base]}
%     \label{fig:ap-ativo}
% \end{figure}
% Cada exemplo $\bm{x}$ é obtido do conjunto de dados não rotulados
% $\mathcal{U}$ e apresentado a um modelo $\theta$ que seja probabilístico, que gere saídas similares diretamente proporcionais a probabilidades ou que forneça alguma outra maneira de se estimar seu grau de confiança.
% Com base no grau de confiança, é possível calcular a medida de informatividade de cada exemplo.
% Esse grau de confiança permite o cálculo da medida de \textit{informatividade}.
%
% A medida de \textbf{informatividade} $m(\bm{x})$ é a base da tomada de decisão da estratégia de consulta e pode ser implementada de diversas maneiras conforme explicado na Seção \ref{sec:isolada}.
% Uma vez definida a medida de informatividade, uma estratégia de consulta precisa ser definida; diferentes estratégias são estudadas na Seção \ref{sec:estrategias}.



\green{apontar parâmetros escolhidos neste trabalho para as estratégias,
quando houver}

\subsection{Amostragem aleatória}
A amostragem aleatória corresponde ao aprendizado passivo aplicado a apenas
uma parte dos exemplos.
Não há uma ordem de preferência ou critério para a realização das
consultas - apenas a aleatoriedade.
Suas principais características são: ser totalmente exploratória, ou seja,
não enfoca nenhuma região especial do espaço de exemplos; e,
ser agnóstica, pois não requer um aprendiz.
Seu custo computacional pode ser considerado nulo.

\subsection{Amostragem por incerteza}\label{unc}
% least confident
Provavelmente a mais simples medida de informatividade
% $Inf(\bm{x})$
para se decidir quando selecionar um exemplo $\bm{x}$
(ou grupo de exemplos, na proposta original) é a máxima probabilidade a posteriori
dada por um modelo probabilístico \citep{journals/sigir/Lewis95a}:
\begin{equation}
P_{max}(\bm{x})=\max_{\bm{y}\in Y}P(\bm{y}|\bm{x})
\end{equation}
Classificadores não probabilísticos e com saídas numéricas podem simular uma
distribuição de probabilidades por meio da aplicação da função sigmoide logística
$g=\frac{1}{1+e^{-\bm{x}}}$
\ano{qual seria uma boa ref para isso?}:
\begin{equation} \label{eqprob}
 P(y_o=1|\bm{x}) = \frac{g(f_o(\bm{x}))}{\sum_{1 \leq p \leq |Y|}g(f_p(\bm{x})) }
\end{equation}

Onde $f_o(\bm{x})$ é a função preditiva da classe $o$ para o exemplo $\bm{x}$;
valores próximos de $1$ indicam pertinência à classe e próximos de $0$, o oposto.

A estratégia de amostragem por incerteza consiste em consultar o exemplo
mais informativo $\bm{x}^*$,
ou seja, aquele com a menor $P_{max}(\bm{x})$,
com o intuito de se explorar a fronteira de decisão no espaço de exemplos, conforme
Equação \ref{equnc}.
A complexidade dessa estratégia é $\mathcal{O}(1)$ - equivalente
a apenas um treinamento por consulta.
\begin{equation} \label{equnc}
 \bm{x}^*= \argmin_{\bm{x}\in\mathcal{U}}P_{max}(\bm{x})
\end{equation}


\subsection{Amostragem por margem ou entropia}\label{mar}
Em problemas multiclasse, o menor $P_{max}(\bm{x})$ pode não indicar o exemplo
mais controverso, pois pode existir um exemplo com duas ou mais classes igualmente prováveis,
porém com maior $P_{max}(\bm{x})$.
A medida da margem, apresentada nas Equações \ref{eqz} e \ref{eqmar},
evita esse problema utilizando o valor da diferença entre as duas maiores probabilidades.
Outra possibilidade é a medida de entropia normalizada
\citep{journals/bioinformatics/LewinSA0P04}, apresentada na \ref{eqent}.
\begin{eqnarray} \label{eqz}
\bm{z}=\argmax_{\bm{y}\in Y}P(\bm{y}|\bm{x})
\\
M(\bm{x})=P(\bm{z}|\bm{x})-\max_{\bm{y}\in Y\setminus\{\bm{z}\}}P(\bm{y}|\bm{x})
\label{eqmar}
\end{eqnarray}
\begin{equation} \label{eqent}
E(\bm{x})=-\log^{-1}|Y|\sum_{\bm{y}\in Y}P(\bm{y}|\bm{x})\log(P(\bm{y}|\bm{x}))
\end{equation}


\subsection{Busca no espaço de hipóteses}\label{sgnet}
É possível fazer uma amostragem ativa baseada na perspectiva do espaço de hipóteses.
A intuição dessa abordagem é que os exemplos mais importantes residem na região onde
as hipóteses se contradizem.
Isso equivale a consultar os exemplos que reduziriam o \versionspace 
\citep{books/daglib/0087929} depois de inseridos no conjunto de treinamento.
A busca no espaço de hipóteses é feita pelo acompanhamento das hipóteses
mais específicas e as mais gerais pertencentes aos conjuntos $S$ e $G$ de todas as hipóteses possíveis,
denominadas $h_S \in S$ e $h_G \in G$, respectivamente.
\tar{colocar figura? para esse texto confuso fazer sentido e evitar formalismo do mittchel}
Uma característica distintiva deste paradigma com relação aos demais neste capítulo é
seu \textbf{modelo de decisão binário}: todos os exemplos controversos são considerados
igualmente informativos,
podendo ser consultados em qualquer ordem ou em lotes.

\textit{SG-network} \cite{journals/ml/CohnAL94},
também chamado de CAL \citep{journals/tcs/Dasgupta11} em referência a seus proponentes,
é baseado na busca no espaço de hipóteses e foi um dos primeiros algoritmos de aprendizado ativo.
Ele faz uma aproximação para ser capaz de induzir os modelos específico
$\theta_S$ e geral $\theta_G$, pois a quantidade de hipóteses possível pode ser infinita.
A aproximação é feita pela geração ou amostragem de \ing{exemplos de fundo}{background instances}
e rotulação artificial deles de acordo com a meta desejada de treinamento:
especificidade ou generalidade.
Depois de criados os modelos iniciais, eventuais exemplos que causem desacordo entre $\theta_S$ e $\theta_G$
são selecionados para consulta.
Duas redes \ing{perceptron multicamadas}{multilayer perceptron} \citep{haykin2004comprehensive}
foram empregadas no trabalho original,
mas qualquer classificador apto a lidar com exemplos ponderados poderia ser usado.
A ordem de complexidade das estratégias desse paradigma é $\mathcal{O}(|Y|)$.


 \ano{feature: decisão de consulta é binária, há o cjt dos consultáveis e o dos não consultáveis
 sem uma ordem de relevância para os consultáveis}

 \ano{feature: é parcialmente exploratório, pois requer sorteio na área de desacordo}

\ano{feature: dependente de algoritmo de aprendizado}

\ano{definição da sequência de consultas é gradual}

\ano{feature: próxima consulta depende dos rótulos anteriores}

Existem outras três abordagens, baseadas em \svm que podem ser interpretadas como
uma busca de sucessivas divisões no \versionspace \cite{tong2002support}:
\ing{margem simples}{simple margin}, \ing{margem maxmin}{maxmin margin} e
\ing{margem razão}{ratio margin}.
Sob outra ótica, elas podem também serem vistas como um tipo de
amostragem por incerteza, vista na seção anterior.


\ano{há mais detalhes de sgnet comentados no arquivo tex}
%  \red{infos dos txts sobre SG-network cohn1994improving:}
% \esb{Se concentra em membership queries, cita angluin86 e valiant84.
% Em problemas formais, como encontrar uma fronteira no "unit line interval"
%  requer O(1/e ln(1/e))
% exemplos de treinamento aleatórios para se atingir um erro 'e'.
% Se for permitida a síntese de membership queries, 'e' pode ser atingido em O(ln(1/e)).
% Formaliza o aprendiz capaz de determinar a região de incerteza e nomeia como
% Selective Sampling.
% Pode-se calcular a região de inc. em lotes para reduzir a complexidade.
% Apresenta primeiro "a naive neural network querying algorithm":
% 0.1 < o < 0.9 = exemplo na região de incerteza
% judd88 diferencia configuração de arquitetura da MLP.
% Uma única rede pode descrever apenas um conceito, ou seja, uma pequena parte da região de incerteza,
% principalmente porque a MLP tende a ser excessivamente confiante em diversas partes do espaço de
% atributos.
% Os tamanhos dos conjuntos S e G crescem exponencialmente com o número de exemplos. O mesmo é válida
% para a quantidade de configurações de redes.
% Propõe a SG-network baseado em busca do version-space do mitchel82.
% Usa o conceito de "partial ordering in generality of the concepts".
% The version space (space of plausible queries) is reduced with every query.
% Ver algoritmo na página 10.
% Eles propõe mesclar s e G numa só rede.
% Na prática, em conjuntos grandes, é mais eficiente retreinar a rede do zero quando novos exemplos
% são adicionados.
% Experimentos:
% o problema do (par de) triângulo
% --------------------
% topologia 2-8-3-1
% 
% 12 redes treinadas inicialmente com 10, 20, ..., 150 pontos.
% Compara com random e com naive mlp.
% Plota o espaço de parâmetros com a fronteira de decisão criada pela rede comparada com a
%  fronteira real (há também os exemplos + e - espalhados inutilmente).
% Plota error X queries.
% Compararou erros com diferença significativa com mais de 90% de confiança.
% }
% \red{-------------------------- fim das info}

% 
% \subsection{Query by Committee}
% Committees, also called ensemble-based classifiers,
% are combinations of models whose united predictions are meant to achieve better accuracy than a
% single model.
% Query by Bagging and Query by Boosting are two examples of active learning committees
% \cite{conf/icml/AbeM98}.
% Depending on the member models output,
% several measures of disagreement are possible.
% % The possibility to take measures about the \textbf{disagreement between concurrent hypotheses},
% % rather than a single model probability output, is the main feature of this strategy.
% 
% % In data-based ensembles, subsampling techniques are the most popular,
% % specifically \textit{boosting} and \textit{bagging}.
% % While boosting \cite{schapire1990strength} explores instances uncovered
% % (incorrectly classified) by previous models to generate the next one,
% % bagging \cite{breiman1996bagging} tries to force different biases by randomly
% % selecting considerably different subsets of instances for each classifier.
% % In the active learning context,
% % the several flavors of Query by Committee are similar to both uncertainty sampling and
% \textit{query by disagreement}.
% % They unite the localized notion of uncertainty from the former with the multiple opinions from
% the latter into a single measure.
% % Due to its enforced diversity, \textit{Decorate} ensembles are also worth to mention.
% %
% In this paper,
% % \textit{soft vote entropy} \cite{settles2012active} is considered when generating queries from
% committees apart from the fact that non-probabilistic classifiers like decision trees are adopted
% instead of probabilistic ones.
% since the base learning algorithms of all strategies are not ensembles,
% a comparison that includes \textit{Query by Committee} is deferred to future work.
% Moreover, a fair comparison between strategies requires the same base learner,
% otherwise accuracies of classifiers trained on the actively sampled instances could not be
% compared.
% % Additionally, JS-divergence is implemented for Random Forest.
% 
% % More elaborate measures quantify the difference/spread between the probability distribution of
% the ensemble as a whole and its members;
% % two such measures are \textit{JS-divergence} and \textit{KL-divergence}.
% % They have been described as good measures to achieve accurate class probability estimates
% \cite{melville2004diverse}. %mccallum1998employing}.
% 
% The complexity of Query by Committee is considered here as $\mathcal{O}(1)$,
% if the ensemble is seen as a single base learner or $\mathcal{O}(M)$, if the number of members $M$
% is considered.


\subsection{\Eer}
A estratégia de redução de erro adotada neste trabalho é baseada no
\ing{exemplo de redução de entropia}{entropy reduction example} proposto por
\cite{conf/ijcai/GuoG07}.
É um método que busca pelo exemplo que mais reduz a entropia na predição geral
do modelo para todo o conjunto de dados;
considera, assim, implicitamente a informação sobre eventuais agrupamentos subjacentes,
evitando depender apenas dos escassos exemplos rotulados.
% Essa variante de estratégias de redução de erro foi adotada dado que uma performance superior à
% original foi reportada pelos autores.

Para cada exemplo candidato com vetor descritivo $\bm{x}$
obtido da reserva $\mathcal{U}$,
sua classe mais provável,
representada pelo vetor preditivo $\bm{y}'$, é calculada de forma
otimista:
\begin{equation}
 \bm{y}' = \argmin_{\bm{y}}{\sum_{\bm{u} \in \mathcal{U}} O(\bm{x}, \theta_{\mathcal{L}\cup
\{\langle\bm{u},y\rangle\}})}
\end{equation}
onde $O$ é a função objetivo.
A complexidade computacional é $\mathcal{O}(|Y||\mathcal{U}|^2)$.
\ano{está correto colocar duas variáveis com potências diferentes em $\mathcal{O}$?}
Após cada consulta, caso a classe real seja diferente da esperada,
o método recorre à estratégia de amostragem por incerteza (Seção \ref{unc})
como medida de contingência.
Para contemplar problemas multiclasse,
a amostragem por margem (Seção \ref{mar}) foi utilizada nos experimentos deste trabalho.
 
Neste trabalho, seguindo a escolha do artigo original,
optou-se pela entropia como função objetivo.
\ano{verificar se ficaram mesmo as duas; balacc é melhor que kappa porque não zera tão fácil?}
Adicionalmente, a acurácia balanceada (Seção \ref{metricas})
foi adotada como uma variação do método,
visando agir diretamente nas medidas multiclasse de interesse apresentadas na
Seção \ref{metricas}.
Apenas cem exemplos foram amostrados de $\mathcal{U}$ em cada iteração devido ao
alto custo computacional da estratégia.

\ano{feature: dependente de algoritmo de aprendizado}

\ano{definição da sequência de consultas é gradual}

\ano{feature: próxima consulta depende dos rótulos anteriores}


\subsection{Impacto esperado no modelo}

\ano{feature: dependente de algoritmo de aprendizado}

\ano{definição da sequência de consultas é gradual}

\ano{feature: próxima consulta depende dos rótulos anteriores}

\subsection{Amostragem ponderada por densidade}\label{dw}
A proposta geral das amostragens ponderadas por densidade é o uso da medida de
\textit{densidade de informação}, que atribui diferentes pesos à medida de
informatividade conforme o nível de concentração de exemplos não rotulados no entorno de $\bm{x}$
\citep{settles2008curious}:
\begin{equation}\label{eqid}
 ID(\bm{x}) = Inf(\bm{x})\frac{1}{|\mathcal{U}|} \sum_{\bm{u} \in \mathcal{U}} sim(\bm{x},\bm{u})
\end{equation}
Seu desdobramento natural é a \textit{utilidade de treinamento},
que é a densidade de informação inversamente ponderada pela concentração de exemplos rotulados,
resultando num afastamento das regiões mais consultadas
\citep{journals/coling/FujiiITT98}:
\begin{equation}\label{eqtu}
 TU(\bm{x}) = ID(\bm{x}) (\sum_{\bm{l} \in \mathcal{L}} sim(\bm{x},\bm{l}))^{-1}
\end{equation}


Qualquer medida de similaridade $sim(\bm{x},\bm{u})$
e de informatividade $H(\bm{x})$ podem ser adotadas.
Neste trabalho, $Inf(\bm{x}) = 1 - M$ e três medidas de distância $d(\bm{x},\bm{u})$
(euclidiana, Manhattan e Mahalanobis) foram transformadas em medidas de similaridade
$sim(\bm{x},\bm{u})$ pela fórmula \ref{eq:sim}.
\begin{equation}\label{eq:sim}
 sim(\bm{x},\bm{u}) = \frac{1}{1 + d(\bm{x},\bm{u})}
\end{equation}

A ordem de complexidade é $\mathcal{O}(1)$, se os $|\mathcal{U}|^2$ cálculos de distância forem
devidamente armazenados em memória para futuro acesso rápido.

\ano{explicar como empreguei mahalanobis}
\ano{expoentes ponderadores nem são mencionados}

\ano{feature: dependente de algoritmo de aprendizado}

\ano{definição da sequência de consultas é gradual}

\ano{feature: próxima consulta depende dos rótulos anteriores}

\subsection{Amostragem por agrupamento}
O processo de aprendizado pode explorar agrupamentos naturais na \pool,
pois são independentes da existência de rótulos.
Essa abordagem é uma alternativa à realização de consultas que enfocam a fronteira de decisão ou
o manejo de hipóteses citados anteriormente.
Uma importante representante desse paradigma é a \textit{amostragem hierárquica}
proposta por \cite{journals/tcs/Dasgupta11} baseada em
agrupamento hierárquico \citep{journals/cj/Murtagh83}.
O método de agrupamento hierárquico organiza os exemplos numa hierarquia que pode
ser representada por uma árvore.
Cada nó folha simboliza um exemplo e cada nó pai representa uma relação de
proximidade/similaridade entre seus filhos.
Os filhos, por sua vez, podem ser exemplos isolados ou novas relações.
Qualquer nó tem o potencial de ser visto como o grupo dos exemplos representados
pelos nós folhas mais abaixo na hierarquia.
Na árvore como um todo, as diferentes podas possíveis definem a organização em grupos.
\ano{figura}

A amostragem hierárquica faz uso da árvore para definir a relevância dos exemplos.
Eles têm maior probabilidade de serem consultados se pertencerem aos grupos
mais impuros e representativos.
A implementação original do autor foi adotada neste trabalho com o mesmo
algoritmo de agrupamento chamado
\textit{Ward's average linkage method}\footnote{
Implementação disponível no Weka \cite{journals/sigkdd/HallFHPRW09}.}
\ano{como traduzir?}

\tar{dar mais detalhes? replicar o algoritmo(ele tem formulas por todo o texto))?
essa abordagem é complexa}.

\esb{clust. hierar. - explica o que é agrupamento hierárquico}

\ano{Aplicar Ward no Weka. Gerar SVG e citar
http://www.trex.uqam.ca/view.php
usando em alguma base 2D interessante. Gerar com e sem ramos proporcionais.
Gravei SVGs no PC de casa.}
\ano{feature: agnóstica}

\ano{definição da sequência de consultas é gradual}

\ano{feature: próxima consulta depende dos rótulos anteriores}

% Há diferentes propostas para a determinação de quais exemplos são informativos para consulta.
% Por conveniência, aqui elas estão separadas entre aquelas baseadas na análise de \textit{informatividade isolada} de cada exemplo, aquelas baseadas na \textit{informatividade conjunta} e aquelas baseadas numa análise que combina \textit{informatividade com representatividade}.
% Cada uma das três tem uma perspectiva própria, portanto devem ser vistas como não excludentes entre si; ou seja, elas estão sujeitas a sobreposição, especialmente da primeira em relação às demais.
% 
% \subsection{Informatividade isolada}\label{sec:isolada}
% Uma medida isolada se baseia numa informação extraída do modelo quando apresentado a um exemplo candidato.
% 
% Em classificadores probabilísticos, como é o caso do \textit{Naive Bayes} \citep{duda2001pattern},
% é possível selecionar os exemplos mais relevantes pelos valores de probabilidade condicional atribuídos pelo modelo.
% Essa estratégia é conhecida como \textbf{\textit{uncertainty sampling}}\footnote{[amostragem por incerteza]
% } \citep{lewis:1994:SAT:188490.188495}.
% Ela é simples e bastante difundida.
% Nela, o exemplo com a probabilidade de pertencer à classe mais provável mais próxima de $0,5$ é considerado o candidato ideal a ser enviado ao oráculo.
% No caso com mais de duas classes, pode-se medir a entropia 
% CITAR
% ou considerar a diferença entre os valores de probabilidade dos dois rótulos melhor cotados. Essa variação é conhecida como \textit{margin sampling} \citep{scheffer2001active}.
% Tem sido argumentado que a margem é mais indicada quando se desejar reduzir o erro de classificação, enquanto que a entropia é mais indicada quando se deseja aperfeiçoar a resposta probabilística do modelo CITAR.
% 
% 
% Árvores de decisão \citep{quinlan1993c4}, $k$-vizinhos mais próximos \citep{aha1991instance} e máquinas de vetores de suporte \citep{cristianini2000introduction} também têm sido usados para a estratégia de \textit{uncertainty sampling}.
% A medida de incerteza, nesses casos, pode ser respectivamente: a pureza do nó, a proporção de vizinhos positivos e a distância exemplo-fronteira \citep{settles2010active}.
% 
% % Expected Model Change
% O futuro impacto de um exemplo sobre o modelo, chamado de \textit{\textbf{expected model change}}\footnote{[mudança esperada no modelo]
% }, também é uma indicação razoável de sua possível contribuição para o aprendizado.
% A maneira proposta por \cite{settles2008multiple} é o \textit{\textbf{expected gradient length}}\footnote{[comprimento esperado do gradiente]
% }.
% Ela se aplica a modelos baseados na técnica de gradiente descendente:
% %citar???
% deve ser escolhido para treinamento o exemplo capaz de contribuir com uma descida de maior magnitude.
% Como o rótulo não é sabido de antemão, usa-se a soma das contribuições de cada rótulo ponderada pelas respectivas probabilidades condicionais.
% 
% % Query-By-Committee
% Por fim, a \textbf{consulta por comitê}\footnote{[\textit{query-by-committee}]
% }, facilitada pela própria natureza dos \textit{ensembles}, privilegia os exemplos a respeito dos quais há maior discordância entre os modelos-membro \citep{seung1992query}.
% NOVAMENTE, VERIFICAR ENTROPIA, SE É EQUIVALENTE
% 
% \textit{Active-Decorate} \citep{melville2004diverse} é uma estratégia de aprendizado ativo baseada em \textit{ensemble} do tipo \textit{Decorate} \citep{melville:phd2005}; ela mede a margem das duas maiores probabilidades a posteriori dadas pelo comitê como um todo - uma adaptação da margem de votos usada por \citet{mamitsuka1998query}.
% \textit{Ensembles Decorate} foram reportados recentemente \cite{zhang2012empirical} como superiores a \textit{Boosting} e \textit{Bagging} na escassez de exemplos de treinamento e equivalentes nas demais situações.
% Por isso, é um forte candidato para ser o classificador base do aprendizado ativo, especialmente em casos de cota reduzida.
% \textit{Adaboost} melhor para conjuntos maiores. \textit{Random forests} 
% Os mesmos autores reportaram que \textit{JS-Divergence}\footnote{
%   \textit{JS-divergence} é uma versão simétrica e suavizada de \textit{KL-divergence} \citep{settles2012active}.
% }, além de mais complexa, é menos efetiva em termos de acurácia do que a medida de margem proposta.
% 
% !!passar para um capitulo mais adequado!!
% Decomposição viés-variância do erro.
% Ruído intrínseco é o erro esperado do preditor bayesiano ótimo\cite{zhang2012empirical}.
% Viés é o desvio sistemático normalmente esperado ao longo de diferentes experimentos (diferentes conjuntos de treinamento).
% Variância é a variabilidade esperada em torno do viés dados diferentes experimentos.
% 
% 
% 
% ???Essa é a medida de informatividade isolada adotada na proposta ??ainda é?? (Capítulo \ref{cap:plano}),
% pois é independente da forma de composição do \textit{ensemble}.
% Isso abre a possibilidade de aplicação das diversas técnicas enumeradas na
% Seção \ref{sec:ensemble}.
% O uso dessa medida pode ser parte de outras medidas mais complexas como as mencionadas nas Seções \ref{sec:conjunta} e \ref{sec:inf_representativa}.
% 
% 
% % \citep{dagan1995committee} HMM, part of speech
% % \citep{freund1997selective} mesma laia do dagan e seung, mas mais comprido
% 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Informatividade conjunta}\label{sec:conjunta}
% Uma medida conjunta se baseia em uma informação extraída do modelo quando,
%  além do exemplo candidato sob análise, os candidatos restantes também são utilizados.
% 
% % Expected Error Reduction
% A intensidade de redução no erro de generalização, por exemplo,
%  é uma medida sugestiva quanto à utilidade de um exemplo.
% Ela foi proposta por \cite{roy2001toward} em uma abordagem chamada
% \textit{\textbf{expected error reduction}}\footnote{[redução do erro esperado]
% }.
% Ela assume que os exemplos não rotulados restantes podem ser usados
%  como conjunto de validação desde que as predições atuais para eles
%  sejam consideradas como os rótulos verdadeiros - ou como probabilidades
%  condicionais se for o caso do classificador.
% % citar SVM e outros modelos???
% A medida do erro de generalização é custosa, com ordem de complexidade
%  de pelo menos $\mathcal{O}(|U||L|)$, o que torna desejável alguma maneira de estimá-lo.
% 
% % Variance Reduction
% Uma forma indireta de se fazer a minimização do erro de generalização
%  é a \textbf{redução da variância}\footnote{[\textit{variance reduction}]
% }.
% Apesar do enfoque diferente, a ordem de complexidade continua sendo um
% problema, pois depende quadraticamente do número de parâmetros do modelo.
% Mesmo quando se reduz essa complexidade por amostragem, redução de
%  dimensionalidade, etc., essa abordagem, assim como outras de medidas conjuntas, permanece empiricamente muito mais lenta que medidas isoladas como \textit{uncertainty sampling} \citep{settles2010active}.
% 
% Métodos mais promissores são descritos na Seção \ref{sec:inf_representativa}.
% 
% \subsection{Informativo-representatividade}\label{sec:inf_representativa}
% A incerteza a respeito do rótulo de um exemplo não é necessariamente indicativa da importância do mesmo.
% Isso pode ser notado na Figura \ref{fig:incerteza_vs_importancia}.
% O exemplo mais controverso é $\boldsymbol{x_a}$ - aquele mais próximo da fronteira de decisão.
% Apesar disso, qualquer dos exemplos $\boldsymbol{x_b}$, $\boldsymbol{x_c}$, $\boldsymbol{x_d}$ ou $\boldsymbol{x_e}$ discriminaria melhor a região onde a maioria dos dados se encontra.
% \begin{figure}
% \begin{center}
% \begin{tikzpicture}
% \begin{axis}[axis y line=left, xmin=20, xmax=72, ymin=1.45, ymax=1.9, axis x line=bottom, grid, xlabel=peso (kg),   ylabel=altura (m)]
% \addplot[only marks,mark=text,text mark=\C{$+$},mark options={blue,scale=1}] plot coordinates {
%     (50,1.5)
% }; \addlegendentry{positivo}
% \addplot[only marks,mark=text,text mark=\T{?},mark options={gray,scale=1}] plot coordinates {
%     (51.6,1.76) (48,1.55) (36,1.55) (38,1.61) (43,1.5)
% }; \addlegendentry{não rotulado}
% \addplot[only marks,mark=text,text mark=\Q{$-$},mark options={red,scale=1}] plot coordinates {
%     (30,1.60)
% }; \addlegendentry{negativo}
% 
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_a}$, mark options={black,scale=1}] plot coordinates {
%     (51.6,1.73)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_d}$, mark options={black,scale=1}] plot coordinates {
%   (48,1.52)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_c}$, mark options={black,scale=1}] plot coordinates {
%   (36,1.52)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_b}$, mark options={black,scale=1}] plot coordinates {
%   (38,1.58)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_e}$, mark options={black,scale=1}] plot coordinates {
%   (43,1.47)};
% 
% \addplot[thick, mark=none, teal] plot coordinates {
%     (54.5,1.86) (35,1.45)
% };
% % \node[small dot,pin=-45:{$\boldsymbol{x^*}$}] at (333,300) {};
% % \node[small dot,pin=45:{$\boldsymbol{x_b}$}] at (290,110) {};
% % \node[small dot,pin=45:{$\boldsymbol{x_a}$}] at (160,110) {};
% \end{axis}
% \end{tikzpicture}
% \caption{O exemplo mais controverso ($\boldsymbol{x_a}$), ou seja, o mais próximo da fronteira, nem sempre é o mais representativo da distribuição dos dados.}
% \label{fig:incerteza_vs_importancia}
% \end{center}
% \end{figure}
% % Density-Weighted Methods
% Por esse motivo existem os métodos baseados em \textbf{ponderação por densidade}\footnote{[\textit{density-weighted}]
% }, que podem, entre outras possibilidades, dividir o espaço de atributos por agrupamentos; ponderar a medida de relevância do exemplo pela sua representatividade na distribuição dos dados; ou escolher o candidato com maior afinidade em relação ao conjunto não rotulado e maior diferença em relação ao conjunto de treinamento \citep{settles2010active}.
% 
% Segundo \cite{settles2008multiple}, os resultados reportados com esse tipo de abordagem se mostraram superiores àqueles não baseados em densidade ou representatividade.
% % conferir??
% Além disso, eles mostram que é viável a manutenção de um registro de densidades pré-computadas com o objetivo de atingir um tempo de processamento similar ao da estratégia de \textit{uncertainty sampling} (a referência natural da área no quesito custo computacional).
% 
% % \subsection{Notas}
% \cite{mccallum1998employing} fazem uso da ponderação por densidade e de comitês (Seção \ref{sec:isolada}) em dados de distribuição estacionária.
% Eles conseguiram bons resultados em bases diversas, chegando a duplicar a acurácia quando comparada a uma seleção por consulta aleatória.
% Esse resultado, relativamente antigo, somado à já citada observação de \cite{settles2008multiple},
% direciona o presente trabalho para o uso de comitês e ponderação da discordância interna (informatividade isolada) por densidade (informativo-representatividade).
% 
% A forma de obtenção das medidas de informatividade é afetada pelas particularidades de cada cenário.
% Eles são descritos na Seção \ref{sec:cenarios}.

\subsection{Outras estratégias}
Os códigos originais dos autores das seguintes estratégias \textit{margem simples},
\textit{self-conf}, \textit{KFF} e \textit{balancedEE}
\citep{journals/jmlr/TongK01,journals/jmlr/BaramEL04,conf/icdm/OsugiKS05}
foram adaptados para contemplar problemas multiclasse por meio da aplicação de
\ing{rodízio}{round-robin} entre sub-estratégias.
A cada sub-estratégia foi atribuída uma classe principal,
na configuração \textit{um para muitos}.
Porém tal configuração resultou em estratégias excessivamente
piores que a amostragem aleatória.
Isso poderia ser um indício de problemas na implementação original ou na adaptação,
ou mesmo da ineficácia do rodízio.
Por esses motivos elas foram excluídas deste trabalho.

\ano{Não implementei Variance reduction pois exige um sistema muito complexo
e com otimizações e ainda assim é ordens de magnitude mais lento que  Unc. Sampl.}
% os experimentos.

\tar{outras - mencionar as que ficaram de fora (Beygelzimmer)}

%mais detalhes sobre essas estratégias:
% Online choice of active learning algorithms
% A simple active-learning heuristic based on ``farthest-first'' traversal sequences
%                     in kernel space. Farthest-first (FF) sequences have been previously used for computing provably
%                     approximate optimal clustering for k-center problems (Hochbaum and Shmoys, 1985). The FF
%                     traversal of the points in a data set is defined as follows. Start with any point x and find the farthest
%                     point from x. Then find the farthest point from the first two (where the distance of a point from a set
%                     is defined to be the minimum distance to a point in the set), etc. In any metric space, FF traversals
%                     can be used for computing 2-approximation solutions to the k-center clustering problem in which
%                     one seeks an optimal k-clustering of the data and optimality is measured by the maximum diameter
%                     of the clusters. In particular, by taking the first k elements in the FF traversal as ``centroids`` and then
%                     assigning each other point to its closest ``centroid``, one obtains a k-clustering whose cost is within
%                     a factor 2 of the optimal (Hochbaum and Shmoys, 1985).
% 
%                  * Parece que é o sucessor do MAB3.
%                  * The idea is similar to COMB (by Luz et. al.). We use two learners:
%                  * SIMPLE and KFF. the latter exploits and the former explores the data.
%                  * the context switch between the two methods is done randomly using a biased coin.
%                  * the bias is dynamically chosen and reflects the `effectivness' of exploration,
%                  * which is measured by a distance function between two hypothesis.
%                  *
%                  * the implemention corresponds the paper:
%                  * Thomas Osugi, Deng Kun, and Stephen Scott.
%                  * Balancing Exploration and Exploitation: A New Algorithm for Active Machine Learning.
%                  * In Proceedings of the Fifth IEEE International Conference on Data Mining. November 2005.
%                  */

\subsection{Considerações}
\ano{deixar aqui apenas as da literatura, depois repeti-las junto com as propostas numa outra tabela
no prox capitulo}

\begin{table}
\caption{Características de cada estratégia.
\textit{A ordem de complexidade é dada conforme a quantidade de exemplos
a aprender para viabilizar cada consulta. \ano{é aceito O(0)?}}
}
\scalebox{0.88}{
\begin{tabular}{c|c|c|c|c|c}
\textbf{estratégia} & \textbf{\makecell{forma\\ de busca}}&\textbf{\makecell{presença \\de aprendiz}} & \textbf{\makecell{definição da \\sequência de \\consultas}} & \textbf{\makecell{dependência\\entre\\consultas}}&\textbf{\makecell{ordem de\\complexidade}}\\ \hline
Rnd & \makecell{exploratória\\aleatória} & \makecell{agnóstica}&autônoma&nenhuma&$\mathcal{O}(0)$\\ \hline
Clu&\makecell{balanceada:\\exploratória e\\prospectiva}& agnóstica&interativa&total&\makecell{não\\especificada}\\ \hline
\makecell{Unc/Mar/Ent\\DW}&prospectiva&gnóstica&interativa&total&$\mathcal{O}(1)$\\ \hline % EMC
EER&prospectiva&gnóstica&interativa&total&$\mathcal{O}(|Y||\mathcal{U}|^2)$\\ \hline
SGmulti&\makecell{exploratória\\limitada e\\aleatória}&gnóstica&interativa&total&$\mathcal{O}(|Y|)$\\ \hline
TU&\makecell{balanceada:\\exploratória e\\prospectiva}&gnóstica&interativa&\makecell{após etapa\\exploratória}&$\mathcal{O}(1)$\\ \hline
ATU&\makecell{exploratória\\ponderada}&agnóstica&autônoma&nenhuma&$\mathcal{O}(0)$\\ \hline
GATU&\makecell{em fases:\\exploratória e\\prospectiva}&\makecell{em fases:\\agnóstica e\\gnóstica}&interativa&\makecell{após etapa\\exploratória}&$\mathcal{O}(1)$\\ \hline
GATU&\makecell{alternada:\\exploratória e\\prospectiva}&\makecell{alternada:\\agnóstica e\\gnóstica}&interativa&frequente&$\mathcal{O}(1)$\\ \hline
\end{tabular}
}
\end{table}

\ano{diferencia de aprendizado semisuperv. colocar algoritmos se der tempo;
apresenta cada uma com uma figura padrão ilustrando sua particularidade}

\tar{usar semisupervised somente na fase de predição não faria muito sentido.
usar semisupervised no learner faz sentido pelo fato de se ter tantos exemplos
unlabeled à disposição}

\tar{citar relação com crowd sourcing/labeling?}

