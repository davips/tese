\chapter{Metodologia}\label{metodologia}
Foi empreendida uma avaliação experimental para identificar os pontos
críticos na escolha de estratégias e também para comprovação empírica das propostas
dos capítulos \ref{propostas} e \ref{aml}.
Para haver solidez estatística e também para uma boa representatividade dos
variados domínios existentes em aplicações reais, foram selecionadas as
cem bases de dados mais diversas
do projeto de \cite{doi/ucipp} que é baseado no repositório UCI \citep{bache2013uci}.
Porém, apenas noventa e quatro \ano{conferir} bases foram viáveis com relação a
tempo de processamento e puderam ter seus experimentos terminados.
O critério de diversidade envolveu manter apenas uma dentre cada grupo de bases de um
mesmo domínio - com exceção de algumas que tivessem características
(atributos, classes e número de exemplos)
suficientemente diferentes ou cuja acurácia passiva fosse suficientemente distinta para pelo
menos três dos classificadores mencionados na Seção \ref{learners}.

\ano{ilustrar o uso de banco de dados, a hierarquia de classes das estratégias;
fluxograma de 4 fases: queries, hits, measures, sumarização (médias/friedmans = latex)}

\tar{demsar usa (0.000, +-0.005)  no exemplo}

% Nesse artigo é discutido o fato do Friedman ignorar as diferenças entre modelos (http://www.r-bloggers.com/beware-the-friedman-test/):
% @article{zimmerman1993relative,
%   title={Relative power of the Wilcoxon test, the Friedman test, and repeated-measures ANOVA on ranks},
%   author={Zimmerman, Donald W and Zumbo, Bruno D},
%   journal={The Journal of Experimental Education},
%   volume={62},
%   number={1},
%   pages={75--86},
%   year={1993},
%   publisher={Taylor \& Francis}
% }

\section{Descrição das bases}
As bases de dados têm suas características expostas no Apêndice \ref{detalhes}
(tabelas \ref{tab:datasetsa},
\ref{tab:datasetsb} e \ref{tab:datasetsc}).
Para maior clareza do tipo de diversidade das bases, alguns grupos especiais foram
criados da seguinte forma:
\begin{itemize}
 \item bases com mais de quatro vezes mais exemplos na classe
majoritária do que na minoritária (Tabela \ref{tab:imb})
 \item bases com mais de cinquenta atributos (Tabela \ref{tab:x})
 \item bases com mais de cinco classes (Tabela \ref{tab:y})
 \item bases com mais de mil exemplos (Tabela \ref{tab:n})
 \item bases com menos de quatrocentos exemplos (Tabela \ref{tab:nm})
\end{itemize}

\input dataset-tables-reduxes

É possível notar a presença de atributos nominais, por exemplo, na Tabela \ref{tab:datasetsa}.
Os algoritmos de aprendizado providos pela ferramenta
Weka \citep{journals/sigkdd/HallFHPRW09}
fizeram eventual uso de seus próprios filtros internos para lidar com esse tipo de atributo,
mas as \elms e as estratégias baseadas na métrica de distância de Mahalanobis precisaram ser
transformadas com a substituição de atributos nominais por numéricos e pela aplicação do
\ing{filtro de padronização}{z-score} \citep{kreyszig2007advanced}
para possibilitar os cálculos e para evitar matrizes mal condicionadas - respectivamente.

\ano{exemplos repetidos foram removidos,
mas mantido um deles com a moda dos rótulos}

\ano{A quantidade de atributos da base Arcene foi reduzida para 998 devido
a restrições de armazenamento do sistema gerenciador de banco de dados}

\tar{
Experiments with Random Projection 2000
http://cseweb.ucsd.edu/~dasgupta/papers/randomf.pdf
;;;;;;
preferem RP(O(n)) a PCA (O(n3));
;;;;;
é uma boa justificativa para ELM, e bom para reduzir
rapidamente as dimensões de bases enormes para o limite de 1000 do mysql.
;;;;;;
 Randomness is now a standard tool in algorithm design;
 for instance, it is the basis of the only known polynomial-time
 algorithm for primality testing.
;;;;;
if the projected dimension is high enough, then a
PCA-projected mixture could easily be far better separated
than its randomly projected counterpart. For this reason
PCA remains an important tool in the study of Gaussian
clusters.
}

\section{Algoritmos de aprendizado}\label{learners}
Cada algoritmo de aprendizado tem, intrinsecamente, um viés próprio \ano{REF}.
É natural esperar que esse viés influencie no desempenho das estratégias gnósticas
ou que o aprendizado seja afetado pela sequência de consultas gerada por uma
determinada estratégia agnóstica.
Também pode ser um fator relevante o fato de que, no aprendizado passivo,
classificadores com boa performance com poucos dados podem ter baixa
performance com muitos dados
\citep{journals/sigkdd/AttenbergP10,journals/jmlr/PerlichPS03}.
Dessa forma, diferentes algoritmos de aprendizado
precisam ser adotados quando alguma comparação entre estratégias é pretendida.

Cinco algoritmos comumente usados e implementados na biblioteca Weka foram adotados:
C4.5\footnote{Implementação baseada no algoritmo de
árvore de decisão C4.5 denominada J48.}, NB\footnote{\textit{Naive Bayes}},
VFDT\footnote{\textit{Very Fast Decision Trees}},
5-NN\footnote{Cinco vizinhos mais próximos}
e SVM\footnote{\textit{Support Vector Machines \ano{explicar detalhes da implementação svmlib/weka para multiclasse?}}}
\citep{books/mk/Quinlan93,conf/ecml/Lewis98,conf/kdd/DomingosH00,journals/tit/Hart68,
hearst1998support}.
Adicionalmente, por sua ausência na literatura de aprendizado ativo e características
distintivas com relação aos outros algoritmos,
três variantes das \elms também foram adotadas - conforme adaptações descritas
na Seção \ref{elmnovas}.

\green{descrever parâmetros dos learners:
5-nn ponderado pelo inverso da distância euclidiana padronizada;
outros ajustes: vou pegar no código e help do weka}

\section{Experimento preliminar}\label{preliminar}
Dado o grande número de estratégias, bases de dados e classificadores envolvidos,
um experimento reduzido \citep{conf/hais/SantosC14} foi conduzido visando
a construção de um panorama geral do comportamento das estratégias
e a definição do dimensionamento mais adequado dos experimentos definitivos
aos recursos computacionais.
Apenas dez estratégias e os algoritmos mais rápidos (C4.5, NB, VFDT e 5-NN)
foram adotados.
Dez execuções de validação cruzada em dez partições totalizaram cem \pools
para cada base - conforme sugerido na literatura de classificação
\cite{conf/pakdd/BouckaertF04}.
As \pools foram consultados até o ponto em que a acurácia máxima da
melhor estratégia houvesse sido atingida.

Aproximadamente um mês\footnote{Pausas devido a problemas técnicos incluídas.}
de experimento foi necessário para apenas a conclusão
nas vinte e oito menores bases de dados.
Assim, considerando-se o crescimento exponencial do custo computacional em alguns
pares \textit{algoritmo de aprendizado}-\textit{estratégia} com o aumento do número
de classes, atributos e/ou exemplos, foi necessário reduzir o procedimento
de validação (Seção \ref{validacao}) e antecipar o término das
consultas.

\section{Avaliação}\label{avaliacao}
\ano{pro final: quando perde, perde muito feio?}

\subsection{Métricas}\label{metricas}
\esb{Um cara que usa log no eixo X e usa ``Area under the Learning Curve'':
{http://perso.rd.francetelecom.fr/lemaire/publis/ijcnn\_2\_2011\_camera\_ready.pdf}
}

An Easy to Use Repository for Comparing and Improving Machine Learning Algorithm Usage
http://arxiv.org/pdf/1405.7292.pdf
fala sobre guardar resultados a 'instance level' com as predições do classificadores


\ano{talvez o primeiro artigo que fala em "area under the learning curve" (chamando confusamente de AUClog): When will feature feedback help? quantifying the complexity of classification problems (2007)
O próximo, sem siglas, é do Settles (com f-measure e sem log(x)):
An analysis of active learning strategies for sequence labeling tasks (2008)
No "active chalenge 2011",
que alguns adotam como referência para citar ALC, foi usada a AUC verdadeira e log2(x) no cálculo (igual ao Cawley):
http://www.causality.inf.ethz.ch/activelearning.php?page=evaluation
Porém, eles avaliam sem validação cruzada, talvez por limitação do próprio fato de ser uma competição.
O dataset inteiro é usado uma só vez e o teste é feito em cima de
"all the samples with unknown labels".
Isso explica o fato de classificadores semisupervisionados terem alavancado as estratégias na competição.
Já estou rodando as estratégias agnósticas com 5x5-fold.
Podemos adotar ALC c/ AUC e log(x) para sumarizar os resultados.
}

 Uma medida comum na área de aprendizado ativo
 é a \textit{área debaixo da curva de aprendizado} (Area under the Learning Curve - ALC)
 \citep{journals/jmlr/GuyonCDL11}.
 Ela consiste no somatório de alguma medida de desempenho ao longo
 das consultas.
 Seu intuito é avaliar o desempenho geral de uma estratégia, ou seja,
 numa ampla faixa de orçamentos.
 Assim, a medida se mostra adequada para a tarefa de comparação
 de estratégias.
 Ela foi adotada em conjunto com a medida kappa -
 resultando no valor médio da medida para toda a sequência de consultas.

A medida kappa de Cohen \citep{journals/coling/EugenioG04}
é utilizada para comparar o grau de consenso entre avaliadores
tem demonstrado bom poder discriminatório frente a outras medidas
que sumarizam a matriz de confusão \citep{conf/acivs/DemirkesenC08}.
Quando aplicada como medida de desempenho de classificação,
ela assume valor $1$ para acerto total, $0$ para desempenho equivalente ao
aleatório e $-1$ para erro total.
Valores intermediários indicam o quão bom ou ruim é o clasificador.
\cite{conf/pkdd/Shah11} apresenta a versão multiclasse para a medida kappa
que foi adotada neste trabalho.
Ela tem a importante propriedade de remeter à medida original em problemas binários.
Por fim, ela permite realizar a comparação por dois pontos de vista:
interestratégias e em relação ao acaso.
\ano{colocar fórmula da kappa? já incluir pseudoALC na fórmula?}

Outro ponto de vista importante é em relação ao desempenho passivo.
Sendo ele dado por apenas um valor para todos os exemplos, não existe
a possibilidade de se calcular uma ALC.
Assim, deve ser definido um momento na curva de aprendizado como o
limite do orçamento disponível e deve ser avaliado o modelo induzido até então.
\green{baseline p/ AccBal é $1/|Y|$ ?}
Nesse caso, foi adotada a acurácia balanceada \citep{journals/bmcbi/MassoV10}
por ter um significado mais próximo
da usual medida de acurácia quando se comparam classificadores.
Assim como a kappa multiclasse, ela é adequada para problemas multiclasse desbalanceados.
O orçamento escolhido foi $\cent=\frac{|\mathcal{U}|}{2}$
% metade dos exemplos disponíveis
nas trinta e nove bases com menos de quatrocentos exemplos (Tabela \ref{tab:nm})
e  $\cent=200$ nas bases restantes.
% duzentos exemplos

\ano{colocar fórmula da accbal?}



\subsection{Validação}\label{validacao}
Nos experimentos,
para viabilidade computacional e conforme literatura de aprendizado ativo \ano{REF}
foram adotadas cinco execuções de validação cruzada em cinco partes -
totalizando vinte e cinco \pools para cada base.

\tar{mencionar detalhes de embaralhamento? e seeds de classificador?}

\ano{A survey of cross-validation procedures for model selection (2010)
{http://www.di.ens.fr/willow/pdfs/2010\_Arlot\_Celisse\_SS.pdf}
;;;
tem até review de fast CVs.
;;;
According to Breiman and Spector (1992) the best risk estimator is LOO,
whereas 10-fold CV is more accurate for model selection.
}

\subsection{Teste estatístico}
\ano{citar programa do Covões}

explicar critério de empate não arbitrário que inventei, pois na construção da árvore de nichos
haveria confusão se adotasse apenas os vencedores, por causa da existência de estratégias similares.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Ferramentas}\label{sec:ferramentas}
Foram utilizados um total de 188 núcleos\footnote{\textit{Núcleos} por simplicidade,
mas na realidade cada computador oferecia diferentes unidades de processamento;
sendo o outro tipo as \textit{threads} na nomenclatura da Intel.} de processamento:
\begin{itemize}
\item 24 núcleos de 2,4GHz da \textit{nuvem} USP;
\item 108 núcleos de 3,5GHz do \textit{cluster} Biocom;
\item 24 núcleos de 2,5GHz do servidor GPU do laboratório Biocom;
\item 8 núcleos de 4GHz da estação de trabalho; e
\item 8 núcleos de 2,4GHz do \textit{notebook} de trabalho\footnote{Ambos,
estação e \textit{notebook} vinculados ao orientador do autor deste trabalho.}.
\end{itemize}

\green{descrever hardware, mysql}

