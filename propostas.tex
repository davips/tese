\chapter{Propostas} \label{propostas}
\esb{quando a pessoa não sabe que algoritmo de aprendizado é adequado à base,
é melhor ela adotar uma estratégia agnóstica,
assim ela não compromete sua amostragem e pode,
posteriormente, quando já tiver os rótulos,
escolher o melhor mais apropriadamentre}

O tema desta tese é o uso efetivo do aprendizado de máquina ativo por meio de escolhas
adequadas diante da diversidade existente de estratégias.

\esb{esboça a estrutura conjunta deste e dos próximos 4 capítulos;
explica que a contribuição se divide em três partes: análise comparativa,
viabilidade de ap. ativo pra ELM e meta-aprendizado; os detalhes
são dados em seus respectivos capítulos e a metodologia geral
vem antes}

\ano{revisar totalmente conforme nova estrutura de capitulos}

Neste capítulo são apresentadas as contribuições e trabalhos derivados da pesquisa
realizada.
Foi desenvolvida uma biblioteca \citep{doi/ml} de interface com o
\textit{software} Weka
que serviu de base para as implementações mencionadas nas próximas seções.

\tar{mencionar em cada seção o artigo em que foi ou vai ser publicado o tema}

\ano{agDW* levam vantagem talvez porque com classificadores hard (NB, C45?, ...)
a estimativa de informatividade (a estimativa da distribuição de probabilidade)
fica prejudicada pela presença do learner.
É preciso comparar classificador a classifcador.}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\esb{pra onde vai isso?}
A implementação dos algoritmos aqui propostos e de existentes na literatura
culminou em uma biblioteca extensível de código aberto específica para aprendizado ativo.
Ela está disponível publicamente para fins de pesquisa e replicabilidade \citep{doi/al}.


\section{Busca no espaço de hipóteses multiclasse}
Conforme explicado na Seção \ref{sgnet},
é possível fazer uma amostragem ativa dentro
da perspectiva do espaço de hipóteses.
Entretanto, a abordagem original exposta na Seção \ref{sgnet}
contempla apenas problemas de classificação binária.
Para contornar essa limitação, uma adaptação chamada \textit{SGmulti}
foi proposta \citep{conf/hais/SantosC14}.

Diferentemente da abordagem original onde existe uma classe positiva
que define um modelo mais geral e um mais específico,
na proposta de adaptação um modelo específico é induzido para cada classe.
Cada modelo, assim, tem uma aproximação da hipótese mais geral
($\theta_G$) e a conjunção de todos os modelos contém
aproximações das hipóteses mais específicas de cada classe ($\theta_S$).
Isso é feito por meio da rotulação artificial de todos os exemplos presentes
na reserva de acordo com a meta de cada modelo,
que é apresentar a hipótese mais geral para uma dada classe.
Uma vez gerados os modelos com os exemplos artificiais,
os exemplos para consulta passam a ser amostrados da região de desacordo
entre todos os modelos.

A ordem de complexidade do \textit{SG-multi} é $\mathcal{O}(|Y|)$.

\ano{mesclar descrição abaixo que é mais formal com a descrição acima?}

Para cada classe $c \in Y$, existe um par modelo/conjunto de treinamento
$\langle\theta^c,\mathcal{L}^c\rangle$
devidamente projetado para representar a hipótese mais geral
$h^c_G$ com relação à classe $c$.
Inicialmente, todos os exemplos
$\langle\bm{x},y,w\rangle \in \mathcal{L}^c$
são os mesmos exemplos da reserva, exceto por duas diferenças:
eles são rotulados como positivos para a classe correspondente
($y=c$) e lhes são atribuídos pesos com apenas uma pequena fração
do peso dos exemplos que já têm suas classes reveladas
($w << 1$),
como sugerido recentemente na literatura \cite{series/synthesis/2012Settles}.
O valor adotado para o peso neste trabalho foi
$w=\frac{1}{|Y||\mathcal{U}|}$,
pois ele assegura que a soma de toda a influência dos exemplos de fundo
seja menor que o peso de um único exemplo real.
Essa medida evita que os exemplos de fundo se sobreponham aos
exemplos reais no início do processo de rotulação - momento de escassez
de exemplos reais.

A função de predição $f(\theta_c, \bm{x})$ retorna
a classe mais provável de um dado exemplo $\bm{x}$
de acordo com o modelo fornecido $\theta_c$.
É possível encontrar um exemplo controverso $\bm{x}^*$ \ano{sem consenso}
comparando as saídas de todas as diferentes funções de predição.
Cada função de predição representa o conceito mais geral
de cada classe:
\[
  \forall a,b \in Y, a \neq b, \exists \bm{x}^* \mid f(\theta_a,\bm{x}^*) \neq f(\theta_b,\bm{x}^*)
\]

Assim que um exemplo da região de desacordo $\bm{x}^*$ é consultado
ele substitui seu exemplo de fundo correspondente em todos os conjuntos
de treinamento com seu rótulo real e peso integral:
 \[
  \mathcal{L}_c \leftarrow (\mathcal{L}_c - \{\langle\bm{x}^*,c,w\rangle\}) \cup
\{\langle\bm{x}^*,c,1\rangle\} \forall c \in Y
 \]


\section{Variações da amostragem ponderada por densidade}

\ano{as variantes se justificam mais por sua natureza e papel nos experimentos do
que por um suposto avanço no estado da arte; é assim porque existem muitas estratégias
mais recentes que precisariam ser comparadas com elas}

\subsection{Agnóstica}\label{ag}
A estratégia DW pondera a incerteza de forma a afastar as consultas
dos exemplos já rotulados e a aproximá-las das maiores concentrações de exemplos
não rotulados. Essa característica faz com que os exemplos tendam a ser consultados
na região de fronteira e arredores, mesmo que todos os exemplos
estejam associados a um mesmo nível de incerteza.
Isso significa que o classificador e sua medida de incerteza representam um papel que
pode ser redundante, de ajuste fino ou eventualmente contraproducente.
Essa possibilidade de redundância aliada à ideia de agnosticismo da amostragem baseada
em agrupamento motivou a adaptação da amostragem ponderada por densidade por meio
da remoção da medida de incerteza da fórmula inicial previamente apresentada
nas equações \ref{eqid} e \ref{eqtu}.
A nova fórmula é apresentada na Equação \ref{eq:agtu}.
\begin{equation}\label{eq:agtu}
 TU(\bm{x}) =
 \frac{1}{|\mathcal{U}|} \sum_{\bm{u} \in \mathcal{U}} sim(\bm{x},\bm{u})
 (\sum_{\bm{l} \in \mathcal{L}} sim(\bm{x},\bm{l}))^{-1}
\end{equation}
Assim, possivelmente sem grande impacto na acurácia,
pode-se adiar a escolha do algoritmo de aprendizado para depois da obtenção dos rótulos.
Em determinadas aplicações também pode ser útil a possibilidade de se conhecer toda
a sequência de consultas antes da interação com o oráculo começar.
Frequentemente, o número de consultas é conhecido de antemão \citep{settles2010active};
isso permite, por exemplo, que elas sejam repartidas entre vários oráculos que podem
trabalhar de forma independente dos demais.
Essa possibilidade de paralelização não existe na estratégia de agrupamento hierárquico,
pois ela faz uso dos rótulos para determinar a pureza de cada grupo.
Outra vantagem é a inexistência de tempo de espera interconsultas.

\subsection{Híbrida}\label{htu}
% \ano{uma amostragem balanceada tem mais chance de estar sendo exploratória?}
A abordagem agnóstica baseada em densidade é de natureza exploratória,
pois enfoca as regiões mais desconhecidas (sem rótulos) do espaço de exemplos.
Pela ausência de aprendiz, não há uma fronteira de decisão a se considerar.
Logo, não é possível realizar consultas de caráter prospectivo - ou o ajuste fino citado
na Seção \ref{ag}, ou seja,
que ataquem diretamente os exemplos mais críticos de forma análoga a uma busca binária.
Como a premissa de fronteira única da busca binária não pode ser garantida e
a amostragem puramente exploratória se assemelha a uma busca exaustiva,
é natural supor que o equilíbrio entre exploração e prospecção seja proveitoso.
A estratégia TU embute ambas as abordagens em sua fórmula, mas não
permite que elas ajam separadamente.
Diferentemente,
a nova estratégia (HTU) procura alternar a estratégia TU com a amostragem
puramente exploratória (ATU) de acordo com o nível de contribuição corrente
da componente exploratória em TU.
O nível de contribuição é estimado por meio do cáculo da correlação de
Pearson \citep{books/daglib/0000786} entre as medidas de informatividade de
TU e ATU para toda a reserva de exemplos.
Uma correlação acima de $0,999$, valor arbitrário próximo de $1$,
indica uma baixa contribuição da componente exploratória,
sugerindo que a presença do aprendiz passa a ser relevante ou
que o aprendizado atingiu o nível de ajuste fino.
Espera-se que o emprego do aprendiz apenas nos períodos de relevância
reduza sua influência negativa durante a fase inicial de aprendizado,
ou por todo o aprendizado, no caso de algoritmos que gerem modelos impróprios
para prospecção no dado problema eventualmente empregados equivocadamente
pelo usuário.
\ano{algoritmo}

\input exp-elm
 
\section{Considerações}
\begin{table}
\caption{Características de cada estratégia.
\textit{A ordem de complexidade é dada conforme a quantidade de exemplos
a aprender para viabilizar cada consulta. \ano{é aceito O(0)?}}
}
\scalebox{0.88}{
\begin{tabular}{c|c|c|c|c|c}
\textbf{estratégia} & \textbf{\makecell{forma\\ de busca}}&\textbf{\makecell{presença \\de aprendiz}} & \textbf{\makecell{definição da \\sequência de \\consultas}} & \textbf{\makecell{dependência\\entre\\consultas}}&\textbf{\makecell{ordem de\\complexidade}}\\ \hline
Rnd & \makecell{exploratória\\aleatória} & \makecell{agnóstica}&autônoma&nenhuma&$\mathcal{O}(0)$\\ \hline
Clu&\makecell{balanceada:\\exploratória e\\prospectiva}& agnóstica&interativa&total&\makecell{não\\especificada}\\ \hline
\makecell{Unc/Mar/Ent\\QBC/DW}&prospectiva&gnóstica&interativa&total&$\mathcal{O}(1)$\\ \hline
SVMS&prospectiva&\makecell{gnóstica\\(aprendiz\\específico)}&interativa&total&$\mathcal{O}(|\mathcal{U}||\mathcal{L}|)$\\ \hline
SVMB&\makecell{alternada:\\exploratória e\\prospectiva}&\makecell{gnóstica\\(aprendiz\\específico)}&interativa&total&$\mathcal{O}(|\mathcal{U}||\mathcal{L}|)$\\ \hline
EGL&prospectiva&\makecell{gnóstica\\(aprendiz\\específico)}&interativa&total&$\mathcal{O}(|Y||\mathcal{U}|)$\\ \hline
EER&prospectiva&gnóstica&interativa&total&$\mathcal{O}(|Y||\mathcal{U}|^2)$\\ \hline
SGmulti&\makecell{exploratória\\limitada e\\aleatória}&gnóstica&interativa&total&$\mathcal{O}(|Y|)$\\ \hline
TU&\makecell{balanceada:\\exploratória e\\prospectiva}&gnóstica&interativa&\makecell{após etapa\\exploratória}&$\mathcal{O}(1)$\\ \hline
ATU&\makecell{exploratória\\ponderada}&agnóstica&autônoma&nenhuma&$\mathcal{O}(0)$\\ \hline
GATU&\makecell{em fases:\\exploratória e\\prospectiva}&\makecell{em fases:\\agnóstica e\\gnóstica}&interativa&\makecell{após etapa\\exploratória}&$\mathcal{O}(1)$\\ \hline
GATU&\makecell{alternada:\\exploratória e\\prospectiva}&\makecell{alternada:\\agnóstica e\\gnóstica}&interativa&frequente&$\mathcal{O}(1)$\\ \hline
\end{tabular}
}
\label{stratscompleta}
\end{table}

