Segundo \citeonline{series/synthesis/2012Settles}, \textit{aprendizado ativo} é o estudo de máquinas de aprendizado capazes de se aprimorar fazendo perguntas.
A origem do termo remete à Pedagogia. Nela, o termo se refere ao aproveitamento da
individualidade de cada aluno e seu próprio ritmo de aprendizado.
% Assim, ele pode ser auxiliado pelo professor nos aspectos em que experimenta maior dificuldade visando maior eficácia no ensino \cite{michael2006s}.
Guardadas as devidas proporções, pode-se traçar um paralelo com a área de aprendizado de máquina: um algoritmo pode usufruir de uma atenção seletiva que priorize os exemplos mais difíceis para ele num dado momento, ou seja, que possam trazer mais benefícios para a indução de modelos preditivos num dado instante.

Em sua forma mais geral, como esboçado por \citeonline{forman2012programmer}, o aprendizado de máquina ativo pode lançar mão de todo o conhecimento que um especialista (supervisor humano) seja capaz de transmitir dentro das limitações de configurabilidade do sistema.
Alguns pontos de configuração seriam, por exemplo:
reescrita do programa
% \footnote{Código escrito na linguagem de programação que implementa o sistema ou em alguma linguagem específica do domínio.}
de extração de atributos visando maior separabilidade entre as classes; composição de expressões regulares para extrair termos adequados de textos técnicos;
e, criação de regras de classificação.
Outras informações, mais diretamente obteníveis do supervisor humano, 
incluiriam: valores de atributos, classes associadas com atributos, 
exemplos completos sob demanda, entre outros.
Em linhas gerais, a aquisição de informação deve ser guiada por duas noções:
preferir aquela para a qual o estado corrente do modelo é incerto; e,
preferir aquela estimada como a mais relevante
\cite{krishnapuram2011cost}.

Dentre as perguntas que as máquinas de aprendizado ativo são capazes de
elaborar, a mais direta seria ``\textit{Qual é a classe do exemplo $\bm{x}$?}''.
A obtenção de um rótulo confiável normalmente é um processo 
custoso, logo, trata-se de um ponto de fundamental importância, dada a necessidade de exemplos rotulados em muitas aplicações (Capítulo \ref{intro}).
Isso torna o problema de decidir qual seria o melhor $\bm{x}$ a ser consultado a motivação basilar desta tese.
Adicionalmente, a quantidade de exemplos disponíveis pode ser abundante e a capacidade de esforço humano disponível limitada.
% O esforço, voltando à analogia com o aprendizado humano, corresponderia ao ato de lecionar.
Dessa forma, apenas uma parcela criteriosamente escolhida dos exemplos deve ser rotulada - \novo{consultada}, na terminologia de aprendizado ativo.
Essa abordagem se dá em oposição ao \textit{aprendizado por exemplos} convencional \cite{journals/cacm/Valiant84}, também chamado \novo{passivo}.
No aprendizado passivo, procura-se pelo maior conjunto de treinamento possível ou realiza-se uma amostragem aleatória.
No primeiro caso, o custo de rotulação pode se tornar proibitivo.
No segundo caso, a decisão quanto à relevância dos exemplos é deixada ao acaso.
Em ambos os casos, dependendo da aplicação, a construção do conjunto de treinamento pode ser crítica.
Por exemplo, quando a consulta de um exemplo envolve reações químicas
destrutivas, é desejável fazer o mínimo possível de consultas visando 
um reduzido custo material.
Similarmente, se o mecanismo rotulador, o oráculo, for um especialista humano ou mesmo um 
robô \cite{journals/etai/BryantMOKRK01}, é desejável parcimônia nas consultas para não incorrer num esforço elevado de atenção humana ou movimento mecânico.
Assim, um direcionamento adequado do esforço de aprendizado tem como
resultado um processo de rotulação mais econômico.
A variedade de abordagens existentes para esse direcionamento será assunto da Seção \ref{secestrategias}.
As definições necessárias sobre aprendizado ativo são dadas a seguir - analogamente à Seção \ref{cla}, que discorrera sobre classificação.

Na literatura, os termos \textit{aprendiz} (ativo) e \textit{estratégia} (de aprendizado ativo) são frequentemente usados de forma intercambiável \cite{journals/jcss/BalcanBL09}.
Entretanto, neste texto, optou-se por chamar \textit{aprendiz} apenas a parte da amostragem ativa referente ao aprendizado, ou seja, o algoritmo e seus modelos induzidos.
Existem estratégias sem aprendiz, apesar da ausência de aprendiz contradizer o princípio motivador original do aprendizado ativo anteriormente explicitado.

Nesta tese, o aprendizado convencional é chamado \textit{passivo}, pois é realizado com todos os exemplos disponíveis devidamente rotulados.
A estratégia de amostragem de maior correspondência com o aprendizado passivo é a \textit{aleatória}, pois é uma aproximação não enviesada de todo o conjunto de exemplos.

\simbolo{\hat{\bm{x}}}{exemplo escolhido para consulta}
\simbolo{\cent}{orçamento}
Cada consulta de uma dada estratégia ao oráculo visa a obtenção do rótulo que indica a classe verdadeira do exemplo $\hat{\bm{x}}$ escolhido.
% O processo inteiro de determinação das classes dos exemplos é chamado de \textit{rotulação}.
As consultas podem ter um viés mais \textit{exploratório}, que busca maximizar a variedade na escolha de exemplos; 
ou, mais \textit{prospectivo}, que se concentra apenas nos casos mais críticos, ou seja, com mais informatividade.
O limite de duração para o processamento computacional entre consultas é aqui equiparado ao \textit{tempo de espera tolerável} \cite{conf/amcis/Nah03}, pois é a parte do tempo de processamento que realmente afeta o oráculo.
O símbolo $\cent$ representa o valor do orçamento, que é o número de consultas permitidas.

\section{Estratégias de consulta}\label{secestrategias}
\simbolo{q}{função-critério de consulta}
Na literatura de aprendizado ativo há diversos subcasos, cenários e estratégias.
O subcaso e o cenário mais frequentes, onde se situa a presente tese,
são a consulta de rótulos e o cenário baseado em \pool, respectivamente.
% Os cenários alternativos são apresentados no Apêndice \ref{cenarios}.
No caso das estratégias, elas são frequentemente baseadas em diferentes concepções de relevância de exemplos ou mesmo diferentes teorias do aprendizado.
A amostragem por incerteza, por exemplo, assume que os exemplos - e seus rótulos - são gerados de acordo com uma distribuição de probabilidades.
% - em linha com a teoria do aprendizado estatístico \citep{books/daglib/0097035};
A amostragem por busca no espaço de hipóteses, por sua vez, assume a
existência de hipóteses integrantes de um \textit{\versionspace}
% que podem classificar cada exemplo de formas diferentes
\cite{books/daglib/0087929}.
Estratégias sem aprendiz, por outro lado, são independentes de algoritmo de aprendizado.
Essa diversidade de embasamentos configura-se, praticamente, como um 
conjunto de paradigmas de consulta.
Suas principais representantes são apresentadas nas seções seguintes, com os respectivos princípios de funcionamento e características principais.
A abreviação definida para cada estratégia é dada entre parênteses
na seção correspondente.
Na apresentação das ordens de complexidade, é assumido que todos os
cálculos possíveis de realização antes do início do processo de rotulação 
já foram feitos e seus resultados estão disponíveis em memória.
Essa premissa se baseia no cenário que será especificado na Seção \ref{desccen}.
Ele garante a disponibilidade de todos os exemplos antes do início do processo de rotulação.
Dessa forma, apenas o custo computacional entre consultas se configura
como potencial custo financeiro, pois consome o tempo do oráculo.

O Algoritmo \ref{algo} é o invólucro mais comum das estratégias apresentadas.
Ele aceita diferentes critérios de consulta (\textit{funções-critério}), descritos nas seções a seguir.
% Inf: incerteza, margim, entropia
% (medida-)critério: TU, ATU, HTU
\SetKwProg{alg}{função}{}{}
\SetKwFunction{amostragem}{amostragem}{}
\begin{algoritmo}
\caption{Amostragem ativa baseada em reserva de exemplos.}
\label{algo}
\small
\Entrada{
 \\ $\mathcal{U}$ - reserva de exemplos
 \\ $\mathcal{L}$ - conjunto inicial de exemplos rotulados
 \\ $\phi$ - função indutora (algoritmo de aprendizado)
 \\ $q\colon X \times ... \times \Theta \rightarrow \mathbb{R}$ - função-critério de consulta a se maximizar
 \\ $\cent$ - orçamento (quantidade de exemplos a rotular)
}
\Resultado{
 \\ $\mathcal{L}'$ - conjunto final de exemplos rotulados
}
\alg{\amostragem {$\mathcal{U}$, $\mathcal{L}$, $\phi$, $q$, $\cent$}}{
\Se{$\cent = 0$}{
\Retorna $\mathcal{L}$
}
 \Senao{
 $\theta = \phi(\mathcal{L})$ \\
$\bm{\hat{x}} = \argmax\limits_{\bm{x}}[q(\bm{x}, \cdots, \theta)]$  \come{argumentos requeridos por $q$ dependem de cada estratégia}\\
$\mathcal{L}' = \mathcal{L} \cup \{\langle \bm{\hat{x}} ,o(\bm{\hat{x}}) \rangle \}$ \\
$\mathcal{U}' = \mathcal{U} \setminus \{\bm{\hat{x}}\}$ \\
\Retorna \amostragem{$\mathcal{U}'$,$\mathcal{L}'$, $\phi$, $q$, $\cent-1$} \\
}
}

\end{algoritmo}

\subsection{Estratégias baseadas em incerteza}\label{estsunc}
\simbolo{P_{\theta max}(\bm{x})}{máxima probabilidade a posteriori para o exemplo $\bm{x}$ segundo o modelo $\theta$}
% least confident
Provavelmente a medida de informatividade $Inf(\bm{x})$ mais simples para a decisão de quando se deva selecionar um exemplo $\bm{x}$ da reserva $\mathcal{U}$, ou um grupo deles, é a máxima probabilidade a posteriori dada por um modelo probabilístico $\theta$  \cite{journals/sigir/Lewis95a} - conforme Equação \ref{eqpro}.
\begin{equation}\label{eqpro}
P_{\theta max}(\bm{x})=\max_{y\in Y}P_{\theta}(\bm{y}\mid\bm{x})
\end{equation}
Classificadores não probabilísticos e com saídas numéricas $f$ podem simular
uma distribuição de probabilidades por meio da aplicação da função 
sigmoide logística $g$, conforme Equação \ref{eqprob}.
\begin{equation} \label{eqprob}
 P_{\theta}(y_o=1\mid\bm{x}) = \frac{g(f_o(\bm{x}))}{\sum\limits_{1 \leq p \leq |Y|}g(f_p(\bm{x})) }
\end{equation}
% Onde $f_o(\bm{x})$ é a função preditiva da classe $o$ para o exemplo $\bm{x}$; valores próximos de $1$ indicam pertinência à classe e próximos de $0$, o oposto.

\subsubsection{Amostragem por incerteza}\label{unc}
A estratégia de \textit{\sigla{Unc}{amostragem por incerteza}} consiste em consultar o exemplo mais informativo $\hat{\bm{x}}$,
ou seja, aquele com o maior valor para $1 - P_{\theta max}(\bm{x})$ - conforme Equação \ref{equnc}.
Seu objetivo é explorar a fronteira de decisão no espaço de exemplos.
A complexidade dessa estratégia é $\mathcal{O}(1)$ - equivalente
a apenas um exemplo aprendido por consulta.
\begin{equation} \label{equnc}
 \hat{\bm{x}}= \argmax_{\bm{x}\in\Upool}[1 - P_{\theta max}(\bm{x})]
\end{equation}

\subsubsection{Amostragem por margem ou entropia}\label{mar}
\simbolo{\hat{y}_{\theta}(\bm{x})}{classe mais provável do exemplo $\bm{x}$ de acordo com modelo $\theta$}
% \simbolo{\bm{z}(\bm{x})}{classe predita para o exemplo $\bm{x}$}
\simbolo{M_{\theta}}{medida de informatividade baseada na margem de incerteza}
\simbolo{E}{entropia normalizada}
\simbolo{E_{\theta}}{medida de informatividade baseada em entropia}
Em problemas multiclasse, o menor $P_{\theta max}(\bm{x})$ pode não indicar o exemplo mais controverso.
Por exemplo, na reserva, um exemplo pode ter duas ou mais classes igualmente prováveis.
Essa evidente incerteza inerente ao exemplo não é refletida pelo valor de $P_{\theta max}(\bm{x})$.
A \sigla{Mar}{estratégia baseada na \textit{margem de incerteza}}, cuja medida $M$ de informatividade é apresentada na Equação \ref{eqmar}, evita esse problema utilizando o valor da diferença entre as duas maiores probabilidades - o subscrito $_{\theta}$ é subentendido para $P$ e a classe predita $\hat{y}(\bm{x})$.
\begin{eqnarray} \label{eqz}
% \bm{z}(\bm{x})=\argmax_{\bm{y}\in Y}P(\bm{y}\mid\bm{x})
% \\
M_\theta(\bm{x})=1-\{P[\hat{y}(\bm{x})\mid\bm{x}]-\max_{y\in Y\setminus\{\hat{y}(\bm{x})\}}P(y\mid\bm{x})\}
\label{eqmar}
\end{eqnarray}
Outra possibilidade é a \sigla{Ent}{estratégia de entropia normalizada}, em que $\info=E_\theta$ \cite{journals/bioinformatics/LewinSA0P04}.
A medida $E_\theta$ é dada pela Equação \ref{eqent}, que é baseada na medida de entropia $E(\bm{v})$ para um dado vetor $\bm{v}$, apresentada na Equação \ref{eqent0}.
\begin{eqnarray} 
\label{eqent0}
E(\bm{v}) = -\log^{-1}(\dim v) \sum_{1 \leq i \leq \dim v} v_i \log v_i
\\
\label{eqent}
E_{\theta}(\bm{x}) = E[\bm{P}_{\sim\theta}(\bm{x})]
\end{eqnarray}

\subsubsection{Margem simples}\label{marsim}
A estratégia de amostragem por margem pode ser estendida para um espaço
de parâmetros $\mathcal{F}$, resultante da transformação do espaço de
atributos por uma função núcleo.
Essa foi a abordagem de \citeonline{journals/jmlr/TongK01} para \sigla{SVM}{\textit{Support Vector Machines}} - \cite{hearst1998support};
cuja principal variante é chamada \textit{\sigla{SVMsim}{margem simples}}.
%  If asking each query is expensive relative to computing time then using either the MaxMin or Ratio
% may be preferable. However, ifthe cost ofasking each query is relatively cheap and more emphasis
% is placed upon fast feedback then the Simple method may be more suitable.
Ela seleciona o exemplo mais próximo do hiperplano  
(fronteira de decisão) que divide linearmente o espaço $\mathcal{F}$.
%  algoritmo: learn an SVM on the existing labeled data and choose as the next instance to
%  query the instance that comes closest to the hyperplane in F.

\subsection{Estratégias (não-agnósticas) ponderadas por densidade}\label{dw}
\simbolo{\simi(\bm{x},\bm{u})}{similaridade entre dois exemplos  $\bm{x}$ e $\bm{u}$}
\simbolo{\alpha}{importância relativa da densidade dos exemplos da reserva}
\simbolo{\delta}{importância relativa da densidade dos exemplos rotulados}
\simbolo{\stratID(\bm{x})}{densidade de informação do exemplo $\bm{x}$ relacionada aos exemplos não rotulados}
\simbolo{\stratIDTU(\bm{x})}{$\stratID(\bm{x})$ inversamente ponderado pelos exemplos já rotulados}
As estratégias baseadas em densidade ponderam cada exemplo de acordo com a densidade de sua vizinhança.
Sua ideia principal é consultar exemplos representativos da distribuição dos dados e evitar pontos aberrantes.
Isso é feito por meio do cálculo da medida de \sigla{ID}{densidade de informação}.
Ela atribui diferentes pesos à medida de informatividade.
Cada exemplo tem um peso que corresponde a um valor de densidade que, de acordo com a Equação \ref{eqid}, é mais intenso quando a distância é curta para muitos vizinhos.
Assim, os pesos variam conforme o nível de concentração de exemplos não rotulados no entorno do exemplo $\bm{x}$ sob análise \cite{settles2008curious}, onde $\alpha$ é um parâmetro de ajuste da importância relativa da densidade.
Qualquer medida de similaridade ($\simi$) e de informatividade $\info$ podem ser adotadas.
Assim, a \ing{\sigla{DW}{estratégia ponderada pela densidade}}{Density Weighted} consiste em consultar o exemplo com a maior $\stratID$.
\begin{equation}\label{eqid}
 \stratID(\bm{x}) = \info(\bm{x})
 \left(\frac{1}{|\mathcal{U}|} \sum_{\bm{u} \in \mathcal{U}} \simi(\bm{x},\bm{u})\right)^\alpha
\end{equation}

Um desdobramento natural é a \ing{\sigla{TU}{estratégia baseada na utilidade de treinamento}}{Training Utility}.
Ela faz uso da densidade de informação inversamente ponderada pela concentração de exemplos rotulados $\stratIDTU$, resultando num afastamento das regiões mais consultadas anteriormente \cite{settles2010active,journals/coling/FujiiITT98} - segundo a Equação \ref{eqtu}, onde $\delta$ é um parâmetro de ajuste da importância relativa da densidade dos exemplos rotulados.
\begin{equation}\label{eqtu}
 \stratIDTU(\bm{x}) = \stratID(\bm{x}) 
 \left(\frac{1}{|\mathcal{L}|}
 \sum_{\bm{l} \in \mathcal{L}} \simi(\bm{x},\bm{l})\right)^{-\delta}
\end{equation}

\simbolo{d(\bm{u},\bm{z})}{distância entre dois exemplos $\bm{u}$ e $\bm{z}$}
Neste trabalho, $\info = M$ e as principais medidas de distância $d(\bm{x},\bm{u})$ adotadas são a euclidiana e a de Manhattan.
% e Mahalanobis.
Elas são transformadas em medidas de similaridade $\simi(\bm{x},\bm{u})$ pela fórmula \ref{eq:sim}.
A ordem de complexidade é $\mathcal{O}(1)$, se os $|\mathcal{U}|^2$ resultados dos cálculos de similaridade forem, antes do início do processo de rotulação, devidamente armazenados em memória para acesso rápido posterior.
\begin{equation}\label{eq:sim}
 \simi(\bm{x},\bm{u}) = \frac{1}{1 + d(\bm{x},\bm{u})}
\end{equation}


\subsection{Estratégias agnósticas}\label{estag}
Neste documento, são consideradas agnósticas aquelas estratégias que ignoram a fronteira de decisão traçada pelo modelo de classificação \cite{journals/ml/KearnsSS94}. 
Nas próximas seções são apresentadas algumas variações dessa abordagem.

\subsubsection{Amostragem aleatória}
A \textit{\sigla{Rnd}{amostragem aleatória}} corresponde ao aprendizado passivo aplicado a apenas uma parte dos exemplos.
Não há uma ordem de preferência ou critério para a realização das consultas - apenas a (pseudo)aleatoriedade.
Suas principais características são seu viés totalmente exploratório, ou seja, sem enfocar nenhuma região especial do espaço de exemplos; e, a ausência de aprendiz.
Seu custo computacional pode ser considerado nulo.

\subsubsection{Busca no espaço de hipóteses}\label{sgnet}
\simbolo{S}{conjunto de hipóteses mais específicas}
\simbolo{G}{conjunto de hipóteses mais gerais}
\simbolo{\mathcal{O}(\cdots)}{ordem de complexidade}
É possível fazer uma amostragem ativa baseada na perspectiva do espaço de hipóteses.
A intuição por trás dessa abordagem é o fato dos exemplos mais importantes residirem na região onde as hipóteses se contradizem.
Isso equivale a consultar os exemplos que reduziriam o \versionspace 
depois de inseridos no conjunto de treinamento.
A busca no espaço de hipóteses é feita pelo acompanhamento das hipóteses
mais específicas e das mais gerais pertencentes aos conjuntos $S$ e $G$
de todas as hipóteses possíveis, representadas pelos modelos $\theta_S \in S$ e $\theta_G \in G$, respectivamente.
Uma característica distintiva de estratégias desse tipo é seu modelo de decisão binário: todos os exemplos controversos são considerados igualmente informativos, podendo ser consultados em qualquer ordem ou em lotes.

A \ing{\sigla{SG-network}{rede específica/geral}}{Specific/General network} \cite{journals/ml/CohnAL94}, também chamada de CAL \cite{journals/tcs/Dasgupta11} em referência a seus proponentes,
é baseada na busca no espaço de hipóteses.
Ela foi um dos primeiros algoritmos de aprendizado ativo.
Ela faz uma aproximação para ser capaz de induzir apenas o modelo mais específico $\theta_S$ e o modelo mais geral $\theta_G$, pois a quantidade de hipóteses possíveis pode ser infinita.
A aproximação é feita pela geração ou amostragem de \textit{exemplos de fundo}.
Eles são chamados assim, pois seus rótulos são artificialmente gerados de acordo com a meta desejada de treinamento: especificidade (tendência a predizer a classe positiva) ou generalidade (tendência a predizer a classe negativa).
Depois de criados os modelos iniciais, eventuais exemplos que causem desacordo entre $\theta_S$ e $\theta_G$ são selecionados para consulta.
Duas redes \ing{\sigla{MLP}{perceptron multicamadas}}{MultiLayer Perceptron}, treinadas com o algoritmo \textit{backpropagation} \cite{haykin2004comprehensive}, foram empregadas no trabalho original.
Entretanto, outros algoritmos capazes de induzir modelos aptos a lidar com exemplos ponderados também poderiam ter sido usados.
A ordem de complexidade é $\mathcal{O}(1)$ - ou $\mathcal{O}(|Y|)$ na adaptação multiclasse que será proposta neste trabalho.

% infos mais cruas sobre SG-network cohn1994improving:
% \esb{Se concentra em membership queries, cita angluin86 e valiant84.
% Em problemas formais, como encontrar uma fronteira no "unit line interval"
%  requer O(1/e ln(1/e))
% exemplos de treinamento aleatórios para se atingir um erro 'e'.
% Se for permitida a síntese de membership queries, 'e' pode ser atingido em O(ln(1/e)).
% Formaliza o aprendiz capaz de determinar a região de incerteza e nomeia como Selective Sampling.
% Pode-se calcular a região de inc. em lotes para reduzir a complexidade.
% Apresenta primeiro "a naive neural network querying algorithm":
% 0.1 < o < 0.9 = exemplo na região de incerteza
% judd88 diferencia configuração de arquitetura da MLP.
% Uma única rede pode descrever apenas um conceito, ou seja, uma pequena parte da região de incerteza, principalmente porque a MLP tende a ser excessivamente confiante em diversas partes do espaço de atributos.
% Os tamanhos dos conjuntos S e G crescem exponencialmente com o número de exemplos. O mesmo é válido para a quantidade de configurações de redes.
% Propõe a SG-network baseado em busca do version-space do mitchel82.
% Usa o conceito de "partial ordering in generality of the concepts".
% The version space (space of plausible queries) is reduced with every query.
% Ver algoritmo na página 10. Eles tb propõe mesclar S e G numa só rede.
% Na prática, em conjuntos grandes, é mais eficiente retreinar a rede do zero quando novos exemplos são adicionados.
% Experimentos:
% o problema do (par de) triângulo
% --------------------
% topologia 2-8-3-1
% 
% 12 redes treinadas inicialmente com 10, 20, ..., 150 pontos.
% Compara com random e com naive mlp.
% Plota o espaço de parâmetros com a fronteira de decisão criada pela rede comparada com a fronteira real (há também os exemplos + e - espalhados inutilmente).
% Plota error X queries.
% Compararou erros com diferença significativa com mais de 90% de confiança.

\subsubsection{Amostragem por agrupamento}\label{apresentahs}
O processo de amostragem pode explorar agrupamentos naturais na reserva de exemplos, pois são independentes da existência de rótulos.
Essa abordagem é uma alternativa à realização de consultas que enfocam a
% enfoquem? gramatica
fronteira de decisão ou o manejo de hipóteses em desacordo, citados anteriormente.
Uma importante representante desse tipo de estratégia é \ing{\sigla{HS}{amostragem hierárquica}}{Hierarchical Sampling} proposta por \citeonline{journals/tcs/Dasgupta11}, baseada em agrupamento hierárquico \cite{journals/cj/Murtagh83}.

O método de agrupamento hierárquico organiza os exemplos numa hierarquia que pode ser representada por uma árvore.
Cada nó folha simboliza um exemplo e cada nó pai representa uma relação de
proximidade/similaridade entre seus filhos.
Os filhos, por sua vez, podem ser exemplos isolados ou novas relações de parentesco.
Qualquer nó tem o potencial de ser visto como um só grupo contenedor de todos os exemplos representados pelos nós folhas descendentes diretos ou indiretos dele na hierarquia.
Logo, na árvore como um todo, as diferentes podas possíveis definem diferentes organizações em grupos.
A amostragem hierárquica faz uso da árvore para definir a relevância dos exemplos.
Eles têm maior probabilidade de serem consultados caso pertençam aos grupos
mais impuros e representativos.
O grau de impureza é dado pela proporção de exemplos da mesma classe; o grau de representatividade é dado pela quantidade de exemplos em cada grupo.
A implementação original do autor, adotada neste trabalho, fez uso do algoritmo de agrupamento chamado
\textit{Ward's average linkage method} \cite{journals/csur/JainMF99}.
A ordem de complexidade de cada consulta de HS não é especificada, mas sabe-se o custo da etapa de agrupamento, que é $\mathcal{O}(n^2 \log n)$.
Apesar de alto, se comparado às demais estratégias, esse custo pode ser antecipado, analogamente ao processamento prévio de distâncias seguido de armazenamento em memória sugerido previamente na Seção \ref{dw} para DW e TU.

% É possível aplicar Ward no Weka e gerar SVG em http://www.trex.uqam.ca/view.php
% O(n^2 log(n)) HC \cite{journals/csur/JainMF99}

% http://www.cs.columbia.edu/~djhsu/papers/hier-slides.pdf
% INPUT: hierarchical clustering T
% • INITIALIZE: pruning P = { root }, labeling L(root) = +1
% • FOR t = 1, 2, …:
% – Set v = select-node(P)
% – Pick a random point z in subtree Tv
% – Query z’s label
% – Update empirical counts for all nodes along path from z to v
% – Choose best pruning and labeling (P’,L’) of Tv;
% Set P = ( P \ { v } ) ∪ P’, and L(u) = L’(u) for all u ∈ P’
% • FOR EACH v ∈ P: assign each leaf in Tv the label L(v)
% • RETURN the resulting fully-labeled data set

\subsection{Outras estratégias}\label{outras}
Outros tipos de estratégia são apresentados nesta seção.

\subsubsection{Balanceamento exploração-prospecção}
A natureza puramente prospectiva de SVMsim (Seção \ref{marsim}) possui o viés de consultar prioritariamente exemplos da fronteira de decisão, deixando de explorar as demais regiões de $\mathcal{F}$.
Por esse motivo, \citeonline{conf/icdm/OsugiKS05} propuseram um balanceamento 
entre prospecção e exploração.
A exploração é realizada por um algoritmo que escolhe sempre o exemplo mais distante, chamado \sigla{KFF}{\textit{Kernel Farthest First}}.
A heurística de adotar os mais distantes primeiro, sem a transformação no espaço de atributos, já havia sido usada previamente no cálculo de agrupamentos aproximadamente ótimos por \citeonline{Hochbaum1985}.

O algoritmo de \sigla{SVMbal}{balanceamento exploração-prospecção} inicia com a aplicação de KFF.
Seu primeiro exemplo é aleatório e o segundo é seu par mais distante.
Esse par consiste no conjunto inicial que vai ser estendido com exemplos,
um a um, da mesma maneira que o segundo foi escolhido.
Esse processo exploratório é alternado com SVMsim de acordo com uma probabilidade definida em função da distância entre as predições, para todos os exemplos, antes e depois da última consulta realizada até o momento.

\subsubsection{Consulta por comitê}\label{qbc}
\simbolo{C}{comitê, conjunto de modelos}
\simbolo{\JS(C, \bm{x})}{divergência não-ponderada de Jensen-Shannon no comitê $C$ para o exemplo $\bm{x}$}
Um comitê $\mathcal{C} = \{\theta_1,\theta_2, \ldots, \theta_n\}$ é um conjunto de modelos combinados com o objetivo de superar as predições que a princípio seriam feitas por um único modelo isoladamente \cite{dietterich2000ensemble}.
Quando é adotado um esquema de votação, o princípio do \textit{teorema do júri de Condorcet} \cite{valentini2002ensembles} prova que o comitê é superior a um único indivíduo, desde que seus componentes sejam razoavelmente competentes ou, em outras palavras, sejam melhores que um decisor ao acaso.
De fato, empiricamente, comitês geralmente aumentam a acurácia preditiva de algoritmos de aprendizado que a princípio seriam usados isoladamente \cite{bauer1999empirical}.
Entretanto, é necessário que exista divergência entre os membros \cite{hansen1990neural}.
Portanto, a fonte da capacidade dos comitês de melhorar a acurácia preditiva de classificadores reside na diversidade de vieses de aprendizado.
Essa diversidade pode ser induzida por técnicas de subamostragem - como as populares \textit{boosting} \cite{schapire1990strength} e \textit{bagging}
% (\textit{bootstrap\footnote{\textit{Bootstrap} é uma técnica de amostragem com reposição.} agregating\footnote{[agregação]}})
\cite{breiman1996bagging}.

% Os \textit{ensembles} podem ser homogêneos ou heterogêneos independentemente da forma de combinação das repostas dos seus modelos componentes.
% Apesar disso, aqueles que fazem subamostragem normalmente não precisam ser heterogêneos, pois já têm uma variabilidade de viés devida aos diferentes subconjuntos de treinamento.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{\textit{Ensembles} de uso geral}\label{sec:ens-geral}
% Uma divisão possível das técnicas existentes é em \textit{\textbf{generative}\footnote{[gerador]} ensembles}
% e \textit{\textbf{non generative}\footnote{[não gerador]} ensembles} \cite{valentini2002ensembles}.
% O primeiro tipo interfere diretamente no treinamento dos modelos base, seja por reamostragem dos exemplos, seleção/extração de atributos ou variação nos parâmetros do algoritmo de aprendizado.
% O segundo tipo de \textit{ensemble} é alheio à geração dos modelos base, pois trabalha apenas com as respostas dadas por eles.
% Os principais exemplos de \textit{generative ensembles} são \textit{boosting}
% - que coloca a ênfase nos exemplos mais difíceis -
% e \textit{bagging}
% - com sua ênfase na aleatoriedade da escolha de exemplos.
% % Na Figura \ref{gen} é apresentado o esquema geral dos \textit{generative ensembles}.
% Um de seus principais representantes é o \textbf{AdaBoost} \cite{freund1999short}.
% % \begin{figure} %[H]
% %     \centering
% %     \includegraphics[height=7cm]{imagens/genens.pdf}
% %     \caption{\textit{Generative ensembles}}
% %     \label{gen}
% % \end{figure}
% 
% Alguns exemplos de \textit{non generative ensembles} também podem ser citados, como o \textbf{voto majoritário}\footnote{[\textit{majority voting}]} que é a simples votação de modelos gerados independentemente
% % apresentado na Figura \ref{fig:majvot} 
% \cite{valentini2002ensembles}.
% % \begin{figure} %[H]
% %     \centering
% %     \input imagens/ensemble-majvot.tex
% %     \caption{\textit{Ensemble} de voto majoritário: a moda ($Mo$) das predições determina a predição final $\hat{y}$.}
% %     \label{fig:majvot}
% % \end{figure}
% 
% No caso da \textbf{generalização em pilha}\footnote{[\textit{stacked generalization}]} - um tipo de meta-aprendizado
% \cite{vilalta2002perspective} baseado na metaclassificação de opiniões\footnote{A generalização em pilha é um exemplo em que o termo \textit{ensemble} se mostra mais adequado que \textit{comitê}, pois a combinação das opiniões em nada se assemelha a uma votação.}
% - usa-se um conjunto transformado de exemplos \cite{wolpert1992stacked}.
% Com isso, o espaço de atributos dá lugar ao espaço de votos.
% \cite{dzeroski2004combining} apoiam com base estatística o uso da generalização em pilha e concentram os experimentos na combinação de classificadores heterogêneos.
% O desempenho relatado é igual ou superior à seleção do melhor classificador por validação cruzada.
% 
% Outro \textit{non generative ensemble} é a \textbf{seleção dinâmica}\footnote{[\textit{dynamical selection}]} que se baseia na região onde se encontra o exemplo de teste num espaço de predições \cite{merz1996dynamical}.
% Esse espaço é composto pelos exemplos de treinamento e suas respectivas predições dadas pelos modelos.
% Apenas o modelo com melhor desempenho na proximidade do exemplo sob teste é escolhido e usado para classificá-lo.
% % er visto na Figura \ref{dynsel}.
% % \begin{figure} %[H]
% %     \centering
% %     \includegraphics[height=7cm]{imagens/dynselect.pdf}
% %     \caption{\textit{Dynamical Selection}}
% %     \label{dynsel}
% % \end{figure}
% 
% Muitos outros foram propostos, com a taxonomia de \cite{valentini2002ensembles} apontando mais de quinze subgrupos de \textit{ensembles} em cada um dos dois grupos principais (\textit{generative} e \textit{non generative}).
% 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{\textit{Ensembles} especializados} \label{sec:ens-especializados}
% Outra maneira de se organizar os tipos de \textit{ensemble} existentes é por seu objetivo primário.
% 
% % mudança de conceito
% Um desses objetivos é tratar a \textbf{mudança de conceito} (Seção \ref{sec:mudanca-de-conceito}).
% A mudança de conceito, quando há conceitos recorrentes, pode ser tratada por uma \textit{transferência de aprendizado} entre domínios similares:
% dentro de um fluxo de dados é desejável poder transferir aprendizado sobre conceitos antigos para conceitos novos.
% Por exemplo, um \textit{ensemble} baseado em transferência de aprendizado é o TrAdaBoost \cite{dai2007boosting}.
% Ele, no momento do treinamento,
% reduz o peso de exemplos do domínio de origem não condizentes com a distribuição dos exemplos do domínio de destino.
% \textit{Ensembles} semelhantes, mas diretamente relacionados a fluxo de dados,
% são abordados na Seção \ref{sec:fluxo-ensembles}.
% 
% % desbalanceamento
% O \textbf{desbalanceamento} é um outro problema que tem motivado o desenvolvimento de \textit{ensembles}.
% Com esse intuito, há adaptações de \textit{ensembles}, como o \textit{balanced random forest}\footnote{[floresta aleatória balanceada]} \cite{chen2004using}.
% Há também combinações de \textit{ensembles} com técnicas de balanceamento - como o SMOTEBoost \citep{chawla2003smoteboost} e o \textit{EasyEnsemble}\footnote{[\textit{Ensemble Fácil]}} \citep{liu2006exploratory}.
% O primeiro combina a bastante utilizada \textit{Synthetic Minority Over-sampling TEchnique}\footnote{[técnica de sobre-amostragem minoritária sintética]}  \cite{chawla2002smote} com o AdaBoost;
% o segundo combina vários processos de subamostragem da classe majoritária de forma a obter subconjuntos de treinamento mais equilibrados.
% 
% % Exploratory undersampling for class-imbalance learning
% % citado por
% % Online Learning from Imbalanced Data Streams
% 
% 
% % espaço de atributos heterogêneo
% Outra questão importante que pode ser tratada por \textit{ensembles} é a \textbf{heterogeneidade do espaço de atributos}.
% O uso de \textit{estimativas da acurácia local}\footnote{[\textit{local accuracy estimates}]}, que é a acurácia preditiva com base nos vizinhos rotulados mais próximos, permite a seleção dos modelos mais aptos espacialmente:
% os modelos com melhor desempenho nos exemplos do entorno do exemplo sob teste são escolhidos para opinar sobre o seu possível rótulo.
% Essa é a proposta da \textit{seleção dinâmica de classificador por acurácia local} ou DCS-LA\footnote{[\textit{Dynamic Classifier Selection by Local Accuracy}]}\cite{woods1997combination}.
% % Esse \textit{ensemble} foi implementado especialmente para este artigo e tem suas acurácias registradas na parte experimental.
% 
% % ruído
% Por fim, um problema adicional tratado por \textit{ensembles} é a \textbf{presença de ruído}.
% Um possível critério para determinar se um exemplo está incorretamente rotulado (ruidoso) é o erro por consenso.
% Se nenhum modelo é capaz de predizer corretamente o valor de um determinado exemplo,
% então é muito provável que ele não pertença à distribuição dos exemplos restantes.
% Dessa forma, é possível eliminá-lo ou rotulá-lo corretamente para processos posteriores de treinamento \cite{brodley1996identifying}.

\textit{Query by bagging}
% {consulta por ensacamento, em tradução literal; ou, \textit{bootstrap aggregating}, agregação de inicializações} 
e
\textit{query by boosting}
% {consulta por grupo de amostras impulsionada, em tradução livre}
são dois exemplos de \ing{\sigla{QBC}{consulta por comitê}}{Query By Committee} utilizados por \citeonline{conf/icml/AbeM98}.
Dependendo do tipo de valor de retorno fornecido pelo modelo, diferentes medidas de desacordo podem ser utilizadas.
% The possibility to take measures about the 
% \textbf{disagreement between concurrent hypotheses},
% rather than a single model probability output, is the main feature
% of this strategy.
% In data-based ensembles, subsampling techniques are the most popular,
% specifically \textit{boosting} and \textit{bagging}.
% While boosting \cite{schapire1990strength} explores instances uncovered
% (incorrectly classified) by previous models to generate the next one,
% bagging \cite{breiman1996bagging} tries to force different biases by randomly
% selecting considerably different subsets of instances for each classifier.
% In the active learning context,
% the several flavors of Query by Committee are similar to both uncertainty sampling and
% \textit{query by disagreement}.
% They unite the localized notion of uncertainty from the former with the multiple opinions from
% the latter into a single measure.
% Due to its enforced diversity, \textit{Decorate} ensembles are also worth to mention.
% In this paper,
% % \textit{soft vote entropy} \cite{series/synthesis/2012Settles} is considered when generating queries from
% committees apart from the fact that non-probabilistic classifiers like decision trees are adopted
% instead of probabilistic ones.
%  two such measures are \textit{JS-divergence} and \textit{KL-divergence}.
% They have been described as good measures to achieve accurate class probability estimates
%mccallum1998employing}.
A divergência de Jensen-Shannon \cite{journals/tit/Lin91}, por exemplo,
é uma medida de teoria da informação que compara distribuições de 
probabilidade, comumente usada em comitês para avaliar o grau de
desacordo entre os membros \cite{conf/icml/MelvilleM04}.
A divergência não-ponderada de Jensen-Shannon é definida em termos da
entropia das distribuições na Equação \ref{js}.
\begin{equation}\label{js}
\JS(C,\bm{x})=E_{\theta_{C}}(\bm{x})-\sum{\langle E_{\theta}(\bm{x}) \mid \theta \in C \rangle}
\end{equation}
O modelo geral $\theta_{C}$ é a agregação de todos os modelos e representa o comitê como um todo.
Quanto maior o valor de $\JS$, mais distante os membros estão de um consenso.
Assim, o exemplo com o maior valor deve ser consultado primeiro.
A complexidade computacional é $\mathcal{O}(1)$,
se o comitê for visto como um único algoritmo de aprendizado;
ou $\mathcal{O}(|C|)$, se o número de membros $|C|$ for considerado.


\subsubsection{Redução do erro esperado}
\simbolo{O}{função objetivo na estratégia de redução do erro}
A \ing{\sigla{EER}{estratégia de redução do erro esperado}}{Expected Error Reduction} adotada neste trabalho é baseada no \textit{exemplo de redução da entropia} proposto por \cite{conf/ijcai/GuoG07}.
É um método que busca pelo exemplo que mais reduz a entropia na predição geral do modelo para todo o conjunto de dados.
Ele considera, assim, implicitamente, a informação sobre eventuais agrupamentos subjacentes, evitando depender apenas dos escassos exemplos rotulados.
% Essa variante de estratégias de redução de erro foi adotada dado que uma performance superior à
% original foi reportada pelos autores.

O exemplo $\hat{\bm{x}}$ selecionado para consulta e sua classe mais provável, representada pelo vetor preditivo $\hat{y}$, são obtidos conforme a Equação \ref{eqerr}, onde $O$ é a função objetivo.
\begin{equation}\label{eqerr}
 \langle \hat{\bm{x}}, \hat{y} \rangle = \argmin_{\langle \bm{x}, y \rangle \in \mathcal{U} \times Y}{\sum_{\bm{u} \in \mathcal{U}} O(\theta_{\mathcal{L}\cup
\{\langle\bm{u},y\rangle\}}, \bm{x})}
\end{equation}
Após cada consulta, caso a classe real seja diferente da esperada, o método recorre à estratégia de amostragem por incerteza (Seção \ref{unc}) como medida de contingência.
No artigo original, optou-se pela entropia como função objetivo.
Outras medidas também podem ser adequadas, dependendo da meta, como a acurácia balanceada ou kappa multiclasse (Seção \ref{medidas}).
A complexidade computacional é $\mathcal{O}(|Y||\mathcal{U}|^2)$.

\subsubsection{Impacto esperado no modelo}
O futuro impacto de um exemplo sobre o modelo é a base de um tipo de estratégia chamado \textit{mudança esperada no modelo}.
Esse impacto é uma indicação de sua possível contribuição para o aprendizado.
O procedimento proposto por \cite{conf/nips/SettlesCR07} é chamado \ing{\sigla{EGL}{comprimento esperado do gradiente}}{Expected Gradient Length}.
Ele se aplica a modelos baseados na técnica de gradiente descendente
no espaço $\mathcal{F}$ \cite{haykin2004comprehensive}:
deve ser escolhido para treinamento o exemplo capaz de contribuir com a descida de maior magnitude na curva de erro.
Como o rótulo não é sabido de antemão, usa-se a soma das contribuições de cada rótulo ponderada pelas suas respectivas probabilidades a posteriori.

% \subsection{Expected Model Change}
% One can relief the sampling process from the computational complexity of analyzing the expected impact over the pool.
% This is possible by observing only the expected impact on the model.
% One such strategy is the Expected Gradient Length \cite{conf/nips/SettlesCR07}.
% Since the true label is not known in advance,
% the expected model change is calculated over all possible labels.
% The differences between two trainings (the previous and the candidate to be the next training) $\Delta C(\bm{x},y,\mathcal{L})$ is weighted by the model's posterior probability estimates $P(\bm{x})$:
% \[
%  EMC(\bm{x}) = \sum_{c \in Y}P(c\mid\bm{x}) \Delta C(\bm{x},y,\mathcal{L})
%  \]
%  \[
%  \Delta C(\bm{x},c,\mathcal{L}) = |C(\mathcal{L} \cup \{\langle\bm{x},c\rangle\}) - C(\mathcal{L})|
% \]
% 
% \textit{Expected Model Change} is similar to \textit{uncertainty sampling} because it is based on a localized criterion: it is focused on the relation between the current model and the candidate query instead of the rest of the instances.
% 
% % Although it has higher time complexity than \textit{uncertainty sampling}, it is \textbf{faster than \textit{expected error reduction}}.
% 
% The complexity of each query is $\mathcal{O}(|Y|.|\mathcal{U}|)$.
% Like \textit{Expected Error Reduction},
% training time can be reduced when the learning algorithm is incremental.
% Since none of the learning algorithms adopted in this work have an analogous to the gradient length,
% \textit{Expected Model Change} was not included in the experiments.



% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
%                         FIM do arquivo
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 


% outroas formas de Unc:
% Em classificadores probabilísticos, como é o caso do \textit{Naive Bayes} \citep{duda2001pattern},
% Árvores de decisão \citep{quinlan1993c4}, $k$-vizinhos mais próximos \citep{aha1991instance} também têm sido usados para a estratégia de \textit{uncertainty sampling}.
% A medida de incerteza, nesses casos, pode ser respectivamente: a pureza do nó, a proporção de vizinhos positivos e a distância exemplo-fronteira \citep{settles2010active}.
% 
% Decomposição viés-variância do erro.
% Ruído intrínseco é o erro esperado do preditor bayesiano ótimo\cite{zhang2012empirical}.
% Viés é o desvio sistemático normalmente esperado ao longo de diferentes experimentos (diferentes conjuntos de treinamento).
% Variância é a variabilidade esperada em torno do viés dados diferentes experimentos.
% \begin{figure}
% \begin{center}
% \begin{tikzpicture}
% \begin{axis}[axis y line=left, xmin=20, xmax=72, ymin=1.45, ymax=1.9, axis x line=bottom, grid, xlabel=peso (kg),   ylabel=altura (m)]
% \addplot[only marks,mark=text,text mark=\C{$+$},mark options={blue,scale=1}] plot coordinates {
%     (50,1.5)
% }; \addlegendentry{positivo}
% \addplot[only marks,mark=text,text mark=\T{?},mark options={gray,scale=1}] plot coordinates {
%     (51.6,1.76) (48,1.55) (36,1.55) (38,1.61) (43,1.5)
% }; \addlegendentry{não rotulado}
% \addplot[only marks,mark=text,text mark=\Q{$-$},mark options={red,scale=1}] plot coordinates {
%     (30,1.60)
% }; \addlegendentry{negativo}
% 
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_a}$, mark options={black,scale=1}] plot coordinates {
%     (51.6,1.73)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_d}$, mark options={black,scale=1}] plot coordinates {
%   (48,1.52)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_c}$, mark options={black,scale=1}] plot coordinates {
%   (36,1.52)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_b}$, mark options={black,scale=1}] plot coordinates {
%   (38,1.58)};
% \addplot[only marks,mark=text,text mark=$\boldsymbol{x_e}$, mark options={black,scale=1}] plot coordinates {
%   (43,1.47)};
% 
% \addplot[thick, mark=none, teal] plot coordinates {
%     (54.5,1.86) (35,1.45)
% };
% % \node[small dot,pin=-45:{$\boldsymbol{x^*}$}] at (333,300) {};
% % \node[small dot,pin=45:{$\boldsymbol{x_b}$}] at (290,110) {};
% % \node[small dot,pin=45:{$\boldsymbol{x_a}$}] at (160,110) {};
% \end{axis}
% \end{tikzpicture}
% \caption{O exemplo mais controverso ($\boldsymbol{x_a}$), ou seja, o mais próximo da fronteira, nem sempre é o mais representativo da distribuição dos dados.}
% \label{fig:incerteza_vs_importancia}
% \end{center}
% \end{figure}
% % Density-Weighted Methods
% % \subsection{Notas}
% 

% % Variance Reduction
% Não implementei Variance reduction pois exige um sistema muito complexo e com otimizações e ainda assim é ordens de magnitude mais lento que  Unc. Sampl.
% Uma forma indireta de fazer a minimização do erro de generalização
%  é a \textbf{redução da variância}\footnote{[\textit{variance reduction}]
% }.
% Apesar do enfoque diferente, a ordem de complexidade continua sendo um
% problema, pois depende quadraticamente do número de parâmetros do modelo.
% Mesmo quando se reduz essa complexidade por amostragem, redução de
%  dimensionalidade, etc., essa abordagem, assim como outras de medidas conjuntas, permanece empiricamente muito mais lenta que medidas isoladas como \textit{uncertainty sampling} \citep{settles2010active}.

% \ano{diferenciar de aprendizado semisuperv.}

% \tar{usar semisupervised somente na fase de predição não faria muito
% sentido.
% usar semisupervised no learner faz sentido pelo fato de se ter tantos
% exemplos
% unlabeled à disposição}

% \tar{citar relação com crowd sourcing/labeling?}

% \citep{conf/ijcnn/SalperwyckL11}
% Learning with few examples: An empirical study on leading classifiers 2011
% associa AL com incremental learning, mas não é sobre AL
% faz ALC com AUC e log2
% investiga tipos de AL especificos para poucos exemplos
% compara ?bastante? datasets:
% The study presented in this paper aims to
% study a larger panel of both algorithms (9 different kinds) and
% data sets (17 UCI conjuntos).
% % http://ieeexplore.ieee.org/xpls/icp.jsp?arnumber=6033333
% % combina AUC final com ALC num grafico 2D

% Activized Learning: Transforming Passive to Active with Improved Label Complexity 2012 Hanneke
% First, since we are lacking a complete understanding of the potential capabilities of active learning, we are not yet sure to what standards we should aspire for active learning algorithms to meet, and in particular this challenges our ability to characterize how a ?good? active learning algorithm should behave. Second, since we have yet to identify a complete set of general principles for the design of effective active learning algorithms, in many cases the most effective known active learning algorithms have problem-specific designs (e.g., designed specifically for linear separators, or decision trees, etc., under specific assumptions on the data distribution), and it is not clear what components of their design can be abstracted and transferred to the design of active learning algorithms for different learning problems (e.g., with different types of classifiers,
% or different data distributions). Finally, we have yet to fully understand the scope of the relative
% benefits of active learning over passive learning, and in particular the conditions under which such
% improvements are achievable, as well as a general characterization of the potential magnitudes of
% these improvements. In the present work, we take steps toward closing this gap in our understanding
% of the capabilities, general principles, and advantages of active learning.
% ...
% REALIZABLE CASE
% In the realizable case, there are obvious examples of learning problems where
% active learning can provide a significant advantage compared to passive learning ...  binary search strategy for selecting which examples to request labels for naturally leads to exponential improvements in label complexity compared to learning from random labeled examples (passive learning). ?
% Disagreement-based methods are sometimes referred to as ?mellow? active learning, since in some sense this is the least we can expect from a reasonable active learning algorithm; it never requests the label of an example whose label it can infer from information already available, but otherwise makes no attempt to seek out particularly informative examples to request the labels of. 
% Balcan, Hanneke, and Vaughan (2010) noted that if we do not require the algorithm to be self-verifying, instead simply measuring the number of label requests the algorithm needs to find a good classifier, rather than the number
% needed to both find a good classifier and verify that it is indeed good, then these negative results vanish.
% In fact, (shockingly) they were able to show that for any concept space with finite VC dimension, and any fixed data distribution, for any given passive learning algorithm there is an active learning algorithm with asymptotically superior label complexity for every nontrivial target concept!